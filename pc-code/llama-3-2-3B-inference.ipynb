{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"onboarding_task_dataset_v3.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open(filename, 'r', encoding='utf-8') as f:\n",
    "  for line in f:\n",
    "    data.append(json.loads(line.strip()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset: 577 examples\n",
      "Validation dataset: 63 examples\n",
      "Test dataset: 63 examples\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dataset = Dataset.from_list(data)\n",
    "\n",
    "train_test_data = dataset.train_test_split(test_size=63, seed=42)\n",
    "train_val_data = train_test_data[\"train\"].train_test_split(test_size=63, seed=42)\n",
    "\n",
    "# Access the train, validation, and test datasets\n",
    "train_dataset = train_val_data[\"train\"]\n",
    "eval_dataset = train_val_data[\"test\"]\n",
    "test_dataset = train_test_data[\"test\"]\n",
    "\n",
    "# Print the number of examples in each set\n",
    "print(f\"Train dataset: {len(train_dataset)} examples\")\n",
    "print(f\"Validation dataset: {len(eval_dataset)} examples\")\n",
    "print(f\"Test dataset: {len(test_dataset)} examples\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|system|>\\nYou are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|end|>\\n<|user|>\\n\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"VPs of development or executives in real estate?\"\\nOutput:<|end|>\\n<|assistant|>{\\'management_level\\': [\\'Executive and Sr. VP\\'], \\'title\\': [\\'VP of Development\\', \\'Vice President of Development\\']}<|end|>'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[13][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_message = \"\"\"Definition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"VPs of development or executives in real estate?\"\\nOutput:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"\"\"{\\'management_level\\':\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE_INFERENCE = \"\"\"\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>{{system_message}}<|eot_id|>\n",
    "<|begin_of_text|><|start_header_id|>user<|end_header_id|>{{user_message}}<|eot_id|>\n",
    "<|start_header_id|>assistant<|end_header_id|>{{prefix}}\"\"\"\n",
    "PROMPT_TEMPLATE_FINETUNING = \"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>{{system}}<|eot_id|>\n",
    "    <|start_header_id|>user<|end_header_id|>{{user}}<|eot_id|>\n",
    "    <|start_header_id|>assistant<|end_header_id|>{{assistant}}<|eot_id|>\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jinja2 import Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = Template(PROMPT_TEMPLATE).render({\"system_message\": system_message, \"user_message\": user_message, \"prefix\" : prefix})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = \"/home/raza/Downloads/meta-llama-3-2-3B-Instruct\"\n",
    "# peft_model_name = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BitsAndBytesConfig, AutoProcessor, AutoModelForCausalLM\n",
    "import torch\n",
    "from peft import PeftModel\n",
    "\n",
    "# specify how to quantize the model\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "            bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "device_map = {\"\": torch.cuda.current_device()} if torch.cuda.is_available() else None\n",
    "\n",
    "model_kwargs = dict(\n",
    "    attn_implementation=\"flash_attention_2\", # set this to True if your GPU supports it (Flash Attention drastically speeds up model computations)\n",
    "    torch_dtype=\"auto\",\n",
    "    use_cache=False, # set to False as we're going to use gradient checkpointing\n",
    "    device_map=device_map,\n",
    "    quantization_config=quantization_config,\n",
    ")\n",
    "# Assuming you're using a text generation model like GPT\n",
    "processor = AutoProcessor.from_pretrained(base_model)\n",
    "\n",
    "# Set the padding token to be the same as eos_token if it's not defined\n",
    "if processor.pad_token is None:\n",
    "    processor.pad_token = processor.eos_token  # or you can set a custom token if needed\n",
    "\n",
    "processor.padding_side = 'right'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96bbeb8d54ce43d584222078cb25d323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "          base_model,\n",
    "          trust_remote_code=True,\n",
    "          attn_implementation=\"flash_attention_2\", # set this to True if your GPU supports it (Flash Attention drastically speeds up model computations)\n",
    "          torch_dtype=\"auto\",\n",
    "          use_cache=False, # set to False as we're going to use gradient checkpointing\n",
    "          device_map=device_map,\n",
    "          quantization_config=quantization_config,\n",
    ")\n",
    "\n",
    "# peft_model = PeftModel.from_pretrained(\n",
    "#     model,\n",
    "#     peft_model_name\n",
    "# )\n",
    "\n",
    "# peft_model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\n",
      "<|begin_of_text|><|start_header_id|>user<|end_header_id|>Definition of a Functional Area:\n",
      "- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\n",
      "\n",
      "Definition of Management Level:\n",
      "- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\n",
      "- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\n",
      "\n",
      "Definition of a Job Title:\n",
      "- A job title refers to a specific employment position combined with a functional area.\n",
      "- Examples include 'VP of Engineering' (functional area: Engineering) and 'Director of Finance' (functional area: Finance).\n",
      "\n",
      "Instructions:\n",
      "1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\n",
      "2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\n",
      "3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\n",
      "4. If a keyword is classified as title, don't include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don't include \"VP\" in management levels.\n",
      "\n",
      "Example:\n",
      "Query: \"Provide a list of CFOs and VPs working in the technology sector\"\n",
      "Output: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\n",
      "\n",
      "Guidelines:\n",
      "- \"Leaders\" implies CSuite/President level\n",
      "- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\n",
      "- Use knowledge base for educated guesses about classifications\n",
      "\n",
      "Query: \"VPs of development or executives in real estate?\"\n",
      "Output:<|eot_id|>\n",
      "<|start_header_id|>assistant<|end_header_id|>{'management_level':\n"
     ]
    }
   ],
   "source": [
    "print(prompt.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Output: systemYou are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.\n",
      "userDefinition of a Functional Area:\n",
      "- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\n",
      "\n",
      "Definition of Management Level:\n",
      "- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\n",
      "- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\n",
      "\n",
      "Definition of a Job Title:\n",
      "- A job title refers to a specific employment position combined with a functional area.\n",
      "- Examples include 'VP of Engineering' (functional area: Engineering) and 'Director of Finance' (functional area: Finance).\n",
      "\n",
      "Instructions:\n",
      "1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\n",
      "2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\n",
      "3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\n",
      "4. If a keyword is classified as title, don't include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don't include \"VP\" in management levels.\n",
      "\n",
      "Example:\n",
      "Query: \"Provide a list of CFOs and VPs working in the technology sector\"\n",
      "Output: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\n",
      "\n",
      "Guidelines:\n",
      "- \"Leaders\" implies CSuite/President level\n",
      "- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\n",
      "- Use knowledge base for educated guesses about classifications\n",
      "\n",
      "Query: \"VPs of development or executives in real estate?\"\n",
      "Output:\n",
      "assistant{'management_level': ['VP', 'Executive and Sr.\n"
     ]
    }
   ],
   "source": [
    "def inference_function(model, max_new_tokens, input_text: str):\n",
    "    \"\"\"\n",
    "    Simple inference function to generate text based on an input prompt.\n",
    "\n",
    "    Args:\n",
    "    - input_text (str): The input text to be processed by the model.\n",
    "    - max_length (int): The maximum length of the generated text.\n",
    "\n",
    "    Returns:\n",
    "    - str: The generated text.\n",
    "    \"\"\"\n",
    "    # Process the input text\n",
    "    inputs = processor(input_text, return_tensors=\"pt\", padding=True).to(model.device)\n",
    "    # Generate output from the model\n",
    "    output = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=True,  # Enable sampling for more diverse outputs\n",
    "        temperature=0.1,\n",
    "        top_p=0.9\n",
    "    )\n",
    "\n",
    "    # Decode the output tokens into text\n",
    "    generated_text = processor.decode(output[0], skip_special_tokens=True)  # Get the first sequence\n",
    "\n",
    "    return generated_text\n",
    "\n",
    "# Example usage\n",
    "input_text = \"Donald Trump is \"\n",
    "generated_output = inference_function(model=model, input_text=prompt.strip(), max_new_tokens=8)\n",
    "print(f\"Generated Output: {generated_output}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Util Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"prompt\": \"<|system|>\\nYou are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|end|>\\n<|user|>\\n\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \\\"Board of Directors,\\\" \\\"CSuite and President,\\\" \\\"Executive and Sr. VP,\\\" \\\"General Manager,\\\" \\\"VP,\\\" \\\"Director,\\\" \\\"Manager,\\\" \\\"Senior (Individual Contributor),\\\" \\\"Mid (Individual Contributor),\\\" and \\\"Junior.\\\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include 'VP of Engineering' (functional area: Engineering) and 'Director of Finance' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\\\"Board of Directors,\\\" \\\"CSuite and President,\\\" \\\"Executive and Sr. VP,\\\" \\\"General Manager,\\\" \\\"VP,\\\" \\\"Director,\\\" \\\"Manager,\\\" \\\"Senior (Individual Contributor),\\\" \\\"Mid (Individual Contributor),\\\" \\\"Junior\\\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \\\"ceo\\\" to \\\"Chief Executive Officer\\\" and include both the full title and its abbreviation if mentioned in the query, e.g., \\\"VP of Engineering\\\" and \\\"Vice President of Engineering.\\\"\\n3. Response Format: Your response must be a dictionary with two keys: \\\"management_levels\\\" and \\\"titles\\\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don't include it in the management levels and vice versa. e.g if \\\"VP of Engineering\\\" is classified as title then don't include \\\"VP\\\" in management levels.\\n\\nExample:\\nQuery: \\\"Provide a list of CFOs and VPs working in the technology sector\\\"\\nOutput: {\\\"management_levels\\\": [\\\"VP\\\"], \\\"titles\\\": [\\\"Chief Financial Officer\\\", \\\"CFO\\\"]}\\n\\nGuidelines:\\n- \\\"Leaders\\\" implies CSuite/President level\\n- Titles without functional areas (e.g., \\\"Founder\\\", \\\"Managing Director\\\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \\\"VPs of development or executives in real estate?\\\"\\nOutput:<|end|><|assistant|>{ \\\"management_level\\\" : \",\n",
      "  \"ground_truth\": {\n",
      "    \"management_level\": [\n",
      "      \"Executive and Sr. VP\"\n",
      "    ],\n",
      "    \"title\": [\n",
      "      \"VP of Development\",\n",
      "      \"Vice President of Development\"\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def parse_string(input_string):\n",
    "    # Define the markers and unwanted \"Output:\" part\n",
    "    marker = \"<|assistant|>\"\n",
    "    output_label = \"Output:\"\n",
    "    end_marker = \"<|end|>\"  # Marker that may appear at the end of the string\n",
    "    \n",
    "    # Find the index of the main marker\n",
    "    marker_index = input_string.find(marker)\n",
    "\n",
    "    # If the marker is found, split the string accordingly\n",
    "    if marker_index != -1:\n",
    "        prompt = input_string[:marker_index].strip() + marker + \"\"\"{ \"management_level\" : \"\"\"\n",
    "        ground_truth = input_string[marker_index + len(marker):].strip()\n",
    "        \n",
    "        # Remove the \"Output:\" label if it's present at the beginning of the ground truth\n",
    "        if ground_truth.startswith(output_label):\n",
    "            ground_truth = ground_truth[len(output_label):].strip()\n",
    "        \n",
    "        # Remove the \"<|end|>\" token or other similar tokens from the ground truth\n",
    "        ground_truth = ground_truth.replace(end_marker, \"\").strip()\n",
    "\n",
    "        # Convert single quotes to double quotes for valid JSON parsing\n",
    "        ground_truth = ground_truth.replace(\"'\", \"\\\"\")\n",
    "\n",
    "        # Try parsing the ground truth into a dictionary\n",
    "        try:\n",
    "            ground_truth_dict = json.loads(ground_truth)  # Assumes ground truth is a valid JSON string\n",
    "        except json.JSONDecodeError:\n",
    "            ground_truth_dict = None  # If it's not valid JSON, return None\n",
    "            \n",
    "        return {\n",
    "            \"prompt\": prompt,\n",
    "            \"ground_truth\": ground_truth_dict\n",
    "        }\n",
    "    else:\n",
    "        # If the marker is not found, return the entire input as prompt, and None as ground_truth\n",
    "        return {\n",
    "            \"prompt\": input_string.strip(),\n",
    "            \"ground_truth\": None\n",
    "        }\n",
    "\n",
    "\n",
    "parsed_result = parse_string(test_dataset[13][\"text\"])\n",
    "\n",
    "print(json.dumps(parsed_result, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'VPs of development or executives in real estate?'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_query(input_str):\n",
    "    # Define the pattern to capture the last \"Query:\" and corresponding \"Output:\"\n",
    "    pattern = r'Use knowledge base for educated guesses about classifications\\s*Query:\\s*(.*?)\\s*Output:'\n",
    "    \n",
    "    # Search for the pattern\n",
    "    match = re.search(pattern, input_str, re.DOTALL)\n",
    "    \n",
    "    if match:\n",
    "        # Extract the query text (the first group corresponds to the query part)\n",
    "        query = match.group(1).strip()\n",
    "        return eval(query)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "extract_query(test_dataset[13][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def response_parser(response_str):\n",
    "    # Define a regular expression pattern to capture all JSON objects in the string\n",
    "    json_pattern = r'(\\{.*?\\})'\n",
    "    \n",
    "    # Find all matches of the JSON objects in the string\n",
    "    matches = re.findall(json_pattern, response_str.strip(), re.DOTALL)\n",
    "    \n",
    "    if matches:\n",
    "        # Get the last match, which should be the most recent JSON object\n",
    "        last_json_str = matches[-1]\n",
    "        \n",
    "        try:\n",
    "            # Parse the last matched JSON string\n",
    "            parsed_response = json.loads(last_json_str)\n",
    "            return parsed_response\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Error: The last JSON in the response string is not valid.\")\n",
    "            return None\n",
    "    else:\n",
    "        print(\"Error: No valid JSON found in the response.\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "def display_comparison(comparison_list):\n",
    "    # Helper function to safely get key from dictionary or return a default value\n",
    "    def safe_get(entry, field, subfield=None, default=\"N/A\"):\n",
    "        if entry.get(field) is None:  # Check if the field itself is None\n",
    "            return default\n",
    "        if subfield:  # If we need to access a subfield (e.g., 'label', 'confidence')\n",
    "            return entry.get(field, {}).get(subfield, default)\n",
    "        return entry.get(field, default)\n",
    "    \n",
    "    # Extract relevant information from Query, Ground Truth, Prediction, and Exact Match\n",
    "    query_data = [entry.get('Query', 'N/A') for entry in comparison_list]\n",
    "    \n",
    "    # Extract 'Ground Truth' data, handling missing keys or NoneType\n",
    "    gt_data = [\n",
    "        f\"{safe_get(entry, 'Ground Truth')}\"\n",
    "        for entry in comparison_list\n",
    "    ]\n",
    "    \n",
    "    # Extract 'Prediction' data, handling missing keys or NoneType\n",
    "    pred_data = [\n",
    "        f\"{safe_get(entry, 'Prediction')}\"\n",
    "        for entry in comparison_list\n",
    "    ]\n",
    "    \n",
    "    # Extract 'Exact Match' information (assuming it's a boolean)\n",
    "    exact_match_data = [\n",
    "        \"Yes\" if entry.get('Exact Match', False) else \"No\"  # Default to False if 'Exact Match' is missing or None\n",
    "        for entry in comparison_list\n",
    "    ]\n",
    "    \n",
    "    # Create a DataFrame with the new information\n",
    "    df = pd.DataFrame({\n",
    "        'Query': query_data,\n",
    "        'Ground Truth (GT)': gt_data,\n",
    "        'Prediction (Pred)': pred_data,\n",
    "        'Exact Match': exact_match_data\n",
    "    })\n",
    "    \n",
    "    # Display the DataFrame as a neat table\n",
    "    display(df)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BitsAndBytesConfig, AutoProcessor, AutoModelForCausalLM\n",
    "import torch\n",
    "from peft import PeftModel\n",
    "\n",
    "# specify how to quantize the model\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "            bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "device_map = {\"\": torch.cuda.current_device()} if torch.cuda.is_available() else None\n",
    "\n",
    "model_kwargs = dict(\n",
    "    attn_implementation=\"flash_attention_2\", # set this to True if your GPU supports it (Flash Attention drastically speeds up model computations)\n",
    "    torch_dtype=\"auto\",\n",
    "    use_cache=False, # set to False as we're going to use gradient checkpointing\n",
    "    device_map=device_map,\n",
    "    quantization_config=quantization_config,\n",
    ")\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(base_model)\n",
    "processor.padding_side = 'right'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1358ea8dbf9f4cbbbc3b993be63bd23a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): Phi3ForCausalLM(\n",
       "      (model): Phi3Model(\n",
       "        (embed_tokens): Embedding(32064, 3072, padding_idx=32000)\n",
       "        (embed_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x Phi3DecoderLayer(\n",
       "            (self_attn): Phi3FlashAttention2(\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (qkv_proj): Linear4bit(in_features=3072, out_features=9216, bias=False)\n",
       "              (rotary_emb): Phi3RotaryEmbedding()\n",
       "            )\n",
       "            (mlp): Phi3MLP(\n",
       "              (gate_up_proj): Linear4bit(in_features=3072, out_features=16384, bias=False)\n",
       "              (down_proj): Linear4bit(in_features=8192, out_features=3072, bias=False)\n",
       "              (activation_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): Phi3RMSNorm()\n",
       "            (resid_attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (post_attention_layernorm): Phi3RMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (norm): Phi3RMSNorm()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=3072, out_features=32064, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "          base_model,\n",
    "          trust_remote_code=True,\n",
    "          attn_implementation=\"flash_attention_2\", # set this to True if your GPU supports it (Flash Attention drastically speeds up model computations)\n",
    "          torch_dtype=\"auto\",\n",
    "          use_cache=False, # set to False as we're going to use gradient checkpointing\n",
    "          device_map=device_map,\n",
    "          quantization_config=quantization_config,\n",
    ")\n",
    "\n",
    "peft_model = PeftModel.from_pretrained(\n",
    "    model,\n",
    "    peft_model_name\n",
    ")\n",
    "\n",
    "peft_model.eval()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finetuning_v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
