{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":41518,"status":"ok","timestamp":1735811309869,"user":{"displayName":"Ali Raza","userId":"08516408430091031466"},"user_tz":-300},"id":"xBCkQ-aoV3g-","outputId":"b0941b14-6435-4d5e-b913-40f917c35eb9"},"outputs":[],"source":["# pip install -q transformers[torch] datasets\n","# pip install -q bitsandbytes trl peft\n","# pip install flash-attn --no-build-isolation"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":572,"status":"ok","timestamp":1735811577024,"user":{"displayName":"Ali Raza","userId":"08516408430091031466"},"user_tz":-300},"id":"XjqZ5C_waZT1"},"outputs":[],"source":["from datasets import DatasetDict\n","import json"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":590,"status":"ok","timestamp":1735811549144,"user":{"displayName":"Ali Raza","userId":"08516408430091031466"},"user_tz":-300},"id":"XXkI7dHradaA"},"outputs":[],"source":["filename = \"llama-3-finetuning-data.jsonl\""]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":431,"status":"ok","timestamp":1735811584754,"user":{"displayName":"Ali Raza","userId":"08516408430091031466"},"user_tz":-300},"id":"Bdc50QKBbkKm"},"outputs":[],"source":["data = []\n","with open(filename, 'r', encoding='utf-8') as f:\n","  for line in f:\n","    data.append(json.loads(line.strip()))\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":424,"status":"ok","timestamp":1735811710425,"user":{"displayName":"Ali Raza","userId":"08516408430091031466"},"user_tz":-300},"id":"Dgmct4Tqbswq","outputId":"517b6081-379a-45f7-cc04-91a45185ea02"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train dataset: 577 examples\n","Validation dataset: 63 examples\n","Test dataset: 63 examples\n"]}],"source":["from datasets import Dataset\n","\n","dataset = Dataset.from_list(data)\n","\n","train_test_data = dataset.train_test_split(test_size=63, seed=42)\n","train_val_data = train_test_data[\"train\"].train_test_split(test_size=63, seed=42)\n","\n","# Access the train, validation, and test datasets\n","train_dataset = train_val_data[\"train\"]\n","eval_dataset = train_val_data[\"test\"]\n","test_dataset = train_test_data[\"test\"]\n","\n","# Print the number of examples in each set\n","print(f\"Train dataset: {len(train_dataset)} examples\")\n","print(f\"Validation dataset: {len(eval_dataset)} examples\")\n","print(f\"Test dataset: {len(test_dataset)} examples\")\n","\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"From the latest report of Genentech, tell me the key highlights of the company.\"\\nOutput:<|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>{\\'management_levels\\': [], \\'titles\\': []}<|eot_id|>'}\n","{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"Director of Human-AI Collaboration\"\\nOutput:<|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>{\\'management_levels\\': [], \\'titles\\': [\\'Director of Human-AI Collaboration\\']}<|eot_id|>'}\n","{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"Identify junior roles in cloud services.\"\\nOutput:<|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>{\\'management_levels\\': [\\'Junior\\'], \\'titles\\': []}<|eot_id|>'}\n","{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"List all senior engineers in robotics innovation labs.\"\\nOutput:<|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>{\\'management_levels\\': [\\'Senior (Individual Contributor)\\'], \\'titles\\': []}<|eot_id|>'}\n","{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"Director Mental Health Programs\"\\nOutput:<|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>{\\'management_levels\\': [], \\'titles\\': [\\'Director of Mental Health Programs\\']}<|eot_id|>'}\n","{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"Leaders of top energy companies in the US.\"\\nOutput:<|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>{\\'management_levels\\': [\\'CSuite and President\\'], \\'titles\\': []}<|eot_id|>'}\n","{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"VP Planetary Science\"\\nOutput:<|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>{\\'management_levels\\': [], \\'titles\\': [\\'VP of Planetary Science\\', \\'Vice President of Planetary Science\\']}<|eot_id|>'}\n","{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"VP Construction Innovation\"\\nOutput:<|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>{\\'management_levels\\': [], \\'titles\\': [\\'VP of Construction Innovation\\', \\'Vice President of Construction Innovation\\']}<|eot_id|>'}\n","{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"Directors or managers leading innovation projects in IT.\"\\nOutput:<|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>{\\'management_levels\\': [\\'Director\\', \\'Manager\\'], \\'titles\\': [\\'Director of Innovation\\', \\'Manager of Innovation\\']}<|eot_id|>'}\n","{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"Chief Archaeologist\"\\nOutput:<|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>{\\'management_levels\\': [], \\'titles\\': [\\'Chief Archaeologist\\']}<|eot_id|>'}\n","{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"VP Marine Innovation\"\\nOutput:<|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>{\\'management_levels\\': [], \\'titles\\': [\\'VP of Marine Innovation\\', \\'Vice President of Marine Innovation\\']}<|eot_id|>'}\n","{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"Heads of marketing for social media platforms.\"\\nOutput:<|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>{\\'management_levels\\': [], \\'titles\\': [\\'Head of Marketing\\']}<|eot_id|>'}\n","{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"Chief Data Ethics Officer\"\\nOutput:<|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>{\\'management_levels\\': [], \\'titles\\': [\\'Chief Data Ethics Officer\\', \\'CDEO\\']}<|eot_id|>'}\n","{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"VPs of development or executives in real estate?\"\\nOutput:<|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>{\\'management_levels\\': [\\'Executive and Sr. VP\\'], \\'titles\\': [\\'VP of Development\\', \\'Vice President of Development\\']}<|eot_id|>'}\n","{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"Leaders of government tech initiatives in Asia.\"\\nOutput:<|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>{\\'management_levels\\': [\\'CSuite and President\\'], \\'titles\\': []}<|eot_id|>'}\n","{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"VP Cultural Communications\"\\nOutput:<|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>{\\'management_levels\\': [], \\'titles\\': [\\'VP of Cultural Communications\\', \\'Vice President of Cultural Communications\\']}<|eot_id|>'}\n","{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"Director Neural Implants\"\\nOutput:<|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>{\\'management_levels\\': [], \\'titles\\': [\\'Director of Neural Implants\\']}<|eot_id|>'}\n","{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"VP CRISPR Applications\"\\nOutput:<|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>{\\'management_levels\\': [], \\'titles\\': [\\'VP of CRISPR Applications\\', \\'Vice President of CRISPR Applications\\']}<|eot_id|>'}\n","{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"Find all CTOs, CFOs, and CMOs in AI startups.\"\\nOutput:<|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>{\\'management_levels\\': [], \\'titles\\': [\\'Chief Technology Officer\\', \\'CTO\\', \\'Chief Financial Officer\\', \\'CFO\\', \\'Chief Marketing Officer\\', \\'CMO\\']}<|eot_id|>'}\n","{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"Chief Human Potential Officer\"\\nOutput:<|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>{\\'management_levels\\': [], \\'titles\\': [\\'Chief Human Potential Officer\\', \\'CHPO\\']}<|eot_id|>'}\n","{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"Division chiefs in government\"\\nOutput:<|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>{\\'management_levels\\': [], \\'titles\\': [\\'Chief\\']}<|eot_id|>'}\n","{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"Executives in pharma and leaders in biotech.\"\\nOutput:<|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>{\\'management_levels\\': [\\'Executive and Sr. VP\\', \\'CSuite and President\\'], \\'titles\\': []}<|eot_id|>'}\n","{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"List board members of top banks in Europe.\"\\nOutput:<|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>{\\'management_levels\\': [\\'Board of Directors\\'], \\'titles\\': []}<|eot_id|>'}\n","{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"Chief Digital Transformation Officer\"\\nOutput:<|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>{\\'management_levels\\': [], \\'titles\\': [\\'Chief Digital Transformation Officer\\', \\'CDTO\\']}<|eot_id|>'}\n","{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"Director Climate Studies\"\\nOutput:<|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>{\\'management_levels\\': [], \\'titles\\': [\\'Director of Climate Studies\\']}<|eot_id|>'}\n","{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"VP Engineering & Architecture positions\"\\nOutput:<|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>{\\'management_levels\\': [], \\'titles\\': [\\'VP of Engineering and Architecture\\', \\'Vice President of Engineering and Architecture\\']}<|eot_id|>'}\n","{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"Find senior strategists in public policy organizations.\"\\nOutput:<|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>{\\'management_levels\\': [\\'Senior (Individual Contributor)\\'], \\'titles\\': [\\'Public Policy Strategist\\']}<|eot_id|>'}\n","{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"Director of Quantum Initiatives\"\\nOutput:<|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>{\\'management_levels\\': [], \\'titles\\': [\\'Director of Quantum Initiatives\\']}<|eot_id|>'}\n","{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"Find research assistants specializing in quantum computing.\"\\nOutput:<|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>{\\'management_levels\\': [], \\'titles\\': [\\'Research Assistant\\']}<|eot_id|>'}\n","{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"Head of AI/ML Research\"\\nOutput:<|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>{\\'management_levels\\': [], \\'titles\\': [\\'Head of AI/ML Research\\']}<|eot_id|>'}\n","{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"List all leaders in the construction sector.\"\\nOutput:<|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>{\\'management_levels\\': [\\'CSuite and President\\'], \\'titles\\': []}<|eot_id|>'}\n","{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"Leaders responsible for diversity and inclusion initiatives.\"\\nOutput:<|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>{\\'management_levels\\': [\\'CSuite and President\\', \\'Executive and Sr. VP\\'], \\'titles\\': [\\'Head of Diversity and Inclusion\\']}<|eot_id|>'}\n","{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"List interns contributing to social media campaigns.\"\\nOutput:<|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>{\\'management_levels\\': [\\'Intern\\'], \\'titles\\': []}<|eot_id|>'}\n","{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"Chief Mindfulness Officer\"\\nOutput:<|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>{\\'management_levels\\': [], \\'titles\\': [\\'Chief Mindfulness Officer\\', \\'CMO\\']}<|eot_id|>'}\n","{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"Chief Future Officer\"\\nOutput:<|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>{\\'management_levels\\': [], \\'titles\\': [\\'Chief Future Officer\\', \\'CFO\\']}<|eot_id|>'}\n","{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"Who leads the logistics team in FMCG companies?\"\\nOutput:<|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>{\\'management_levels\\': [\\'Director\\'], \\'titles\\': [\\'Director of Logistics\\']}<|eot_id|>'}\n","{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"Director Infrastructure Planning\"\\nOutput:<|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>{\\'management_levels\\': [], \\'titles\\': [\\'Director of Infrastructure Planning\\']}<|eot_id|>'}\n","{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"VP Ancient Studies\"\\nOutput:<|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>{\\'management_levels\\': [], \\'titles\\': [\\'VP of Ancient Studies\\', \\'Vice President of Ancient Studies\\']}<|eot_id|>'}\n","{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"Chief Marketing & Growth Officer\"\\nOutput:<|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>{\\'management_levels\\': [], \\'titles\\': [\\'Chief Marketing and Growth Officer\\']}<|eot_id|>'}\n","{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"Find assistant professors specializing in data science.\"\\nOutput:<|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>{\\'management_levels\\': [], \\'titles\\': [\\'Assistant Professor\\']}<|eot_id|>'}\n","{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"Find senior managers in manufacturing.\"\\nOutput:<|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>{\\'management_levels\\': [\\'Senior (Individual Contributor)\\', \\'Manager\\'], \\'titles\\': []}<|eot_id|>'}\n","{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"Executives in renewable energy\"\\nOutput:<|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>{\\'management_levels\\': [\\'Executive and Sr. VP\\'], \\'titles\\': []}<|eot_id|>'}\n","{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"Regional Director and Territory Manager positions\"\\nOutput:<|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>{\\'management_levels\\': [\\'Director\\', \\'Manager\\'], \\'titles\\': []}<|eot_id|>'}\n","{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"mid-level managers and senior managers in retail\"\\nOutput:<|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>{\\'management_levels\\': [\\'Mid (Individual Contributor)\\', \\'Manager\\'], \\'titles\\': []}<|eot_id|>'}\n","{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"List the interns involved in environmental policy research.\"\\nOutput:<|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>{\\'management_levels\\': [\\'Intern\\'], \\'titles\\': []}<|eot_id|>'}\n","{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"Head of Growth & VP Growth positions\"\\nOutput:<|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>{\\'management_levels\\': [], \\'titles\\': [\\'Head of Growth\\', \\'VP of Growth\\', \\'Vice President of Growth\\']}<|eot_id|>'}\n","{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"Chief Experience Officer positions\"\\nOutput:<|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>{\\'management_levels\\': [], \\'titles\\': [\\'Chief Experience Officer\\', \\'CXO\\']}<|eot_id|>'}\n","{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"Who leads the product innovation teams in tech startups?\"\\nOutput:<|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>{\\'management_levels\\': [\\'Director\\'], \\'titles\\': [\\'Director of Product Innovation\\']}<|eot_id|>'}\n","{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"Executives at global pharma companies.\"\\nOutput:<|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>{\\'management_levels\\': [\\'Executive and Sr. VP\\'], \\'titles\\': []}<|eot_id|>'}\n","{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"Chief Marketing Officer or VP Marketing roles in FAANG\"\\nOutput:<|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>{\\'management_levels\\': [], \\'titles\\': [\\'Chief Marketing Officer\\', \\'CMO\\', \\'VP of Marketing\\', \\'Vice President of Marketing\\']}<|eot_id|>'}\n","{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"VP Augmented Intelligence\"\\nOutput:<|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>{\\'management_levels\\': [], \\'titles\\': [\\'VP of Augmented Intelligence\\', \\'Vice President of Augmented Intelligence\\']}<|eot_id|>'}\n","{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"University President and Provost\"\\nOutput:<|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>{\\'management_levels\\': [\\'CSuite and President\\'], \\'titles\\': [\\'Provost\\']}<|eot_id|>'}\n","{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"List junior associates in investment banking teams.\"\\nOutput:<|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>{\\'management_levels\\': [\\'Junior\\'], \\'titles\\': [\\'Associate\\']}<|eot_id|>'}\n","{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"Chief Epidemiologist\"\\nOutput:<|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>{\\'management_levels\\': [], \\'titles\\': [\\'Chief Epidemiologist\\']}<|eot_id|>'}\n","{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"sr. vp global operations\"\\nOutput:<|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>{\\'management_levels\\': [\\'Executive and Sr. VP\\'], \\'titles\\': []}<|eot_id|>'}\n","{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"Find mid-level contributors in healthcare.\"\\nOutput:<|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>{\\'management_levels\\': [\\'Mid (Individual Contributor)\\'], \\'titles\\': []}<|eot_id|>'}\n","{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"List leaders or directors in environmental projects.\"\\nOutput:<|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>{\\'management_levels\\': [\\'CSuite and President\\', \\'Director\\'], \\'titles\\': []}<|eot_id|>'}\n","{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"Identify senior executives in fintech.\"\\nOutput:<|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>{\\'management_levels\\': [\\'Executive and Sr. VP\\'], \\'titles\\': []}<|eot_id|>'}\n","{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"Executives in fintech startups focusing on compliance.\"\\nOutput:<|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>{\\'management_levels\\': [\\'Executive and Sr. VP\\'], \\'titles\\': [\\'Chief Compliance Officer\\']}<|eot_id|>'}\n","{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"Chief Alternative Energy Officer\"\\nOutput:<|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>{\\'management_levels\\': [], \\'titles\\': [\\'Chief Alternative Energy Officer\\', \\'CAEO\\']}<|eot_id|>'}\n","{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"List board members in the banking sector.\"\\nOutput:<|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>{\\'management_levels\\': [\\'Board of Directors\\'], \\'titles\\': []}<|eot_id|>'}\n","{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"VP People Operations & Culture\"\\nOutput:<|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>{\\'management_levels\\': [], \\'titles\\': [\\'VP of People Operations and Culture\\', \\'Vice President of People Operations and Culture\\']}<|eot_id|>'}\n","{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an intelligent assistant dedicated to extracting management levels and job titles from user queries. Before doing so, you must understand what a functional area is.<|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\nDefinition of a Functional Area:\\n- A functional area is a department or group of personnel tasked with a specific organizational function. These include departments like finance, marketing, engineering, etc.\\n\\nDefinition of Management Level:\\n- A management level refers to a hierarchical position within an organization without a specific functional area. It encompasses broader titles that may include roles across different functional areas.\\n- Management levels include: \"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" and \"Junior.\"\\n\\nDefinition of a Job Title:\\n- A job title refers to a specific employment position combined with a functional area.\\n- Examples include \\'VP of Engineering\\' (functional area: Engineering) and \\'Director of Finance\\' (functional area: Finance).\\n\\nInstructions:\\n1. Management Levels: Only return management levels that match the predefined set: [\"Board of Directors,\" \"CSuite and President,\" \"Executive and Sr. VP,\" \"General Manager,\" \"VP,\" \"Director,\" \"Manager,\" \"Senior (Individual Contributor),\" \"Mid (Individual Contributor),\" \"Junior\"].\\n2. Job Titles: Normalize the job title after extracting it from the text. For example, convert \"ceo\" to \"Chief Executive Officer\" and include both the full title and its abbreviation if mentioned in the query, e.g., \"VP of Engineering\" and \"Vice President of Engineering.\"\\n3. Response Format: Your response must be a dictionary with two keys: \"management_levels\" and \"titles\". Each key should have a list of management levels and titles respectively.\\n4. If a keyword is classified as title, don\\'t include it in the management levels and vice versa. e.g if \"VP of Engineering\" is classified as title then don\\'t include \"VP\" in management levels.\\n\\nExample:\\nQuery: \"Provide a list of CFOs and VPs working in the technology sector\"\\nOutput: {\"management_levels\": [\"VP\"], \"titles\": [\"Chief Financial Officer\", \"CFO\"]}\\n\\nGuidelines:\\n- \"Leaders\" implies CSuite/President level\\n- Titles without functional areas (e.g., \"Founder\", \"Managing Director\") go in titles list\\n- Use knowledge base for educated guesses about classifications\\n\\nQuery: \"Director Quantum Biology\"\\nOutput:<|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>{\\'management_levels\\': [], \\'titles\\': [\\'Director of Quantum Biology\\']}<|eot_id|>'}\n"]}],"source":["for item in test_dataset:\n","    print(item)"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":597,"status":"ok","timestamp":1735811714218,"user":{"displayName":"Ali Raza","userId":"08516408430091031466"},"user_tz":-300},"id":"RZ8Ki3vHb9_F"},"outputs":[],"source":["dataset_dict = {\"train\": train_dataset,\n","                \"test\": eval_dataset}"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":529,"status":"ok","timestamp":1735811729791,"user":{"displayName":"Ali Raza","userId":"08516408430091031466"},"user_tz":-300},"id":"8l-bbKylcDjJ"},"outputs":[],"source":["raw_datasets = DatasetDict(dataset_dict)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1735811736422,"user":{"displayName":"Ali Raza","userId":"08516408430091031466"},"user_tz":-300},"id":"NklsshVGcQTT","outputId":"9bd16991-29dd-476d-97ac-bd0251a26ca7"},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['text'],\n","        num_rows: 577\n","    })\n","    test: Dataset({\n","        features: ['text'],\n","        num_rows: 63\n","    })\n","})"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["raw_datasets"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":304,"referenced_widgets":["dc47551a2c134381af1e94b7c736a357","38496c2096014bb182b6802726a6c086","2c51620748b8460aae4415897e3b464e","e3a6fdc329da4c078e3b2ac7a3bbbef1","b5bd78f99b52441e8bcdb21a6d9f3102","feaec0fccff045828af84bf58ce002df","7d57acf29422411c9ce7db5f62e35b59","eb52bc275ae946ac80d7bcd5f5b2f5a4","f4f968a603bd4a03a9f0c5aeaaafac69","e026252033394ebcbb965a8fd37053bf","e670541eb0ca4d4cb08b18176300793c","ab7aff5740fb48469ffc8c4db19696d6","6c0c3a855f41420fb5d22c76b9987603","403a7acbeb3947afa41d070c26405317","a9ef28aed5f94cef8aa7e4a4fdadb39e","1287988ad9c34b478f798e3e115c3a11","983768e254b143d1a50896a1756de2fe","021d9fefd4f44d9aa2c01c3ec63cdafb","9e53479a11894b4fbf7ca835eb070eba","48dcb3035dd44aaabdaf97a18f588813","fafd5e01a2c54e399ffdd01d5de30ff4","e470a1fa5f3840c58a17dd2e051c3db6","12a27aa8119d4000af8a039c528eedd8","46570a2fe95c4e82b4c44551c166f27e","36dfd5ec20124987a31a19fe2ff14861","cb0eb4832cb4446c8bf3087c63a082be","d82e30e6819e4ce1b6c250b9c7f703ff","26a30e8099504d2d9ee5364f45192e95","9eb5f26dbab447d683a2ec0266adc623","8e91f3e759194759824d8b90881674c2","8086b030aeb54e88b7bcd3b477409a5d","6717b4680eed4786bfd3ee5bf60595ec","cf698bce66ab4fffa7c97d0753fc49a7","418dd516d8fe48acb36d8e1669bc1a2b","7f5d3e9baf544ebb911bff3ad85028df","1acdc45992b147a395576115a13d21fe","764698493c274763995de1558a363891","2b96a571cf554509bc06fcecce2ecaf5","c1c805421c7e409f93f44bdf89d62db3","6cbad495963049fab25e22bb75f4ba28","dd78eb50c1bc42caaf122393286de01d","0a26ab4ea81e4d5aa2521b9d6dd11b39","45817db873d14496b8315ff3202c2085","75e1b4e4706047a28125b625e4c4667a","b248c17ffe5f4a1b875061fb7f7087fb","e7deaa0d282647be876890482d623908","2e5e1d8d14b34189bdc8a43deebc3315","6f2db1dfae4446598a94d8b53e3d4265","efbec3f178e74e93801570c7281bbaf4","17f4bd10c1f54bf781e7062dfda7a3c4","a2050d0434d6436ebd17e368b1d3f8e3","10ea66e01d6a44e3b2280e3362fd04fc","31b291a6e4d0405298a90ff18394a022","27a230a966fe4487a0820cc88a0b3c33","e6d26795de924ae58ac7a49b29d4aaa5"]},"executionInfo":{"elapsed":18150,"status":"ok","timestamp":1735812247566,"user":{"displayName":"Ali Raza","userId":"08516408430091031466"},"user_tz":-300},"id":"7xHAchIaeGDH","outputId":"a0cb332c-4994-458c-ca68-51b8acb45699"},"outputs":[],"source":["from transformers import AutoTokenizer\n","\n","model_name = \"/home/raza/Downloads/meta-llama-3-2-3B-Instruct\"\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","# set pad_token_id equal to the eos_token_id if not set\n","if tokenizer.pad_token_id is None:\n","  tokenizer.pad_token_id = tokenizer.eos_token_id\n","\n","# Set reasonable default for models without max length\n","if tokenizer.model_max_length > 100_000:\n","  tokenizer.model_max_length = 2048\n"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":627,"referenced_widgets":["9f325b15a0df4c62a0b3a4a38aff29f5","0b51b8cfb11c450cbea1981ec156d676","cc4e1df338bb4fa69cac3a89a08cd85b","bc97a7a1ed394598baab90438841d719","619d0c0ffa3c4235a310895389501176","e3f453f2b9c64e4e9b69bf87698cbb92","77be1ea8b2244a499e710b875eb2d988","3b5dfb8f46d248339023c48bbf1f7070","12dd6a65b0c64c73a9b224f0af33b49f","bd66add61d8b4ef59b328f64ac7bd882","d411270eed4a487a957f836011f1c1b3","5574de81969b463cafb998c950c44661","e357a60af21e4751ab236aac707fa043","b4c5f0a1cba84cf19680bdbf723fe583","a420922901f848ff9dc134d45b3ac8c3","c8ef8b0375814985ac4407a855db1388","8c8e4c0c6e064fc58a3623374e10fd48","bab5ac46b2cf4c038f5d1a6c6b1ba79a","d0c99c2bf07b40baabe759ebf1cd73f4","089c59f3538c487c991d0917fb6f78ee","25df39f8067f4ce5a9ebd46577b7e9c8","a975b6fe6d014f2cbd88d6b014d74fea"]},"executionInfo":{"elapsed":2692,"status":"error","timestamp":1735813590885,"user":{"displayName":"Ali Raza","userId":"08516408430091031466"},"user_tz":-300},"id":"5BgIX2dOcR9e","outputId":"9c58c1f5-fd9c-44e4-b29c-fb61e8ca2850"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d459fcbba7f542d8a8346b8dd0ee6568","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from transformers import BitsAndBytesConfig\n","import torch\n","from peft import LoraConfig, prepare_model_for_kbit_training, TaskType, PeftModel\n","from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer, set_seed\n","from transformers import AutoProcessor, DataCollatorForSeq2Seq, AutoTokenizer\n","from transformers import AutoModelForSeq2SeqLM, AutoModelForCausalLM\n","from transformers import AutoConfig, GenerationConfig\n","\n","# specify how to quantize the model\n","quantization_config = BitsAndBytesConfig(\n","            load_in_4bit=True,\n","            bnb_4bit_quant_type=\"nf4\",\n","            bnb_4bit_compute_dtype=torch.bfloat16,\n",")\n","device_map = {\"\": torch.cuda.current_device()} if torch.cuda.is_available() else None\n","\n","model_kwargs = dict(\n","    attn_implementation=\"flash_attention_2\", # set this to True if your GPU supports it (Flash Attention drastically speeds up model computations)\n","    torch_dtype=\"auto\",\n","    use_cache=False, # set to False as we're going to use gradient checkpointing\n","    device_map=device_map,\n","    quantization_config=quantization_config,\n",")\n","\n","processor = AutoTokenizer.from_pretrained(model_name)\n","processor.padding_side = 'right'\n","\n","# Set the padding token to be the same as eos_token if it's not defined\n","if processor.pad_token is None:\n","    processor.pad_token = processor.eos_token  # or you can set a custom token if needed\n","\n","\n","\n","\n","model = AutoModelForCausalLM.from_pretrained(\n","          model_name,\n","          trust_remote_code=True,\n","          attn_implementation=\"flash_attention_2\", # set this to True if your GPU supports it (Flash Attention drastically speeds up model computations)\n","          torch_dtype=\"auto\",\n","          use_cache=False, # set to False as we're going to use gradient checkpointing\n","          device_map=device_map,\n","          quantization_config=quantization_config,\n",")\n","\n","\n","\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["Generated Output: Once upon a time, in a bustling city, there was a beautiful and vibrant public park. The park was a hub of activity, with people from all walks of life coming to walk, jog, play games, or simply enjoy the scenery.\n"]}],"source":["def inference_function(input_text: str, max_length: int = 50):\n","    \"\"\"\n","    Simple inference function to generate text based on an input prompt.\n","\n","    Args:\n","    - input_text (str): The input text to be processed by the model.\n","    - max_length (int): The maximum length of the generated text.\n","\n","    Returns:\n","    - str: The generated text.\n","    \"\"\"\n","    # Process the input text\n","    inputs = processor(input_text, return_tensors=\"pt\", padding=True).to(model.device)\n","\n","    # Generate output from the model\n","    output = model.generate(\n","        **inputs,\n","        max_length=max_length,\n","        do_sample=True,  # Enable sampling for more diverse outputs\n","        temperature=1.0,\n","        top_p=0.9\n","    )\n","\n","    # Decode the output tokens into text\n","    generated_text = processor.decode(output[0], skip_special_tokens=True)  # Get the first sequence\n","\n","    return generated_text\n","\n","# Example usage\n","input_text = \"Once upon a time\"\n","generated_output = inference_function(input_text)\n","print(f\"Generated Output: {generated_output}\")\n"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["model = prepare_model_for_kbit_training(model)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["total_epochs = 15"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":216},"executionInfo":{"elapsed":24616,"status":"error","timestamp":1735813944510,"user":{"displayName":"Ali Raza","userId":"08516408430091031466"},"user_tz":-300},"id":"edmiudpZcjss","outputId":"c92704a9-a3ec-4260-f57b-2e2e57de2d89"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/raza/miniconda3/envs/finetuning_v2/lib/python3.9/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of  Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","/tmp/ipykernel_165834/1722739665.py:49: FutureWarning: `tokenizer` is deprecated and removed starting from version 0.16.0 for `SFTTrainer.__init__`. Use `processing_class` instead.\n","  trainer = SFTTrainer(\n","/home/raza/miniconda3/envs/finetuning_v2/lib/python3.9/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of  Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d43d060838584342b64c34ca39893ab6","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"eac5a3537e5a4744bbb567325cadbf01","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/577 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"37e0a0e868dc4943acc26108da597d10","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/63 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Using auto half precision backend\n"]}],"source":["from trl import SFTTrainer\n","from peft import LoraConfig\n","from transformers import TrainingArguments\n","\n","# path where the Trainer will save its checkpoints and logs\n","output_dir = './finetuned_llama3-2-3B_model'\n","\n","\n","# Adjusted TrainingArguments for 15 epochs and saving checkpoints every 2 epochs\n","training_args = TrainingArguments(\n","    fp16=True,  # Use mixed precision\n","    bf16=False,  # BF16 is generally for specific hardware; here, fp16 is better suited\n","    do_eval=True,\n","    eval_strategy=\"epoch\",  # Evaluate at the end of each epoch\n","    evaluation_strategy=\"epoch\",  # Ensure evaluation happens at every epoch\n","    gradient_accumulation_steps=4,  # Accumulate gradients to simulate a larger batch size\n","    gradient_checkpointing=True,  # Save memory during training\n","    gradient_checkpointing_kwargs={\"use_reentrant\": False},  # Optional, helps with stability\n","    learning_rate=2e-5,  # Low learning rate for fine-tuning\n","    log_level=\"info\",\n","    logging_steps=10,  # Log every 10 steps\n","    logging_strategy=\"steps\",\n","    lr_scheduler_type=\"cosine\",  # Use a cosine decay scheduler\n","    max_steps=-1,  # Train for the full number of epochs\n","    num_train_epochs=total_epochs,  # Fine-tune for 15 epochs\n","    output_dir=output_dir,  # Path where the model is saved\n","    overwrite_output_dir=True,  # Overwrite any existing model\n","    per_device_train_batch_size=4,  # Batch size of 4 (adjust if necessary)\n","    per_device_eval_batch_size=4,  # Eval batch size (use 2-4 depending on memory)\n","    push_to_hub=False,\n","    save_strategy=\"epoch\",  # Save model after each epoch\n","    save_steps=None,  # Disable saving based on steps (use epochs instead)\n","    save_total_limit=None,  # Limit the number of saved checkpoints (optional)\n","    seed=42,\n","    logging_dir=\"./logs\",  # Directory to store logs (TensorBoard)\n","    load_best_model_at_end=True,  # Load the best model based on validation loss\n",")\n","\n","# based on config\n","peft_config = LoraConfig(\n","    r=64,\n","    lora_alpha=16,\n","    lora_dropout=0.1,\n","    bias=\"none\",\n","    task_type=\"CAUSAL_LM\",\n","    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",")\n","\n","trainer = SFTTrainer(\n","    model=model_name,\n","    args=training_args,\n","    train_dataset=raw_datasets[\"train\"],\n","    eval_dataset=raw_datasets[\"test\"],\n","    tokenizer=processor,\n","    peft_config=peft_config,\n",")\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4RqzeQ_Wj8l7"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"elapsed":516,"status":"ok","timestamp":1735812871981,"user":{"displayName":"Ali Raza","userId":"08516408430091031466"},"user_tz":-300},"id":"68e7nPCderlT","outputId":"ac3d1d2a-f29f-4d43-be27-bbf9b5a73f6e"},"outputs":[],"source":["# from transformers import AutoTokenizer\n","# tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","# chat = [\n","#   {\"role\": \"system\", \"content\": \"You are a sentiment analysis agent\"},\n","#   {\"role\": \"user\", \"content\": \"Classify the following statement as Positive or Negative:\\nStatement: I am happy\"},\n","#   {\"role\": \"assistant\", \"content\": \"Positive\"},\n","# ]\n","\n","# tokenizer.apply_chat_template(chat, tokenize=False)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["import torch\n","torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["***** Running training *****\n","  Num examples = 577\n","  Num Epochs = 15\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 4\n","  Total optimization steps = 540\n","  Number of trainable parameters = 36,700,160\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e00e53c020e14813960f1adc68821669","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/540 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 2.4912, 'grad_norm': 0.28775086998939514, 'learning_rate': 1.9983081582712684e-05, 'epoch': 0.28}\n","{'loss': 2.3672, 'grad_norm': 0.31076881289482117, 'learning_rate': 1.9932383577419432e-05, 'epoch': 0.55}\n","{'loss': 2.2098, 'grad_norm': 0.3079773187637329, 'learning_rate': 1.9848077530122083e-05, 'epoch': 0.83}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 4\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6265b1a425784582ad0f74930afa16c6","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/16 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_llama3-2-3B_model/checkpoint-37\n","loading configuration file /home/raza/Downloads/meta-llama-3-2-3B-Instruct/config.json\n","Model config LlamaConfig {\n","  \"architectures\": [\n","    \"LlamaForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"bos_token_id\": 128000,\n","  \"eos_token_id\": [\n","    128001,\n","    128008,\n","    128009\n","  ],\n","  \"head_dim\": 128,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 131072,\n","  \"mlp_bias\": false,\n","  \"model_type\": \"llama\",\n","  \"num_attention_heads\": 24,\n","  \"num_hidden_layers\": 28,\n","  \"num_key_value_heads\": 8,\n","  \"pretraining_tp\": 1,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": {\n","    \"factor\": 32.0,\n","    \"high_freq_factor\": 4.0,\n","    \"low_freq_factor\": 1.0,\n","    \"original_max_position_embeddings\": 8192,\n","    \"rope_type\": \"llama3\"\n","  },\n","  \"rope_theta\": 500000.0,\n","  \"tie_word_embeddings\": true,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128256\n","}\n","\n","tokenizer config file saved in ./finetuned_llama3-2-3B_model/checkpoint-37/tokenizer_config.json\n","Special tokens file saved in ./finetuned_llama3-2-3B_model/checkpoint-37/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 2.0058774948120117, 'eval_runtime': 5.159, 'eval_samples_per_second': 12.212, 'eval_steps_per_second': 3.101, 'epoch': 1.0}\n","{'loss': 2.0477, 'grad_norm': 0.30620676279067993, 'learning_rate': 1.973044870579824e-05, 'epoch': 1.08}\n","{'loss': 1.8807, 'grad_norm': 0.287406861782074, 'learning_rate': 1.957989512315489e-05, 'epoch': 1.36}\n","{'loss': 1.7174, 'grad_norm': 0.3243946135044098, 'learning_rate': 1.9396926207859085e-05, 'epoch': 1.63}\n","{'loss': 1.5325, 'grad_norm': 0.35606786608695984, 'learning_rate': 1.9182161068802742e-05, 'epoch': 1.91}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 4\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"57bc05e3560b4e77801b911bd6250559","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/16 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_llama3-2-3B_model/checkpoint-74\n","loading configuration file /home/raza/Downloads/meta-llama-3-2-3B-Instruct/config.json\n","Model config LlamaConfig {\n","  \"architectures\": [\n","    \"LlamaForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"bos_token_id\": 128000,\n","  \"eos_token_id\": [\n","    128001,\n","    128008,\n","    128009\n","  ],\n","  \"head_dim\": 128,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 131072,\n","  \"mlp_bias\": false,\n","  \"model_type\": \"llama\",\n","  \"num_attention_heads\": 24,\n","  \"num_hidden_layers\": 28,\n","  \"num_key_value_heads\": 8,\n","  \"pretraining_tp\": 1,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": {\n","    \"factor\": 32.0,\n","    \"high_freq_factor\": 4.0,\n","    \"low_freq_factor\": 1.0,\n","    \"original_max_position_embeddings\": 8192,\n","    \"rope_type\": \"llama3\"\n","  },\n","  \"rope_theta\": 500000.0,\n","  \"tie_word_embeddings\": true,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128256\n","}\n","\n","tokenizer config file saved in ./finetuned_llama3-2-3B_model/checkpoint-74/tokenizer_config.json\n","Special tokens file saved in ./finetuned_llama3-2-3B_model/checkpoint-74/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 1.3275282382965088, 'eval_runtime': 5.2654, 'eval_samples_per_second': 11.965, 'eval_steps_per_second': 3.039, 'epoch': 2.0}\n","{'loss': 1.3094, 'grad_norm': 0.4378772974014282, 'learning_rate': 1.8936326403234125e-05, 'epoch': 2.17}\n","{'loss': 1.048, 'grad_norm': 0.48989933729171753, 'learning_rate': 1.866025403784439e-05, 'epoch': 2.44}\n","{'loss': 0.7709, 'grad_norm': 0.4631698429584503, 'learning_rate': 1.8354878114129368e-05, 'epoch': 2.72}\n","{'loss': 0.5312, 'grad_norm': 0.370974063873291, 'learning_rate': 1.802123192755044e-05, 'epoch': 2.99}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 4\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a26f2273da5241ed9f0e316ebabcb81a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/16 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_llama3-2-3B_model/checkpoint-111\n","loading configuration file /home/raza/Downloads/meta-llama-3-2-3B-Instruct/config.json\n","Model config LlamaConfig {\n","  \"architectures\": [\n","    \"LlamaForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"bos_token_id\": 128000,\n","  \"eos_token_id\": [\n","    128001,\n","    128008,\n","    128009\n","  ],\n","  \"head_dim\": 128,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 131072,\n","  \"mlp_bias\": false,\n","  \"model_type\": \"llama\",\n","  \"num_attention_heads\": 24,\n","  \"num_hidden_layers\": 28,\n","  \"num_key_value_heads\": 8,\n","  \"pretraining_tp\": 1,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": {\n","    \"factor\": 32.0,\n","    \"high_freq_factor\": 4.0,\n","    \"low_freq_factor\": 1.0,\n","    \"original_max_position_embeddings\": 8192,\n","    \"rope_type\": \"llama3\"\n","  },\n","  \"rope_theta\": 500000.0,\n","  \"tie_word_embeddings\": true,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128256\n","}\n","\n","tokenizer config file saved in ./finetuned_llama3-2-3B_model/checkpoint-111/tokenizer_config.json\n","Special tokens file saved in ./finetuned_llama3-2-3B_model/checkpoint-111/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.4123690724372864, 'eval_runtime': 5.1761, 'eval_samples_per_second': 12.171, 'eval_steps_per_second': 3.091, 'epoch': 3.0}\n","{'loss': 0.368, 'grad_norm': 0.23368079960346222, 'learning_rate': 1.766044443118978e-05, 'epoch': 3.25}\n","{'loss': 0.2941, 'grad_norm': 0.17825289070606232, 'learning_rate': 1.7273736415730488e-05, 'epoch': 3.52}\n","{'loss': 0.2473, 'grad_norm': 0.13374724984169006, 'learning_rate': 1.686241637868734e-05, 'epoch': 3.8}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 4\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2f48181db33a45019f7e666db688b149","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/16 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_llama3-2-3B_model/checkpoint-148\n","loading configuration file /home/raza/Downloads/meta-llama-3-2-3B-Instruct/config.json\n","Model config LlamaConfig {\n","  \"architectures\": [\n","    \"LlamaForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"bos_token_id\": 128000,\n","  \"eos_token_id\": [\n","    128001,\n","    128008,\n","    128009\n","  ],\n","  \"head_dim\": 128,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 131072,\n","  \"mlp_bias\": false,\n","  \"model_type\": \"llama\",\n","  \"num_attention_heads\": 24,\n","  \"num_hidden_layers\": 28,\n","  \"num_key_value_heads\": 8,\n","  \"pretraining_tp\": 1,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": {\n","    \"factor\": 32.0,\n","    \"high_freq_factor\": 4.0,\n","    \"low_freq_factor\": 1.0,\n","    \"original_max_position_embeddings\": 8192,\n","    \"rope_type\": \"llama3\"\n","  },\n","  \"rope_theta\": 500000.0,\n","  \"tie_word_embeddings\": true,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128256\n","}\n","\n","tokenizer config file saved in ./finetuned_llama3-2-3B_model/checkpoint-148/tokenizer_config.json\n","Special tokens file saved in ./finetuned_llama3-2-3B_model/checkpoint-148/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.20817050337791443, 'eval_runtime': 5.1649, 'eval_samples_per_second': 12.198, 'eval_steps_per_second': 3.098, 'epoch': 4.0}\n","{'loss': 0.2139, 'grad_norm': 0.10989093035459518, 'learning_rate': 1.6427876096865394e-05, 'epoch': 4.06}\n","{'loss': 0.1953, 'grad_norm': 0.1177702322602272, 'learning_rate': 1.5971585917027864e-05, 'epoch': 4.33}\n","{'loss': 0.1811, 'grad_norm': 0.10799044370651245, 'learning_rate': 1.5495089780708062e-05, 'epoch': 4.61}\n","{'loss': 0.1553, 'grad_norm': 0.1283911019563675, 'learning_rate': 1.5000000000000002e-05, 'epoch': 4.88}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 4\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aedfcddf39214c3f9836395e5abf1629","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/16 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_llama3-2-3B_model/checkpoint-185\n","loading configuration file /home/raza/Downloads/meta-llama-3-2-3B-Instruct/config.json\n","Model config LlamaConfig {\n","  \"architectures\": [\n","    \"LlamaForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"bos_token_id\": 128000,\n","  \"eos_token_id\": [\n","    128001,\n","    128008,\n","    128009\n","  ],\n","  \"head_dim\": 128,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 131072,\n","  \"mlp_bias\": false,\n","  \"model_type\": \"llama\",\n","  \"num_attention_heads\": 24,\n","  \"num_hidden_layers\": 28,\n","  \"num_key_value_heads\": 8,\n","  \"pretraining_tp\": 1,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": {\n","    \"factor\": 32.0,\n","    \"high_freq_factor\": 4.0,\n","    \"low_freq_factor\": 1.0,\n","    \"original_max_position_embeddings\": 8192,\n","    \"rope_type\": \"llama3\"\n","  },\n","  \"rope_theta\": 500000.0,\n","  \"tie_word_embeddings\": true,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128256\n","}\n","\n","tokenizer config file saved in ./finetuned_llama3-2-3B_model/checkpoint-185/tokenizer_config.json\n","Special tokens file saved in ./finetuned_llama3-2-3B_model/checkpoint-185/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.13099165260791779, 'eval_runtime': 4.7212, 'eval_samples_per_second': 13.344, 'eval_steps_per_second': 3.389, 'epoch': 5.0}\n","{'loss': 0.1311, 'grad_norm': 0.099880151450634, 'learning_rate': 1.4487991802004625e-05, 'epoch': 5.14}\n","{'loss': 0.119, 'grad_norm': 0.0628439262509346, 'learning_rate': 1.396079766039157e-05, 'epoch': 5.41}\n","{'loss': 0.1131, 'grad_norm': 0.054415322840213776, 'learning_rate': 1.342020143325669e-05, 'epoch': 5.69}\n","{'loss': 0.1082, 'grad_norm': 0.049315936863422394, 'learning_rate': 1.2868032327110904e-05, 'epoch': 5.97}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 4\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"51ac722fc05747f2b39afe912ea5796e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/16 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_llama3-2-3B_model/checkpoint-222\n","loading configuration file /home/raza/Downloads/meta-llama-3-2-3B-Instruct/config.json\n","Model config LlamaConfig {\n","  \"architectures\": [\n","    \"LlamaForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"bos_token_id\": 128000,\n","  \"eos_token_id\": [\n","    128001,\n","    128008,\n","    128009\n","  ],\n","  \"head_dim\": 128,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 131072,\n","  \"mlp_bias\": false,\n","  \"model_type\": \"llama\",\n","  \"num_attention_heads\": 24,\n","  \"num_hidden_layers\": 28,\n","  \"num_key_value_heads\": 8,\n","  \"pretraining_tp\": 1,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": {\n","    \"factor\": 32.0,\n","    \"high_freq_factor\": 4.0,\n","    \"low_freq_factor\": 1.0,\n","    \"original_max_position_embeddings\": 8192,\n","    \"rope_type\": \"llama3\"\n","  },\n","  \"rope_theta\": 500000.0,\n","  \"tie_word_embeddings\": true,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128256\n","}\n","\n","tokenizer config file saved in ./finetuned_llama3-2-3B_model/checkpoint-222/tokenizer_config.json\n","Special tokens file saved in ./finetuned_llama3-2-3B_model/checkpoint-222/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.10942086577415466, 'eval_runtime': 4.7179, 'eval_samples_per_second': 13.353, 'eval_steps_per_second': 3.391, 'epoch': 6.0}\n","{'loss': 0.109, 'grad_norm': 0.07325206696987152, 'learning_rate': 1.2306158707424402e-05, 'epoch': 6.22}\n","{'loss': 0.1026, 'grad_norm': 0.050754375755786896, 'learning_rate': 1.1736481776669307e-05, 'epoch': 6.5}\n","{'loss': 0.1075, 'grad_norm': 0.07395963370800018, 'learning_rate': 1.1160929141252303e-05, 'epoch': 6.77}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 4\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c407b2e97b8648448d6d3b3c27c0e971","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/16 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_llama3-2-3B_model/checkpoint-259\n","loading configuration file /home/raza/Downloads/meta-llama-3-2-3B-Instruct/config.json\n","Model config LlamaConfig {\n","  \"architectures\": [\n","    \"LlamaForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"bos_token_id\": 128000,\n","  \"eos_token_id\": [\n","    128001,\n","    128008,\n","    128009\n","  ],\n","  \"head_dim\": 128,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 131072,\n","  \"mlp_bias\": false,\n","  \"model_type\": \"llama\",\n","  \"num_attention_heads\": 24,\n","  \"num_hidden_layers\": 28,\n","  \"num_key_value_heads\": 8,\n","  \"pretraining_tp\": 1,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": {\n","    \"factor\": 32.0,\n","    \"high_freq_factor\": 4.0,\n","    \"low_freq_factor\": 1.0,\n","    \"original_max_position_embeddings\": 8192,\n","    \"rope_type\": \"llama3\"\n","  },\n","  \"rope_theta\": 500000.0,\n","  \"tie_word_embeddings\": true,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128256\n","}\n","\n","tokenizer config file saved in ./finetuned_llama3-2-3B_model/checkpoint-259/tokenizer_config.json\n","Special tokens file saved in ./finetuned_llama3-2-3B_model/checkpoint-259/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.1034022867679596, 'eval_runtime': 4.6993, 'eval_samples_per_second': 13.406, 'eval_steps_per_second': 3.405, 'epoch': 7.0}\n","{'loss': 0.112, 'grad_norm': 0.05523417890071869, 'learning_rate': 1.0581448289104759e-05, 'epoch': 7.03}\n","{'loss': 0.097, 'grad_norm': 0.052267350256443024, 'learning_rate': 1e-05, 'epoch': 7.3}\n","{'loss': 0.1038, 'grad_norm': 0.05608953908085823, 'learning_rate': 9.418551710895243e-06, 'epoch': 7.58}\n","{'loss': 0.1042, 'grad_norm': 0.04649007320404053, 'learning_rate': 8.839070858747697e-06, 'epoch': 7.86}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 4\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5efa53038bbf442da190f8b2bb8c12c8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/16 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_llama3-2-3B_model/checkpoint-296\n","loading configuration file /home/raza/Downloads/meta-llama-3-2-3B-Instruct/config.json\n","Model config LlamaConfig {\n","  \"architectures\": [\n","    \"LlamaForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"bos_token_id\": 128000,\n","  \"eos_token_id\": [\n","    128001,\n","    128008,\n","    128009\n","  ],\n","  \"head_dim\": 128,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 131072,\n","  \"mlp_bias\": false,\n","  \"model_type\": \"llama\",\n","  \"num_attention_heads\": 24,\n","  \"num_hidden_layers\": 28,\n","  \"num_key_value_heads\": 8,\n","  \"pretraining_tp\": 1,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": {\n","    \"factor\": 32.0,\n","    \"high_freq_factor\": 4.0,\n","    \"low_freq_factor\": 1.0,\n","    \"original_max_position_embeddings\": 8192,\n","    \"rope_type\": \"llama3\"\n","  },\n","  \"rope_theta\": 500000.0,\n","  \"tie_word_embeddings\": true,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128256\n","}\n","\n","tokenizer config file saved in ./finetuned_llama3-2-3B_model/checkpoint-296/tokenizer_config.json\n","Special tokens file saved in ./finetuned_llama3-2-3B_model/checkpoint-296/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.10087685286998749, 'eval_runtime': 4.7009, 'eval_samples_per_second': 13.402, 'eval_steps_per_second': 3.404, 'epoch': 8.0}\n","{'loss': 0.1031, 'grad_norm': 0.04357268288731575, 'learning_rate': 8.263518223330698e-06, 'epoch': 8.11}\n","{'loss': 0.0963, 'grad_norm': 0.048526618629693985, 'learning_rate': 7.6938412925756e-06, 'epoch': 8.39}\n","{'loss': 0.0996, 'grad_norm': 0.0437864288687706, 'learning_rate': 7.131967672889101e-06, 'epoch': 8.66}\n","{'loss': 0.1033, 'grad_norm': 0.05747843533754349, 'learning_rate': 6.579798566743314e-06, 'epoch': 8.94}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 4\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f1decd2dde2445f2a33cd2cf39204a02","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/16 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_llama3-2-3B_model/checkpoint-333\n","loading configuration file /home/raza/Downloads/meta-llama-3-2-3B-Instruct/config.json\n","Model config LlamaConfig {\n","  \"architectures\": [\n","    \"LlamaForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"bos_token_id\": 128000,\n","  \"eos_token_id\": [\n","    128001,\n","    128008,\n","    128009\n","  ],\n","  \"head_dim\": 128,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 131072,\n","  \"mlp_bias\": false,\n","  \"model_type\": \"llama\",\n","  \"num_attention_heads\": 24,\n","  \"num_hidden_layers\": 28,\n","  \"num_key_value_heads\": 8,\n","  \"pretraining_tp\": 1,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": {\n","    \"factor\": 32.0,\n","    \"high_freq_factor\": 4.0,\n","    \"low_freq_factor\": 1.0,\n","    \"original_max_position_embeddings\": 8192,\n","    \"rope_type\": \"llama3\"\n","  },\n","  \"rope_theta\": 500000.0,\n","  \"tie_word_embeddings\": true,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128256\n","}\n","\n","tokenizer config file saved in ./finetuned_llama3-2-3B_model/checkpoint-333/tokenizer_config.json\n","Special tokens file saved in ./finetuned_llama3-2-3B_model/checkpoint-333/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.09970598667860031, 'eval_runtime': 4.7015, 'eval_samples_per_second': 13.4, 'eval_steps_per_second': 3.403, 'epoch': 9.0}\n","{'loss': 0.0988, 'grad_norm': 0.052400071173906326, 'learning_rate': 6.039202339608432e-06, 'epoch': 9.19}\n","{'loss': 0.0972, 'grad_norm': 0.049836497753858566, 'learning_rate': 5.512008197995379e-06, 'epoch': 9.47}\n","{'loss': 0.0977, 'grad_norm': 0.048214539885520935, 'learning_rate': 5.000000000000003e-06, 'epoch': 9.74}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 4\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.0997, 'grad_norm': 0.12826083600521088, 'learning_rate': 4.504910219291941e-06, 'epoch': 10.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8ece868ac8a64ff1b2c552c31bd69b22","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/16 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_llama3-2-3B_model/checkpoint-370\n","loading configuration file /home/raza/Downloads/meta-llama-3-2-3B-Instruct/config.json\n","Model config LlamaConfig {\n","  \"architectures\": [\n","    \"LlamaForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"bos_token_id\": 128000,\n","  \"eos_token_id\": [\n","    128001,\n","    128008,\n","    128009\n","  ],\n","  \"head_dim\": 128,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 131072,\n","  \"mlp_bias\": false,\n","  \"model_type\": \"llama\",\n","  \"num_attention_heads\": 24,\n","  \"num_hidden_layers\": 28,\n","  \"num_key_value_heads\": 8,\n","  \"pretraining_tp\": 1,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": {\n","    \"factor\": 32.0,\n","    \"high_freq_factor\": 4.0,\n","    \"low_freq_factor\": 1.0,\n","    \"original_max_position_embeddings\": 8192,\n","    \"rope_type\": \"llama3\"\n","  },\n","  \"rope_theta\": 500000.0,\n","  \"tie_word_embeddings\": true,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128256\n","}\n","\n","tokenizer config file saved in ./finetuned_llama3-2-3B_model/checkpoint-370/tokenizer_config.json\n","Special tokens file saved in ./finetuned_llama3-2-3B_model/checkpoint-370/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.09909076243638992, 'eval_runtime': 4.6973, 'eval_samples_per_second': 13.412, 'eval_steps_per_second': 3.406, 'epoch': 10.0}\n","{'loss': 0.0978, 'grad_norm': 0.046093929558992386, 'learning_rate': 4.028414082972141e-06, 'epoch': 10.28}\n","{'loss': 0.0953, 'grad_norm': 0.05652180314064026, 'learning_rate': 3.5721239031346067e-06, 'epoch': 10.55}\n","{'loss': 0.1011, 'grad_norm': 0.04933388531208038, 'learning_rate': 3.1375836213126653e-06, 'epoch': 10.83}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 4\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5f136618cfe94e1299d89cd481d6003a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/16 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_llama3-2-3B_model/checkpoint-407\n","loading configuration file /home/raza/Downloads/meta-llama-3-2-3B-Instruct/config.json\n","Model config LlamaConfig {\n","  \"architectures\": [\n","    \"LlamaForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"bos_token_id\": 128000,\n","  \"eos_token_id\": [\n","    128001,\n","    128008,\n","    128009\n","  ],\n","  \"head_dim\": 128,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 131072,\n","  \"mlp_bias\": false,\n","  \"model_type\": \"llama\",\n","  \"num_attention_heads\": 24,\n","  \"num_hidden_layers\": 28,\n","  \"num_key_value_heads\": 8,\n","  \"pretraining_tp\": 1,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": {\n","    \"factor\": 32.0,\n","    \"high_freq_factor\": 4.0,\n","    \"low_freq_factor\": 1.0,\n","    \"original_max_position_embeddings\": 8192,\n","    \"rope_type\": \"llama3\"\n","  },\n","  \"rope_theta\": 500000.0,\n","  \"tie_word_embeddings\": true,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128256\n","}\n","\n","tokenizer config file saved in ./finetuned_llama3-2-3B_model/checkpoint-407/tokenizer_config.json\n","Special tokens file saved in ./finetuned_llama3-2-3B_model/checkpoint-407/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.09870133548974991, 'eval_runtime': 4.6989, 'eval_samples_per_second': 13.408, 'eval_steps_per_second': 3.405, 'epoch': 11.0}\n","{'loss': 0.0985, 'grad_norm': 0.04898371174931526, 'learning_rate': 2.726263584269513e-06, 'epoch': 11.08}\n","{'loss': 0.0975, 'grad_norm': 0.049494918435811996, 'learning_rate': 2.339555568810221e-06, 'epoch': 11.36}\n","{'loss': 0.0956, 'grad_norm': 0.04310060292482376, 'learning_rate': 1.9787680724495617e-06, 'epoch': 11.63}\n","{'loss': 0.0979, 'grad_norm': 0.06262964010238647, 'learning_rate': 1.6451218858706374e-06, 'epoch': 11.91}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 4\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"712c2c11c5a143d9a3281ab9821a1cd6","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/16 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_llama3-2-3B_model/checkpoint-444\n","loading configuration file /home/raza/Downloads/meta-llama-3-2-3B-Instruct/config.json\n","Model config LlamaConfig {\n","  \"architectures\": [\n","    \"LlamaForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"bos_token_id\": 128000,\n","  \"eos_token_id\": [\n","    128001,\n","    128008,\n","    128009\n","  ],\n","  \"head_dim\": 128,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 131072,\n","  \"mlp_bias\": false,\n","  \"model_type\": \"llama\",\n","  \"num_attention_heads\": 24,\n","  \"num_hidden_layers\": 28,\n","  \"num_key_value_heads\": 8,\n","  \"pretraining_tp\": 1,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": {\n","    \"factor\": 32.0,\n","    \"high_freq_factor\": 4.0,\n","    \"low_freq_factor\": 1.0,\n","    \"original_max_position_embeddings\": 8192,\n","    \"rope_type\": \"llama3\"\n","  },\n","  \"rope_theta\": 500000.0,\n","  \"tie_word_embeddings\": true,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128256\n","}\n","\n","tokenizer config file saved in ./finetuned_llama3-2-3B_model/checkpoint-444/tokenizer_config.json\n","Special tokens file saved in ./finetuned_llama3-2-3B_model/checkpoint-444/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.0984833613038063, 'eval_runtime': 4.6983, 'eval_samples_per_second': 13.409, 'eval_steps_per_second': 3.406, 'epoch': 12.0}\n","{'loss': 0.1004, 'grad_norm': 0.048556938767433167, 'learning_rate': 1.339745962155613e-06, 'epoch': 12.17}\n","{'loss': 0.0996, 'grad_norm': 0.05056541785597801, 'learning_rate': 1.0636735967658785e-06, 'epoch': 12.44}\n","{'loss': 0.0999, 'grad_norm': 0.04356081783771515, 'learning_rate': 8.178389311972612e-07, 'epoch': 12.72}\n","{'loss': 0.0939, 'grad_norm': 0.05319838970899582, 'learning_rate': 6.030737921409169e-07, 'epoch': 12.99}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 4\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d53b70638495459a82baf17100a8bf72","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/16 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_llama3-2-3B_model/checkpoint-481\n","loading configuration file /home/raza/Downloads/meta-llama-3-2-3B-Instruct/config.json\n","Model config LlamaConfig {\n","  \"architectures\": [\n","    \"LlamaForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"bos_token_id\": 128000,\n","  \"eos_token_id\": [\n","    128001,\n","    128008,\n","    128009\n","  ],\n","  \"head_dim\": 128,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 131072,\n","  \"mlp_bias\": false,\n","  \"model_type\": \"llama\",\n","  \"num_attention_heads\": 24,\n","  \"num_hidden_layers\": 28,\n","  \"num_key_value_heads\": 8,\n","  \"pretraining_tp\": 1,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": {\n","    \"factor\": 32.0,\n","    \"high_freq_factor\": 4.0,\n","    \"low_freq_factor\": 1.0,\n","    \"original_max_position_embeddings\": 8192,\n","    \"rope_type\": \"llama3\"\n","  },\n","  \"rope_theta\": 500000.0,\n","  \"tie_word_embeddings\": true,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128256\n","}\n","\n","tokenizer config file saved in ./finetuned_llama3-2-3B_model/checkpoint-481/tokenizer_config.json\n","Special tokens file saved in ./finetuned_llama3-2-3B_model/checkpoint-481/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.09837163239717484, 'eval_runtime': 4.6993, 'eval_samples_per_second': 13.406, 'eval_steps_per_second': 3.405, 'epoch': 13.0}\n","{'loss': 0.1024, 'grad_norm': 0.07585842162370682, 'learning_rate': 4.2010487684511105e-07, 'epoch': 13.25}\n","{'loss': 0.0966, 'grad_norm': 0.046450987458229065, 'learning_rate': 2.6955129420176193e-07, 'epoch': 13.52}\n","{'loss': 0.0966, 'grad_norm': 0.05601801723241806, 'learning_rate': 1.519224698779198e-07, 'epoch': 13.8}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 4\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9740f112500444888ec9db8417af5cdd","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/16 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_llama3-2-3B_model/checkpoint-518\n","loading configuration file /home/raza/Downloads/meta-llama-3-2-3B-Instruct/config.json\n","Model config LlamaConfig {\n","  \"architectures\": [\n","    \"LlamaForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"bos_token_id\": 128000,\n","  \"eos_token_id\": [\n","    128001,\n","    128008,\n","    128009\n","  ],\n","  \"head_dim\": 128,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 131072,\n","  \"mlp_bias\": false,\n","  \"model_type\": \"llama\",\n","  \"num_attention_heads\": 24,\n","  \"num_hidden_layers\": 28,\n","  \"num_key_value_heads\": 8,\n","  \"pretraining_tp\": 1,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": {\n","    \"factor\": 32.0,\n","    \"high_freq_factor\": 4.0,\n","    \"low_freq_factor\": 1.0,\n","    \"original_max_position_embeddings\": 8192,\n","    \"rope_type\": \"llama3\"\n","  },\n","  \"rope_theta\": 500000.0,\n","  \"tie_word_embeddings\": true,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128256\n","}\n","\n","tokenizer config file saved in ./finetuned_llama3-2-3B_model/checkpoint-518/tokenizer_config.json\n","Special tokens file saved in ./finetuned_llama3-2-3B_model/checkpoint-518/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.09833750128746033, 'eval_runtime': 4.7011, 'eval_samples_per_second': 13.401, 'eval_steps_per_second': 3.403, 'epoch': 14.0}\n","{'loss': 0.1006, 'grad_norm': 0.050159674137830734, 'learning_rate': 6.761642258056977e-08, 'epoch': 14.06}\n","{'loss': 0.0961, 'grad_norm': 0.04582798480987549, 'learning_rate': 1.6918417287318245e-08, 'epoch': 14.33}\n"]},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_llama3-2-3B_model/checkpoint-540\n","loading configuration file /home/raza/Downloads/meta-llama-3-2-3B-Instruct/config.json\n","Model config LlamaConfig {\n","  \"architectures\": [\n","    \"LlamaForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"bos_token_id\": 128000,\n","  \"eos_token_id\": [\n","    128001,\n","    128008,\n","    128009\n","  ],\n","  \"head_dim\": 128,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 131072,\n","  \"mlp_bias\": false,\n","  \"model_type\": \"llama\",\n","  \"num_attention_heads\": 24,\n","  \"num_hidden_layers\": 28,\n","  \"num_key_value_heads\": 8,\n","  \"pretraining_tp\": 1,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": {\n","    \"factor\": 32.0,\n","    \"high_freq_factor\": 4.0,\n","    \"low_freq_factor\": 1.0,\n","    \"original_max_position_embeddings\": 8192,\n","    \"rope_type\": \"llama3\"\n","  },\n","  \"rope_theta\": 500000.0,\n","  \"tie_word_embeddings\": true,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128256\n","}\n","\n","tokenizer config file saved in ./finetuned_llama3-2-3B_model/checkpoint-540/tokenizer_config.json\n","Special tokens file saved in ./finetuned_llama3-2-3B_model/checkpoint-540/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.0961, 'grad_norm': 0.04443378746509552, 'learning_rate': 0.0, 'epoch': 14.61}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 4\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f6b3ba08c594430ab9334cb1f09ae158","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/16 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_llama3-2-3B_model/checkpoint-540\n","loading configuration file /home/raza/Downloads/meta-llama-3-2-3B-Instruct/config.json\n","Model config LlamaConfig {\n","  \"architectures\": [\n","    \"LlamaForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"bos_token_id\": 128000,\n","  \"eos_token_id\": [\n","    128001,\n","    128008,\n","    128009\n","  ],\n","  \"head_dim\": 128,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 131072,\n","  \"mlp_bias\": false,\n","  \"model_type\": \"llama\",\n","  \"num_attention_heads\": 24,\n","  \"num_hidden_layers\": 28,\n","  \"num_key_value_heads\": 8,\n","  \"pretraining_tp\": 1,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": {\n","    \"factor\": 32.0,\n","    \"high_freq_factor\": 4.0,\n","    \"low_freq_factor\": 1.0,\n","    \"original_max_position_embeddings\": 8192,\n","    \"rope_type\": \"llama3\"\n","  },\n","  \"rope_theta\": 500000.0,\n","  \"tie_word_embeddings\": true,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128256\n","}\n","\n","tokenizer config file saved in ./finetuned_llama3-2-3B_model/checkpoint-540/tokenizer_config.json\n","Special tokens file saved in ./finetuned_llama3-2-3B_model/checkpoint-540/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.09833656251430511, 'eval_runtime': 4.6998, 'eval_samples_per_second': 13.405, 'eval_steps_per_second': 3.404, 'epoch': 14.61}\n"]},{"name":"stderr","output_type":"stream","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from ./finetuned_llama3-2-3B_model/checkpoint-540 (score: 0.09833656251430511).\n"]},{"name":"stdout","output_type":"stream","text":["{'train_runtime': 2147.4783, 'train_samples_per_second': 4.03, 'train_steps_per_second': 0.251, 'train_loss': 0.43018975059191383, 'epoch': 14.61}\n"]}],"source":["trainer_result = trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":15,"metadata":{"id":"ZferjgPignJo"},"outputs":[{"name":"stderr","output_type":"stream","text":["***** Running training *****\n","  Num examples = 577\n","  Num Epochs = 50\n","  Instantaneous batch size per device = 2\n","  Total train batch size (w. parallel, distributed & accumulation) = 4\n","  Gradient Accumulation steps = 2\n","  Total optimization steps = 7,200\n","  Number of trainable parameters = 12,582,912\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f88754079f13455896dbafa1983d904f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/7200 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 1.4911, 'grad_norm': 0.04986097291111946, 'learning_rate': 1.999997620177352e-05, 'epoch': 0.03}\n","{'loss': 1.4963, 'grad_norm': 0.05934108793735504, 'learning_rate': 1.9999904807207348e-05, 'epoch': 0.07}\n","{'loss': 1.4869, 'grad_norm': 0.0683630183339119, 'learning_rate': 1.9999785816641293e-05, 'epoch': 0.1}\n","{'loss': 1.4842, 'grad_norm': 0.07281941920518875, 'learning_rate': 1.9999619230641714e-05, 'epoch': 0.14}\n","{'loss': 1.465, 'grad_norm': 0.06812652945518494, 'learning_rate': 1.99994050500015e-05, 'epoch': 0.17}\n","{'loss': 1.4492, 'grad_norm': 0.06429293751716614, 'learning_rate': 1.999914327574007e-05, 'epoch': 0.21}\n","{'loss': 1.4394, 'grad_norm': 0.06659349054098129, 'learning_rate': 1.9998833909103385e-05, 'epoch': 0.24}\n","{'loss': 1.4123, 'grad_norm': 0.07142454385757446, 'learning_rate': 1.9998476951563914e-05, 'epoch': 0.28}\n","{'loss': 1.3984, 'grad_norm': 0.07648936659097672, 'learning_rate': 1.9998072404820648e-05, 'epoch': 0.31}\n","{'loss': 1.3829, 'grad_norm': 0.08149431645870209, 'learning_rate': 1.999762027079909e-05, 'epoch': 0.35}\n","{'loss': 1.3619, 'grad_norm': 0.08587559312582016, 'learning_rate': 1.999712055165124e-05, 'epoch': 0.38}\n","{'loss': 1.3346, 'grad_norm': 0.08927130699157715, 'learning_rate': 1.9996573249755573e-05, 'epoch': 0.42}\n","{'loss': 1.3053, 'grad_norm': 0.09365545958280563, 'learning_rate': 1.9995978367717063e-05, 'epoch': 0.45}\n","{'loss': 1.2854, 'grad_norm': 0.09901823103427887, 'learning_rate': 1.9995335908367132e-05, 'epoch': 0.48}\n","{'loss': 1.2545, 'grad_norm': 0.10576246678829193, 'learning_rate': 1.9994645874763657e-05, 'epoch': 0.52}\n","{'loss': 1.2201, 'grad_norm': 0.11140930652618408, 'learning_rate': 1.999390827019096e-05, 'epoch': 0.55}\n","{'loss': 1.1894, 'grad_norm': 0.11620467901229858, 'learning_rate': 1.999312309815977e-05, 'epoch': 0.59}\n","{'loss': 1.1516, 'grad_norm': 0.12729205191135406, 'learning_rate': 1.9992290362407232e-05, 'epoch': 0.62}\n","{'loss': 1.1105, 'grad_norm': 0.13645552098751068, 'learning_rate': 1.999141006689687e-05, 'epoch': 0.66}\n","{'loss': 1.0697, 'grad_norm': 0.15095853805541992, 'learning_rate': 1.999048221581858e-05, 'epoch': 0.69}\n","{'loss': 1.0292, 'grad_norm': 0.1643608659505844, 'learning_rate': 1.9989506813588606e-05, 'epoch': 0.73}\n","{'loss': 0.9671, 'grad_norm': 0.19368761777877808, 'learning_rate': 1.998848386484951e-05, 'epoch': 0.76}\n","{'loss': 0.9095, 'grad_norm': 0.18455208837985992, 'learning_rate': 1.998741337447017e-05, 'epoch': 0.8}\n","{'loss': 0.8546, 'grad_norm': 0.21467944979667664, 'learning_rate': 1.9986295347545738e-05, 'epoch': 0.83}\n","{'loss': 0.7839, 'grad_norm': 0.22762279212474823, 'learning_rate': 1.9985129789397633e-05, 'epoch': 0.87}\n","{'loss': 0.7041, 'grad_norm': 0.2359403371810913, 'learning_rate': 1.998391670557349e-05, 'epoch': 0.9}\n","{'loss': 0.625, 'grad_norm': 0.25267505645751953, 'learning_rate': 1.998265610184716e-05, 'epoch': 0.93}\n","{'loss': 0.5556, 'grad_norm': 0.26181575655937195, 'learning_rate': 1.998134798421867e-05, 'epoch': 0.97}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 2\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.4594, 'grad_norm': 0.2873406708240509, 'learning_rate': 1.99799923589142e-05, 'epoch': 1.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"27bb6c8dd28446f2a40f041d21dfa468","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/32 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_model/checkpoint-145\n","loading configuration file /home/raza/Downloads/Phi-3-mini-4k-instruct/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 2047,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer config file saved in ./finetuned_model/checkpoint-145/tokenizer_config.json\n","Special tokens file saved in ./finetuned_model/checkpoint-145/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.4201500117778778, 'eval_runtime': 6.8803, 'eval_samples_per_second': 9.157, 'eval_steps_per_second': 4.651, 'epoch': 1.0}\n","{'loss': 0.3924, 'grad_norm': 0.24495331943035126, 'learning_rate': 1.9978589232386036e-05, 'epoch': 1.03}\n","{'loss': 0.3342, 'grad_norm': 0.21487076580524445, 'learning_rate': 1.997713861131257e-05, 'epoch': 1.07}\n","{'loss': 0.2734, 'grad_norm': 0.20786333084106445, 'learning_rate': 1.9975640502598243e-05, 'epoch': 1.1}\n","{'loss': 0.228, 'grad_norm': 0.17612580955028534, 'learning_rate': 1.997409491337352e-05, 'epoch': 1.14}\n","{'loss': 0.1804, 'grad_norm': 0.13294285535812378, 'learning_rate': 1.9972501850994857e-05, 'epoch': 1.17}\n","{'loss': 0.1594, 'grad_norm': 0.1360795646905899, 'learning_rate': 1.9970861323044667e-05, 'epoch': 1.21}\n","{'loss': 0.1501, 'grad_norm': 0.13306614756584167, 'learning_rate': 1.9969173337331283e-05, 'epoch': 1.24}\n","{'loss': 0.1238, 'grad_norm': 0.1311856061220169, 'learning_rate': 1.9967437901888914e-05, 'epoch': 1.28}\n","{'loss': 0.0963, 'grad_norm': 0.11092741042375565, 'learning_rate': 1.9965655024977617e-05, 'epoch': 1.31}\n","{'loss': 0.0818, 'grad_norm': 0.10440867394208908, 'learning_rate': 1.9963824715083255e-05, 'epoch': 1.35}\n","{'loss': 0.0776, 'grad_norm': 0.08455055952072144, 'learning_rate': 1.9961946980917457e-05, 'epoch': 1.38}\n","{'loss': 0.0641, 'grad_norm': 0.06652998924255371, 'learning_rate': 1.996002183141757e-05, 'epoch': 1.42}\n","{'loss': 0.0605, 'grad_norm': 0.05529429391026497, 'learning_rate': 1.9958049275746617e-05, 'epoch': 1.45}\n","{'loss': 0.0541, 'grad_norm': 0.06545739620923996, 'learning_rate': 1.9956029323293275e-05, 'epoch': 1.48}\n","{'loss': 0.0524, 'grad_norm': 0.06559525430202484, 'learning_rate': 1.9953961983671792e-05, 'epoch': 1.52}\n","{'loss': 0.0471, 'grad_norm': 0.05007561296224594, 'learning_rate': 1.995184726672197e-05, 'epoch': 1.55}\n","{'loss': 0.049, 'grad_norm': 0.038622673600912094, 'learning_rate': 1.9949685182509117e-05, 'epoch': 1.59}\n","{'loss': 0.0503, 'grad_norm': 0.04309534654021263, 'learning_rate': 1.994747574132399e-05, 'epoch': 1.62}\n","{'loss': 0.0485, 'grad_norm': 0.050564881414175034, 'learning_rate': 1.9945218953682736e-05, 'epoch': 1.66}\n","{'loss': 0.0464, 'grad_norm': 0.030253121629357338, 'learning_rate': 1.994291483032687e-05, 'epoch': 1.69}\n","{'loss': 0.0383, 'grad_norm': 0.03816729038953781, 'learning_rate': 1.9940563382223196e-05, 'epoch': 1.73}\n","{'loss': 0.0458, 'grad_norm': 0.03674221783876419, 'learning_rate': 1.993816462056378e-05, 'epoch': 1.76}\n","{'loss': 0.0563, 'grad_norm': 0.04528430849313736, 'learning_rate': 1.9935718556765878e-05, 'epoch': 1.8}\n","{'loss': 0.0512, 'grad_norm': 0.04925185814499855, 'learning_rate': 1.993322520247188e-05, 'epoch': 1.83}\n","{'loss': 0.0455, 'grad_norm': 0.03232640400528908, 'learning_rate': 1.9930684569549265e-05, 'epoch': 1.87}\n","{'loss': 0.0573, 'grad_norm': 0.03843211382627487, 'learning_rate': 1.9928096670090552e-05, 'epoch': 1.9}\n","{'loss': 0.0537, 'grad_norm': 0.04033257067203522, 'learning_rate': 1.9925461516413224e-05, 'epoch': 1.93}\n","{'loss': 0.0451, 'grad_norm': 0.05659109726548195, 'learning_rate': 1.992277912105967e-05, 'epoch': 1.97}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 2\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.0447, 'grad_norm': 0.08023426681756973, 'learning_rate': 1.9920049496797153e-05, 'epoch': 2.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8742ea742d9748ee940fd6e8e2628c2c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/32 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_model/checkpoint-290\n","loading configuration file /home/raza/Downloads/Phi-3-mini-4k-instruct/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 2047,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer config file saved in ./finetuned_model/checkpoint-290/tokenizer_config.json\n","Special tokens file saved in ./finetuned_model/checkpoint-290/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.04589034616947174, 'eval_runtime': 6.8828, 'eval_samples_per_second': 9.153, 'eval_steps_per_second': 4.649, 'epoch': 2.0}\n","{'loss': 0.0353, 'grad_norm': 0.03214845806360245, 'learning_rate': 1.9917272656617704e-05, 'epoch': 2.03}\n","{'loss': 0.0482, 'grad_norm': 0.046078380197286606, 'learning_rate': 1.9914448613738107e-05, 'epoch': 2.07}\n","{'loss': 0.0422, 'grad_norm': 0.030392561107873917, 'learning_rate': 1.99115773815998e-05, 'epoch': 2.1}\n","{'loss': 0.0443, 'grad_norm': 0.05540081113576889, 'learning_rate': 1.9908658973868823e-05, 'epoch': 2.14}\n","{'loss': 0.0386, 'grad_norm': 0.05533044785261154, 'learning_rate': 1.990569340443577e-05, 'epoch': 2.17}\n","{'loss': 0.0422, 'grad_norm': 0.042744383215904236, 'learning_rate': 1.9902680687415704e-05, 'epoch': 2.21}\n","{'loss': 0.0544, 'grad_norm': 0.04437527060508728, 'learning_rate': 1.989962083714808e-05, 'epoch': 2.24}\n","{'loss': 0.0411, 'grad_norm': 0.04528980702161789, 'learning_rate': 1.9896513868196706e-05, 'epoch': 2.28}\n","{'loss': 0.0419, 'grad_norm': 0.03669861704111099, 'learning_rate': 1.9893359795349646e-05, 'epoch': 2.31}\n","{'loss': 0.0508, 'grad_norm': 0.028678929433226585, 'learning_rate': 1.989015863361917e-05, 'epoch': 2.35}\n","{'loss': 0.0399, 'grad_norm': 0.04047102481126785, 'learning_rate': 1.9886910398241673e-05, 'epoch': 2.38}\n","{'loss': 0.0525, 'grad_norm': 0.050724368542432785, 'learning_rate': 1.988361510467761e-05, 'epoch': 2.42}\n","{'loss': 0.0424, 'grad_norm': 0.05365395173430443, 'learning_rate': 1.9880272768611398e-05, 'epoch': 2.45}\n","{'loss': 0.0407, 'grad_norm': 0.036676350980997086, 'learning_rate': 1.9876883405951378e-05, 'epoch': 2.48}\n","{'loss': 0.0395, 'grad_norm': 0.030638301745057106, 'learning_rate': 1.9873447032829713e-05, 'epoch': 2.52}\n","{'loss': 0.0509, 'grad_norm': 0.033147141337394714, 'learning_rate': 1.9869963665602322e-05, 'epoch': 2.55}\n","{'loss': 0.042, 'grad_norm': 0.03821483626961708, 'learning_rate': 1.9866433320848793e-05, 'epoch': 2.59}\n","{'loss': 0.0456, 'grad_norm': 0.0339803546667099, 'learning_rate': 1.9862856015372315e-05, 'epoch': 2.62}\n","{'loss': 0.0482, 'grad_norm': 0.04348069801926613, 'learning_rate': 1.98592317661996e-05, 'epoch': 2.66}\n","{'loss': 0.0445, 'grad_norm': 0.03711177408695221, 'learning_rate': 1.985556059058078e-05, 'epoch': 2.69}\n","{'loss': 0.0432, 'grad_norm': 0.029658477753400803, 'learning_rate': 1.9851842505989355e-05, 'epoch': 2.73}\n","{'loss': 0.0395, 'grad_norm': 0.0401618666946888, 'learning_rate': 1.9848077530122083e-05, 'epoch': 2.76}\n","{'loss': 0.042, 'grad_norm': 0.04017283767461777, 'learning_rate': 1.9844265680898917e-05, 'epoch': 2.8}\n","{'loss': 0.0565, 'grad_norm': 0.03263000026345253, 'learning_rate': 1.984040697646291e-05, 'epoch': 2.83}\n","{'loss': 0.0423, 'grad_norm': 0.03712587431073189, 'learning_rate': 1.9836501435180122e-05, 'epoch': 2.87}\n","{'loss': 0.0428, 'grad_norm': 0.027433102950453758, 'learning_rate': 1.983254907563955e-05, 'epoch': 2.9}\n","{'loss': 0.0493, 'grad_norm': 0.056432176381349564, 'learning_rate': 1.9828549916653013e-05, 'epoch': 2.93}\n","{'loss': 0.0471, 'grad_norm': 0.04579790681600571, 'learning_rate': 1.98245039772551e-05, 'epoch': 2.97}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 2\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.0367, 'grad_norm': 0.06601044535636902, 'learning_rate': 1.982041127670304e-05, 'epoch': 3.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"643307922609459db17207dd73f5fb87","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/32 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_model/checkpoint-435\n","loading configuration file /home/raza/Downloads/Phi-3-mini-4k-instruct/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 2047,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer config file saved in ./finetuned_model/checkpoint-435/tokenizer_config.json\n","Special tokens file saved in ./finetuned_model/checkpoint-435/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.042672719806432724, 'eval_runtime': 6.8808, 'eval_samples_per_second': 9.156, 'eval_steps_per_second': 4.651, 'epoch': 3.0}\n","{'loss': 0.0451, 'grad_norm': 0.04042164236307144, 'learning_rate': 1.9816271834476642e-05, 'epoch': 3.03}\n","{'loss': 0.0465, 'grad_norm': 0.03576890379190445, 'learning_rate': 1.981208567027818e-05, 'epoch': 3.07}\n","{'loss': 0.0401, 'grad_norm': 0.04064302518963814, 'learning_rate': 1.9807852804032306e-05, 'epoch': 3.1}\n","{'loss': 0.0398, 'grad_norm': 0.037023577839136124, 'learning_rate': 1.9803573255885967e-05, 'epoch': 3.14}\n","{'loss': 0.0429, 'grad_norm': 0.038088008761405945, 'learning_rate': 1.9799247046208297e-05, 'epoch': 3.17}\n","{'loss': 0.0349, 'grad_norm': 0.057312220335006714, 'learning_rate': 1.9794874195590514e-05, 'epoch': 3.21}\n","{'loss': 0.0406, 'grad_norm': 0.02943326346576214, 'learning_rate': 1.979045472484584e-05, 'epoch': 3.24}\n","{'loss': 0.0491, 'grad_norm': 0.04820864275097847, 'learning_rate': 1.9785988655009386e-05, 'epoch': 3.28}\n","{'loss': 0.0378, 'grad_norm': 0.043669283390045166, 'learning_rate': 1.9781476007338058e-05, 'epoch': 3.31}\n","{'loss': 0.0424, 'grad_norm': 0.061673104763031006, 'learning_rate': 1.9776916803310463e-05, 'epoch': 3.35}\n","{'loss': 0.0503, 'grad_norm': 0.03322325646877289, 'learning_rate': 1.977231106462679e-05, 'epoch': 3.38}\n","{'loss': 0.0414, 'grad_norm': 0.03704997897148132, 'learning_rate': 1.9767658813208725e-05, 'epoch': 3.42}\n","{'loss': 0.0358, 'grad_norm': 0.04696505144238472, 'learning_rate': 1.9762960071199334e-05, 'epoch': 3.45}\n","{'loss': 0.043, 'grad_norm': 0.047410886734724045, 'learning_rate': 1.9758214860962965e-05, 'epoch': 3.48}\n","{'loss': 0.0371, 'grad_norm': 0.03384257107973099, 'learning_rate': 1.9753423205085127e-05, 'epoch': 3.52}\n","{'loss': 0.0362, 'grad_norm': 0.030623093247413635, 'learning_rate': 1.974858512637241e-05, 'epoch': 3.55}\n","{'loss': 0.0504, 'grad_norm': 0.0637797936797142, 'learning_rate': 1.9743700647852356e-05, 'epoch': 3.59}\n","{'loss': 0.0348, 'grad_norm': 0.033285096287727356, 'learning_rate': 1.9738769792773338e-05, 'epoch': 3.62}\n","{'loss': 0.044, 'grad_norm': 0.042831286787986755, 'learning_rate': 1.9733792584604487e-05, 'epoch': 3.66}\n","{'loss': 0.0371, 'grad_norm': 0.03419559821486473, 'learning_rate': 1.972876904703554e-05, 'epoch': 3.69}\n","{'loss': 0.0601, 'grad_norm': 0.03029838390648365, 'learning_rate': 1.9723699203976768e-05, 'epoch': 3.73}\n","{'loss': 0.0383, 'grad_norm': 0.035257626324892044, 'learning_rate': 1.9718583079558814e-05, 'epoch': 3.76}\n","{'loss': 0.0344, 'grad_norm': 0.035092227160930634, 'learning_rate': 1.9713420698132614e-05, 'epoch': 3.8}\n","{'loss': 0.0528, 'grad_norm': 0.039459455758333206, 'learning_rate': 1.9708212084269283e-05, 'epoch': 3.83}\n","{'loss': 0.041, 'grad_norm': 0.03749575465917587, 'learning_rate': 1.9702957262759964e-05, 'epoch': 3.87}\n","{'loss': 0.0342, 'grad_norm': 0.02491978369653225, 'learning_rate': 1.9697656258615753e-05, 'epoch': 3.9}\n","{'loss': 0.035, 'grad_norm': 0.049811650067567825, 'learning_rate': 1.9692309097067546e-05, 'epoch': 3.93}\n","{'loss': 0.0419, 'grad_norm': 0.057894811034202576, 'learning_rate': 1.9686915803565934e-05, 'epoch': 3.97}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 2\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.0394, 'grad_norm': 0.04243633896112442, 'learning_rate': 1.968147640378108e-05, 'epoch': 4.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7a5a59bf454249bb902c7bf8f8051aca","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/32 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_model/checkpoint-580\n","loading configuration file /home/raza/Downloads/Phi-3-mini-4k-instruct/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 2047,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer config file saved in ./finetuned_model/checkpoint-580/tokenizer_config.json\n","Special tokens file saved in ./finetuned_model/checkpoint-580/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.041130781173706055, 'eval_runtime': 6.8819, 'eval_samples_per_second': 9.154, 'eval_steps_per_second': 4.65, 'epoch': 4.0}\n","{'loss': 0.0438, 'grad_norm': 0.03963303938508034, 'learning_rate': 1.96759909236026e-05, 'epoch': 4.03}\n","{'loss': 0.0377, 'grad_norm': 0.05913958698511124, 'learning_rate': 1.9670459389139433e-05, 'epoch': 4.07}\n","{'loss': 0.0456, 'grad_norm': 0.04234561696648598, 'learning_rate': 1.966488182671972e-05, 'epoch': 4.1}\n","{'loss': 0.0422, 'grad_norm': 0.05398566648364067, 'learning_rate': 1.9659258262890683e-05, 'epoch': 4.14}\n","{'loss': 0.0376, 'grad_norm': 0.036745693534612656, 'learning_rate': 1.9653588724418492e-05, 'epoch': 4.17}\n","{'loss': 0.0456, 'grad_norm': 0.054030586034059525, 'learning_rate': 1.964787323828813e-05, 'epoch': 4.21}\n","{'loss': 0.0385, 'grad_norm': 0.032193899154663086, 'learning_rate': 1.9642111831703294e-05, 'epoch': 4.24}\n","{'loss': 0.036, 'grad_norm': 0.04467589035630226, 'learning_rate': 1.963630453208623e-05, 'epoch': 4.28}\n","{'loss': 0.0325, 'grad_norm': 0.0699598491191864, 'learning_rate': 1.963045136707763e-05, 'epoch': 4.31}\n","{'loss': 0.0494, 'grad_norm': 0.04697725549340248, 'learning_rate': 1.9624552364536472e-05, 'epoch': 4.35}\n","{'loss': 0.0425, 'grad_norm': 0.04656647518277168, 'learning_rate': 1.961860755253993e-05, 'epoch': 4.38}\n","{'loss': 0.0348, 'grad_norm': 0.05076409876346588, 'learning_rate': 1.961261695938319e-05, 'epoch': 4.42}\n","{'loss': 0.0387, 'grad_norm': 0.04508854076266289, 'learning_rate': 1.9606580613579352e-05, 'epoch': 4.45}\n","{'loss': 0.047, 'grad_norm': 0.042552441358566284, 'learning_rate': 1.960049854385929e-05, 'epoch': 4.48}\n","{'loss': 0.0385, 'grad_norm': 0.03640728071331978, 'learning_rate': 1.9594370779171484e-05, 'epoch': 4.52}\n","{'loss': 0.0403, 'grad_norm': 0.045121025294065475, 'learning_rate': 1.958819734868193e-05, 'epoch': 4.55}\n","{'loss': 0.0435, 'grad_norm': 0.03395967558026314, 'learning_rate': 1.9581978281773966e-05, 'epoch': 4.59}\n","{'loss': 0.0343, 'grad_norm': 0.03922656178474426, 'learning_rate': 1.9575713608048146e-05, 'epoch': 4.62}\n","{'loss': 0.0351, 'grad_norm': 0.04987841472029686, 'learning_rate': 1.956940335732209e-05, 'epoch': 4.66}\n","{'loss': 0.0487, 'grad_norm': 0.03836320713162422, 'learning_rate': 1.9563047559630356e-05, 'epoch': 4.69}\n","{'loss': 0.0386, 'grad_norm': 0.0304343830794096, 'learning_rate': 1.9556646245224286e-05, 'epoch': 4.73}\n","{'loss': 0.0392, 'grad_norm': 0.04800746962428093, 'learning_rate': 1.9550199444571868e-05, 'epoch': 4.76}\n","{'loss': 0.0357, 'grad_norm': 0.055739760398864746, 'learning_rate': 1.9543707188357583e-05, 'epoch': 4.8}\n","{'loss': 0.0372, 'grad_norm': 0.04518187418580055, 'learning_rate': 1.953716950748227e-05, 'epoch': 4.83}\n","{'loss': 0.0329, 'grad_norm': 0.02786954864859581, 'learning_rate': 1.9530586433062973e-05, 'epoch': 4.87}\n","{'loss': 0.0445, 'grad_norm': 0.03223817050457001, 'learning_rate': 1.9523957996432785e-05, 'epoch': 4.9}\n","{'loss': 0.0454, 'grad_norm': 0.03789694234728813, 'learning_rate': 1.9517284229140718e-05, 'epoch': 4.93}\n","{'loss': 0.0408, 'grad_norm': 0.03218225762248039, 'learning_rate': 1.9510565162951538e-05, 'epoch': 4.97}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 2\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.0348, 'grad_norm': 0.060963552445173264, 'learning_rate': 1.9503800829845613e-05, 'epoch': 5.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e836f5daff6d4925a2b76bb73af0dd8c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/32 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_model/checkpoint-725\n","loading configuration file /home/raza/Downloads/Phi-3-mini-4k-instruct/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 2047,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer config file saved in ./finetuned_model/checkpoint-725/tokenizer_config.json\n","Special tokens file saved in ./finetuned_model/checkpoint-725/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.03999890387058258, 'eval_runtime': 6.8816, 'eval_samples_per_second': 9.155, 'eval_steps_per_second': 4.65, 'epoch': 5.0}\n","{'loss': 0.0523, 'grad_norm': 0.05152033641934395, 'learning_rate': 1.949699126201877e-05, 'epoch': 5.03}\n","{'loss': 0.037, 'grad_norm': 0.03514130041003227, 'learning_rate': 1.9490136491882143e-05, 'epoch': 5.07}\n","{'loss': 0.0382, 'grad_norm': 0.030937066301703453, 'learning_rate': 1.9483236552061996e-05, 'epoch': 5.1}\n","{'loss': 0.0371, 'grad_norm': 0.052663929760456085, 'learning_rate': 1.94762914753996e-05, 'epoch': 5.14}\n","{'loss': 0.0379, 'grad_norm': 0.03430204465985298, 'learning_rate': 1.946930129495106e-05, 'epoch': 5.17}\n","{'loss': 0.0404, 'grad_norm': 0.05705816298723221, 'learning_rate': 1.9462266043987148e-05, 'epoch': 5.21}\n","{'loss': 0.0362, 'grad_norm': 0.04576617479324341, 'learning_rate': 1.945518575599317e-05, 'epoch': 5.24}\n","{'loss': 0.0427, 'grad_norm': 0.04918767511844635, 'learning_rate': 1.944806046466878e-05, 'epoch': 5.28}\n","{'loss': 0.0316, 'grad_norm': 0.04176202788949013, 'learning_rate': 1.9440890203927846e-05, 'epoch': 5.31}\n","{'loss': 0.0493, 'grad_norm': 0.07278919219970703, 'learning_rate': 1.9433675007898255e-05, 'epoch': 5.35}\n","{'loss': 0.0397, 'grad_norm': 0.045290008187294006, 'learning_rate': 1.9426414910921785e-05, 'epoch': 5.38}\n","{'loss': 0.0377, 'grad_norm': 0.04917127266526222, 'learning_rate': 1.9419109947553925e-05, 'epoch': 5.42}\n","{'loss': 0.0352, 'grad_norm': 0.03781360387802124, 'learning_rate': 1.941176015256371e-05, 'epoch': 5.45}\n","{'loss': 0.048, 'grad_norm': 0.036019135266542435, 'learning_rate': 1.940436556093355e-05, 'epoch': 5.48}\n","{'loss': 0.0338, 'grad_norm': 0.04936652258038521, 'learning_rate': 1.9396926207859085e-05, 'epoch': 5.52}\n","{'loss': 0.0359, 'grad_norm': 0.045985251665115356, 'learning_rate': 1.9389442128748994e-05, 'epoch': 5.55}\n","{'loss': 0.0385, 'grad_norm': 0.03189626708626747, 'learning_rate': 1.9381913359224844e-05, 'epoch': 5.59}\n","{'loss': 0.0311, 'grad_norm': 0.039089594036340714, 'learning_rate': 1.93743399351209e-05, 'epoch': 5.62}\n","{'loss': 0.0447, 'grad_norm': 0.04704012721776962, 'learning_rate': 1.9366721892483976e-05, 'epoch': 5.66}\n","{'loss': 0.0393, 'grad_norm': 0.03694121912121773, 'learning_rate': 1.935905926757326e-05, 'epoch': 5.69}\n","{'loss': 0.0442, 'grad_norm': 0.04635746031999588, 'learning_rate': 1.935135209686012e-05, 'epoch': 5.73}\n","{'loss': 0.0351, 'grad_norm': 0.02950911410152912, 'learning_rate': 1.9343600417027956e-05, 'epoch': 5.76}\n","{'loss': 0.0362, 'grad_norm': 0.04090016707777977, 'learning_rate': 1.9335804264972018e-05, 'epoch': 5.8}\n","{'loss': 0.0284, 'grad_norm': 0.042360540479421616, 'learning_rate': 1.9327963677799224e-05, 'epoch': 5.83}\n","{'loss': 0.0359, 'grad_norm': 0.031623102724552155, 'learning_rate': 1.932007869282799e-05, 'epoch': 5.87}\n","{'loss': 0.0331, 'grad_norm': 0.04873469099402428, 'learning_rate': 1.9312149347588035e-05, 'epoch': 5.9}\n","{'loss': 0.039, 'grad_norm': 0.04905074089765549, 'learning_rate': 1.9304175679820247e-05, 'epoch': 5.93}\n","{'loss': 0.0366, 'grad_norm': 0.04315418377518654, 'learning_rate': 1.9296157727476448e-05, 'epoch': 5.97}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 2\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.0506, 'grad_norm': 0.08018342405557632, 'learning_rate': 1.9288095528719245e-05, 'epoch': 6.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4862fcf9b9db42e899243d19198c03ed","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/32 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_model/checkpoint-870\n","loading configuration file /home/raza/Downloads/Phi-3-mini-4k-instruct/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 2047,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer config file saved in ./finetuned_model/checkpoint-870/tokenizer_config.json\n","Special tokens file saved in ./finetuned_model/checkpoint-870/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.03906916826963425, 'eval_runtime': 6.8824, 'eval_samples_per_second': 9.154, 'eval_steps_per_second': 4.65, 'epoch': 6.0}\n","{'loss': 0.0419, 'grad_norm': 0.04151894152164459, 'learning_rate': 1.9279989121921846e-05, 'epoch': 6.03}\n","{'loss': 0.0337, 'grad_norm': 0.04131153225898743, 'learning_rate': 1.9271838545667876e-05, 'epoch': 6.07}\n","{'loss': 0.0345, 'grad_norm': 0.049131013453006744, 'learning_rate': 1.926364383875118e-05, 'epoch': 6.1}\n","{'loss': 0.0518, 'grad_norm': 0.08803063631057739, 'learning_rate': 1.9255405040175666e-05, 'epoch': 6.14}\n","{'loss': 0.0351, 'grad_norm': 0.05369000509381294, 'learning_rate': 1.9247122189155082e-05, 'epoch': 6.17}\n","{'loss': 0.0367, 'grad_norm': 0.07562945783138275, 'learning_rate': 1.9238795325112867e-05, 'epoch': 6.21}\n","{'loss': 0.0319, 'grad_norm': 0.04933538660407066, 'learning_rate': 1.9230424487681944e-05, 'epoch': 6.24}\n","{'loss': 0.0369, 'grad_norm': 0.0429980605840683, 'learning_rate': 1.922200971670452e-05, 'epoch': 6.28}\n","{'loss': 0.0361, 'grad_norm': 0.04862573742866516, 'learning_rate': 1.9213551052231925e-05, 'epoch': 6.31}\n","{'loss': 0.038, 'grad_norm': 0.047127872705459595, 'learning_rate': 1.9205048534524405e-05, 'epoch': 6.35}\n","{'loss': 0.0351, 'grad_norm': 0.09117541462182999, 'learning_rate': 1.9196502204050925e-05, 'epoch': 6.38}\n","{'loss': 0.0293, 'grad_norm': 0.0317467600107193, 'learning_rate': 1.9187912101488986e-05, 'epoch': 6.42}\n","{'loss': 0.0288, 'grad_norm': 0.039479829370975494, 'learning_rate': 1.917927826772443e-05, 'epoch': 6.45}\n","{'loss': 0.0449, 'grad_norm': 0.04674820229411125, 'learning_rate': 1.917060074385124e-05, 'epoch': 6.48}\n","{'loss': 0.0305, 'grad_norm': 0.05650749057531357, 'learning_rate': 1.916187957117136e-05, 'epoch': 6.52}\n","{'loss': 0.0447, 'grad_norm': 0.032103609293699265, 'learning_rate': 1.9153114791194475e-05, 'epoch': 6.55}\n","{'loss': 0.0334, 'grad_norm': 0.05694513022899628, 'learning_rate': 1.9144306445637822e-05, 'epoch': 6.59}\n","{'loss': 0.0404, 'grad_norm': 0.04499794542789459, 'learning_rate': 1.913545457642601e-05, 'epoch': 6.62}\n","{'loss': 0.0468, 'grad_norm': 0.06567037850618362, 'learning_rate': 1.9126559225690796e-05, 'epoch': 6.66}\n","{'loss': 0.0367, 'grad_norm': 0.05345974490046501, 'learning_rate': 1.911762043577089e-05, 'epoch': 6.69}\n","{'loss': 0.0385, 'grad_norm': 0.03732531890273094, 'learning_rate': 1.910863824921176e-05, 'epoch': 6.73}\n","{'loss': 0.0374, 'grad_norm': 0.06431355327367783, 'learning_rate': 1.9099612708765432e-05, 'epoch': 6.76}\n","{'loss': 0.0504, 'grad_norm': 0.055250126868486404, 'learning_rate': 1.909054385739028e-05, 'epoch': 6.8}\n","{'loss': 0.0318, 'grad_norm': 0.039093974977731705, 'learning_rate': 1.9081431738250815e-05, 'epoch': 6.83}\n","{'loss': 0.0418, 'grad_norm': 0.028014376759529114, 'learning_rate': 1.9072276394717494e-05, 'epoch': 6.87}\n","{'loss': 0.0355, 'grad_norm': 0.04803600534796715, 'learning_rate': 1.9063077870366504e-05, 'epoch': 6.9}\n","{'loss': 0.0347, 'grad_norm': 0.0355534553527832, 'learning_rate': 1.9053836208979554e-05, 'epoch': 6.93}\n","{'loss': 0.044, 'grad_norm': 0.06698889285326004, 'learning_rate': 1.9044551454543683e-05, 'epoch': 6.97}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 2\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.0465, 'grad_norm': 0.22474613785743713, 'learning_rate': 1.903522365125102e-05, 'epoch': 7.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ec5a2da64d4d485c8b52b6e7d5fa5bd2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/32 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_model/checkpoint-1015\n","loading configuration file /home/raza/Downloads/Phi-3-mini-4k-instruct/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 2047,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer config file saved in ./finetuned_model/checkpoint-1015/tokenizer_config.json\n","Special tokens file saved in ./finetuned_model/checkpoint-1015/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.03870159760117531, 'eval_runtime': 6.8818, 'eval_samples_per_second': 9.155, 'eval_steps_per_second': 4.65, 'epoch': 7.0}\n","{'loss': 0.0412, 'grad_norm': 0.04155987873673439, 'learning_rate': 1.902585284349861e-05, 'epoch': 7.03}\n","{'loss': 0.0322, 'grad_norm': 0.03155370056629181, 'learning_rate': 1.901643907588816e-05, 'epoch': 7.07}\n","{'loss': 0.0305, 'grad_norm': 0.029276954010128975, 'learning_rate': 1.9006982393225878e-05, 'epoch': 7.1}\n","{'loss': 0.0465, 'grad_norm': 0.04299108684062958, 'learning_rate': 1.8997482840522218e-05, 'epoch': 7.14}\n","{'loss': 0.027, 'grad_norm': 0.056572530418634415, 'learning_rate': 1.8987940462991673e-05, 'epoch': 7.17}\n","{'loss': 0.0298, 'grad_norm': 0.03572305664420128, 'learning_rate': 1.897835530605258e-05, 'epoch': 7.21}\n","{'loss': 0.0324, 'grad_norm': 0.045558080077171326, 'learning_rate': 1.8968727415326885e-05, 'epoch': 7.24}\n","{'loss': 0.0334, 'grad_norm': 0.03876899182796478, 'learning_rate': 1.8959056836639937e-05, 'epoch': 7.28}\n","{'loss': 0.03, 'grad_norm': 0.04361319914460182, 'learning_rate': 1.894934361602025e-05, 'epoch': 7.31}\n","{'loss': 0.0337, 'grad_norm': 0.08905133605003357, 'learning_rate': 1.8939587799699325e-05, 'epoch': 7.35}\n","{'loss': 0.0361, 'grad_norm': 0.053509537130594254, 'learning_rate': 1.892978943411137e-05, 'epoch': 7.38}\n","{'loss': 0.0439, 'grad_norm': 0.0660071074962616, 'learning_rate': 1.8919948565893144e-05, 'epoch': 7.42}\n","{'loss': 0.0417, 'grad_norm': 0.030473433434963226, 'learning_rate': 1.891006524188368e-05, 'epoch': 7.45}\n","{'loss': 0.0358, 'grad_norm': 0.059401217848062515, 'learning_rate': 1.89001395091241e-05, 'epoch': 7.48}\n","{'loss': 0.034, 'grad_norm': 0.045192837715148926, 'learning_rate': 1.8890171414857366e-05, 'epoch': 7.52}\n","{'loss': 0.04, 'grad_norm': 0.05839899182319641, 'learning_rate': 1.8880161006528075e-05, 'epoch': 7.55}\n","{'loss': 0.0398, 'grad_norm': 0.06186433508992195, 'learning_rate': 1.887010833178222e-05, 'epoch': 7.59}\n","{'loss': 0.0341, 'grad_norm': 0.054195329546928406, 'learning_rate': 1.8860013438466966e-05, 'epoch': 7.62}\n","{'loss': 0.0466, 'grad_norm': 0.05448722839355469, 'learning_rate': 1.884987637463042e-05, 'epoch': 7.66}\n","{'loss': 0.0432, 'grad_norm': 0.04194521903991699, 'learning_rate': 1.8839697188521416e-05, 'epoch': 7.69}\n","{'loss': 0.0402, 'grad_norm': 0.05571626126766205, 'learning_rate': 1.8829475928589272e-05, 'epoch': 7.73}\n","{'loss': 0.0381, 'grad_norm': 0.052007440477609634, 'learning_rate': 1.881921264348355e-05, 'epoch': 7.76}\n","{'loss': 0.0463, 'grad_norm': 0.04092815890908241, 'learning_rate': 1.880890738205386e-05, 'epoch': 7.8}\n","{'loss': 0.0328, 'grad_norm': 0.04736527055501938, 'learning_rate': 1.8798560193349575e-05, 'epoch': 7.83}\n","{'loss': 0.0382, 'grad_norm': 0.06621963530778885, 'learning_rate': 1.8788171126619653e-05, 'epoch': 7.87}\n","{'loss': 0.033, 'grad_norm': 0.0384211465716362, 'learning_rate': 1.877774023131237e-05, 'epoch': 7.9}\n","{'loss': 0.0361, 'grad_norm': 0.06422003358602524, 'learning_rate': 1.876726755707508e-05, 'epoch': 7.93}\n","{'loss': 0.0453, 'grad_norm': 0.059244025498628616, 'learning_rate': 1.8756753153753998e-05, 'epoch': 7.97}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 2\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.0307, 'grad_norm': 0.11450470238924026, 'learning_rate': 1.874619707139396e-05, 'epoch': 8.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6485b3fe837f4d8dbdb739c87e513291","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/32 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_model/checkpoint-1160\n","loading configuration file /home/raza/Downloads/Phi-3-mini-4k-instruct/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 2047,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer config file saved in ./finetuned_model/checkpoint-1160/tokenizer_config.json\n","Special tokens file saved in ./finetuned_model/checkpoint-1160/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.037897415459156036, 'eval_runtime': 6.8824, 'eval_samples_per_second': 9.154, 'eval_steps_per_second': 4.65, 'epoch': 8.0}\n","{'loss': 0.0306, 'grad_norm': 0.052198171615600586, 'learning_rate': 1.873559936023817e-05, 'epoch': 8.03}\n","{'loss': 0.0465, 'grad_norm': 0.05193769186735153, 'learning_rate': 1.8724960070727974e-05, 'epoch': 8.07}\n","{'loss': 0.0418, 'grad_norm': 0.051916033029556274, 'learning_rate': 1.8714279253502616e-05, 'epoch': 8.1}\n","{'loss': 0.0412, 'grad_norm': 0.032911621034145355, 'learning_rate': 1.8703556959398998e-05, 'epoch': 8.14}\n","{'loss': 0.0298, 'grad_norm': 0.04272962361574173, 'learning_rate': 1.869279323945144e-05, 'epoch': 8.17}\n","{'loss': 0.0291, 'grad_norm': 0.05734889954328537, 'learning_rate': 1.8681988144891425e-05, 'epoch': 8.21}\n","{'loss': 0.0328, 'grad_norm': 0.04651014506816864, 'learning_rate': 1.8671141727147374e-05, 'epoch': 8.24}\n","{'loss': 0.0326, 'grad_norm': 0.0498405396938324, 'learning_rate': 1.866025403784439e-05, 'epoch': 8.28}\n","{'loss': 0.0298, 'grad_norm': 0.058720942586660385, 'learning_rate': 1.8649325128804007e-05, 'epoch': 8.31}\n","{'loss': 0.0341, 'grad_norm': 0.07335768640041351, 'learning_rate': 1.863835505204396e-05, 'epoch': 8.35}\n","{'loss': 0.0354, 'grad_norm': 0.03613840043544769, 'learning_rate': 1.862734385977792e-05, 'epoch': 8.38}\n","{'loss': 0.0341, 'grad_norm': 0.046301811933517456, 'learning_rate': 1.861629160441526e-05, 'epoch': 8.42}\n","{'loss': 0.0351, 'grad_norm': 0.05641493201255798, 'learning_rate': 1.860519833856079e-05, 'epoch': 8.45}\n","{'loss': 0.0375, 'grad_norm': 0.06633025407791138, 'learning_rate': 1.8594064115014528e-05, 'epoch': 8.48}\n","{'loss': 0.0356, 'grad_norm': 0.04004504159092903, 'learning_rate': 1.8582888986771423e-05, 'epoch': 8.52}\n","{'loss': 0.0338, 'grad_norm': 0.049565237015485764, 'learning_rate': 1.8571673007021124e-05, 'epoch': 8.55}\n","{'loss': 0.0374, 'grad_norm': 0.06022365763783455, 'learning_rate': 1.8560416229147718e-05, 'epoch': 8.59}\n","{'loss': 0.0393, 'grad_norm': 0.040726207196712494, 'learning_rate': 1.854911870672947e-05, 'epoch': 8.62}\n","{'loss': 0.0305, 'grad_norm': 0.03682369738817215, 'learning_rate': 1.8537780493538576e-05, 'epoch': 8.66}\n","{'loss': 0.0333, 'grad_norm': 0.04483573138713837, 'learning_rate': 1.8526401643540924e-05, 'epoch': 8.69}\n","{'loss': 0.0343, 'grad_norm': 0.03957309201359749, 'learning_rate': 1.851498221089579e-05, 'epoch': 8.73}\n","{'loss': 0.0444, 'grad_norm': 0.072085440158844, 'learning_rate': 1.850352224995563e-05, 'epoch': 8.76}\n","{'loss': 0.0306, 'grad_norm': 0.04552261158823967, 'learning_rate': 1.849202181526579e-05, 'epoch': 8.8}\n","{'loss': 0.0353, 'grad_norm': 0.038377005606889725, 'learning_rate': 1.848048096156426e-05, 'epoch': 8.83}\n","{'loss': 0.0476, 'grad_norm': 0.07054092735052109, 'learning_rate': 1.8468899743781416e-05, 'epoch': 8.87}\n","{'loss': 0.0403, 'grad_norm': 0.04076192528009415, 'learning_rate': 1.8457278217039735e-05, 'epoch': 8.9}\n","{'loss': 0.0459, 'grad_norm': 0.041832055896520615, 'learning_rate': 1.8445616436653567e-05, 'epoch': 8.93}\n","{'loss': 0.0374, 'grad_norm': 0.04473801329731941, 'learning_rate': 1.843391445812886e-05, 'epoch': 8.97}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 2\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.031, 'grad_norm': 0.04714678227901459, 'learning_rate': 1.8422172337162865e-05, 'epoch': 9.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2651c043ae6845f383bcc71557d14cb6","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/32 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_model/checkpoint-1305\n","loading configuration file /home/raza/Downloads/Phi-3-mini-4k-instruct/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 2047,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer config file saved in ./finetuned_model/checkpoint-1305/tokenizer_config.json\n","Special tokens file saved in ./finetuned_model/checkpoint-1305/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.03765296936035156, 'eval_runtime': 6.8911, 'eval_samples_per_second': 9.142, 'eval_steps_per_second': 4.644, 'epoch': 9.0}\n","{'loss': 0.0308, 'grad_norm': 0.03979823738336563, 'learning_rate': 1.8410390129643927e-05, 'epoch': 9.03}\n","{'loss': 0.0414, 'grad_norm': 0.04313907027244568, 'learning_rate': 1.8398567891651163e-05, 'epoch': 9.07}\n","{'loss': 0.0419, 'grad_norm': 0.06284420937299728, 'learning_rate': 1.8386705679454243e-05, 'epoch': 9.1}\n","{'loss': 0.0391, 'grad_norm': 0.05195574462413788, 'learning_rate': 1.837480354951308e-05, 'epoch': 9.14}\n","{'loss': 0.0348, 'grad_norm': 0.045733775943517685, 'learning_rate': 1.8362861558477597e-05, 'epoch': 9.17}\n","{'loss': 0.0311, 'grad_norm': 0.07874564081430435, 'learning_rate': 1.8350879763187433e-05, 'epoch': 9.21}\n","{'loss': 0.0351, 'grad_norm': 0.06498535722494125, 'learning_rate': 1.8338858220671683e-05, 'epoch': 9.24}\n","{'loss': 0.0398, 'grad_norm': 0.046574387699365616, 'learning_rate': 1.8326796988148627e-05, 'epoch': 9.28}\n","{'loss': 0.0376, 'grad_norm': 0.03862404450774193, 'learning_rate': 1.8314696123025456e-05, 'epoch': 9.31}\n","{'loss': 0.0353, 'grad_norm': 0.05989161506295204, 'learning_rate': 1.8302555682897986e-05, 'epoch': 9.35}\n","{'loss': 0.0333, 'grad_norm': 0.05742638558149338, 'learning_rate': 1.8290375725550417e-05, 'epoch': 9.38}\n","{'loss': 0.0328, 'grad_norm': 0.05236978828907013, 'learning_rate': 1.8278156308955024e-05, 'epoch': 9.42}\n","{'loss': 0.0304, 'grad_norm': 0.03841462358832359, 'learning_rate': 1.8265897491271885e-05, 'epoch': 9.45}\n","{'loss': 0.0336, 'grad_norm': 0.04254356026649475, 'learning_rate': 1.8253599330848638e-05, 'epoch': 9.48}\n","{'loss': 0.0324, 'grad_norm': 0.07249242067337036, 'learning_rate': 1.8241261886220155e-05, 'epoch': 9.52}\n","{'loss': 0.0341, 'grad_norm': 0.08628489077091217, 'learning_rate': 1.8228885216108307e-05, 'epoch': 9.55}\n","{'loss': 0.0392, 'grad_norm': 0.04637548327445984, 'learning_rate': 1.821646937942164e-05, 'epoch': 9.59}\n","{'loss': 0.0293, 'grad_norm': 0.04431872069835663, 'learning_rate': 1.8204014435255136e-05, 'epoch': 9.62}\n","{'loss': 0.0301, 'grad_norm': 0.04824022576212883, 'learning_rate': 1.819152044288992e-05, 'epoch': 9.66}\n","{'loss': 0.0289, 'grad_norm': 0.04005409777164459, 'learning_rate': 1.8178987461792955e-05, 'epoch': 9.69}\n","{'loss': 0.0487, 'grad_norm': 0.04697050899267197, 'learning_rate': 1.816641555161679e-05, 'epoch': 9.73}\n","{'loss': 0.0352, 'grad_norm': 0.05205428972840309, 'learning_rate': 1.8153804772199257e-05, 'epoch': 9.76}\n","{'loss': 0.0386, 'grad_norm': 0.03133982792496681, 'learning_rate': 1.8141155183563195e-05, 'epoch': 9.8}\n","{'loss': 0.036, 'grad_norm': 0.05765692889690399, 'learning_rate': 1.8128466845916156e-05, 'epoch': 9.83}\n","{'loss': 0.0355, 'grad_norm': 0.04965776950120926, 'learning_rate': 1.8115739819650124e-05, 'epoch': 9.87}\n","{'loss': 0.0385, 'grad_norm': 0.06339431554079056, 'learning_rate': 1.8102974165341236e-05, 'epoch': 9.9}\n","{'loss': 0.0388, 'grad_norm': 0.053281161934137344, 'learning_rate': 1.8090169943749477e-05, 'epoch': 9.93}\n","{'loss': 0.0325, 'grad_norm': 0.07240192592144012, 'learning_rate': 1.8077327215818395e-05, 'epoch': 9.97}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 2\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.0353, 'grad_norm': 0.04772978276014328, 'learning_rate': 1.806444604267483e-05, 'epoch': 10.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f6c1abbe7c3e4d69b8a6f862e105b2f5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/32 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_model/checkpoint-1450\n","loading configuration file /home/raza/Downloads/Phi-3-mini-4k-instruct/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 2047,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer config file saved in ./finetuned_model/checkpoint-1450/tokenizer_config.json\n","Special tokens file saved in ./finetuned_model/checkpoint-1450/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.037245750427246094, 'eval_runtime': 6.8862, 'eval_samples_per_second': 9.149, 'eval_steps_per_second': 4.647, 'epoch': 10.0}\n","{'loss': 0.0335, 'grad_norm': 0.05922059342265129, 'learning_rate': 1.8051526485628582e-05, 'epoch': 10.03}\n","{'loss': 0.0349, 'grad_norm': 0.06657275557518005, 'learning_rate': 1.8038568606172172e-05, 'epoch': 10.07}\n","{'loss': 0.0359, 'grad_norm': 0.047869786620140076, 'learning_rate': 1.802557246598051e-05, 'epoch': 10.1}\n","{'loss': 0.0318, 'grad_norm': 0.03756537288427353, 'learning_rate': 1.801253812691061e-05, 'epoch': 10.14}\n","{'loss': 0.0272, 'grad_norm': 0.04345676675438881, 'learning_rate': 1.7999465651001297e-05, 'epoch': 10.17}\n","{'loss': 0.0303, 'grad_norm': 0.08344458043575287, 'learning_rate': 1.798635510047293e-05, 'epoch': 10.21}\n","{'loss': 0.0376, 'grad_norm': 0.06222066283226013, 'learning_rate': 1.797320653772707e-05, 'epoch': 10.24}\n","{'loss': 0.0337, 'grad_norm': 0.04209303855895996, 'learning_rate': 1.796002002534622e-05, 'epoch': 10.28}\n","{'loss': 0.0286, 'grad_norm': 0.03990247845649719, 'learning_rate': 1.79467956260935e-05, 'epoch': 10.31}\n","{'loss': 0.0344, 'grad_norm': 0.06107136234641075, 'learning_rate': 1.7933533402912354e-05, 'epoch': 10.35}\n","{'loss': 0.0352, 'grad_norm': 0.05691809952259064, 'learning_rate': 1.7920233418926262e-05, 'epoch': 10.38}\n","{'loss': 0.031, 'grad_norm': 0.050192296504974365, 'learning_rate': 1.7906895737438437e-05, 'epoch': 10.42}\n","{'loss': 0.0306, 'grad_norm': 0.05383843183517456, 'learning_rate': 1.78935204219315e-05, 'epoch': 10.45}\n","{'loss': 0.0286, 'grad_norm': 0.030298657715320587, 'learning_rate': 1.788010753606722e-05, 'epoch': 10.48}\n","{'loss': 0.0388, 'grad_norm': 0.11074766516685486, 'learning_rate': 1.786665714368617e-05, 'epoch': 10.52}\n","{'loss': 0.0358, 'grad_norm': 0.033219508826732635, 'learning_rate': 1.785316930880745e-05, 'epoch': 10.55}\n","{'loss': 0.037, 'grad_norm': 0.048127878457307816, 'learning_rate': 1.7839644095628368e-05, 'epoch': 10.59}\n","{'loss': 0.0396, 'grad_norm': 0.09598518162965775, 'learning_rate': 1.782608156852414e-05, 'epoch': 10.62}\n","{'loss': 0.0332, 'grad_norm': 0.041261035948991776, 'learning_rate': 1.7812481792047587e-05, 'epoch': 10.66}\n","{'loss': 0.0476, 'grad_norm': 0.053093042224645615, 'learning_rate': 1.7798844830928818e-05, 'epoch': 10.69}\n","{'loss': 0.0372, 'grad_norm': 0.05117294564843178, 'learning_rate': 1.7785170750074937e-05, 'epoch': 10.73}\n","{'loss': 0.0327, 'grad_norm': 0.06004621088504791, 'learning_rate': 1.777145961456971e-05, 'epoch': 10.76}\n","{'loss': 0.034, 'grad_norm': 0.038178134709596634, 'learning_rate': 1.7757711489673285e-05, 'epoch': 10.8}\n","{'loss': 0.0363, 'grad_norm': 0.041243355721235275, 'learning_rate': 1.7743926440821857e-05, 'epoch': 10.83}\n","{'loss': 0.042, 'grad_norm': 0.06288367509841919, 'learning_rate': 1.773010453362737e-05, 'epoch': 10.87}\n","{'loss': 0.037, 'grad_norm': 0.047665052115917206, 'learning_rate': 1.7716245833877202e-05, 'epoch': 10.9}\n","{'loss': 0.0374, 'grad_norm': 0.060056403279304504, 'learning_rate': 1.7702350407533845e-05, 'epoch': 10.93}\n","{'loss': 0.041, 'grad_norm': 0.05387398973107338, 'learning_rate': 1.7688418320734596e-05, 'epoch': 10.97}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 2\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.0259, 'grad_norm': 0.054174575954675674, 'learning_rate': 1.7674449639791255e-05, 'epoch': 11.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"96f002d659f24140acc347cff49c4cda","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/32 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_model/checkpoint-1595\n","loading configuration file /home/raza/Downloads/Phi-3-mini-4k-instruct/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 2047,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer config file saved in ./finetuned_model/checkpoint-1595/tokenizer_config.json\n","Special tokens file saved in ./finetuned_model/checkpoint-1595/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.03734889253973961, 'eval_runtime': 6.8824, 'eval_samples_per_second': 9.154, 'eval_steps_per_second': 4.65, 'epoch': 11.0}\n","{'loss': 0.0348, 'grad_norm': 0.056006599217653275, 'learning_rate': 1.766044443118978e-05, 'epoch': 11.03}\n","{'loss': 0.0385, 'grad_norm': 0.0732097327709198, 'learning_rate': 1.7646402761590006e-05, 'epoch': 11.07}\n","{'loss': 0.0348, 'grad_norm': 0.056362785398960114, 'learning_rate': 1.7632324697825288e-05, 'epoch': 11.1}\n","{'loss': 0.0353, 'grad_norm': 0.04466785863041878, 'learning_rate': 1.7618210306902227e-05, 'epoch': 11.14}\n","{'loss': 0.0474, 'grad_norm': 0.05593980848789215, 'learning_rate': 1.7604059656000313e-05, 'epoch': 11.17}\n","{'loss': 0.0376, 'grad_norm': 0.06101289018988609, 'learning_rate': 1.758987281247162e-05, 'epoch': 11.21}\n","{'loss': 0.036, 'grad_norm': 0.06856410950422287, 'learning_rate': 1.75756498438405e-05, 'epoch': 11.24}\n","{'loss': 0.028, 'grad_norm': 0.05705433338880539, 'learning_rate': 1.7561390817803226e-05, 'epoch': 11.28}\n","{'loss': 0.0248, 'grad_norm': 0.03802555799484253, 'learning_rate': 1.7547095802227723e-05, 'epoch': 11.31}\n","{'loss': 0.0294, 'grad_norm': 0.06177530437707901, 'learning_rate': 1.7532764865153178e-05, 'epoch': 11.35}\n","{'loss': 0.0253, 'grad_norm': 0.031469229608774185, 'learning_rate': 1.7518398074789776e-05, 'epoch': 11.38}\n","{'loss': 0.032, 'grad_norm': 0.05170940235257149, 'learning_rate': 1.750399549951834e-05, 'epoch': 11.42}\n","{'loss': 0.0364, 'grad_norm': 0.0533662773668766, 'learning_rate': 1.7489557207890025e-05, 'epoch': 11.45}\n","{'loss': 0.0297, 'grad_norm': 0.03886827081441879, 'learning_rate': 1.747508326862597e-05, 'epoch': 11.48}\n","{'loss': 0.028, 'grad_norm': 0.045283883810043335, 'learning_rate': 1.7460573750616996e-05, 'epoch': 11.52}\n","{'loss': 0.0308, 'grad_norm': 0.036807239055633545, 'learning_rate': 1.7446028722923266e-05, 'epoch': 11.55}\n","{'loss': 0.0293, 'grad_norm': 0.03837868198752403, 'learning_rate': 1.7431448254773943e-05, 'epoch': 11.59}\n","{'loss': 0.0441, 'grad_norm': 0.061378590762615204, 'learning_rate': 1.7416832415566893e-05, 'epoch': 11.62}\n","{'loss': 0.0316, 'grad_norm': 0.04351206123828888, 'learning_rate': 1.7402181274868323e-05, 'epoch': 11.66}\n","{'loss': 0.0392, 'grad_norm': 0.06205639988183975, 'learning_rate': 1.7387494902412462e-05, 'epoch': 11.69}\n","{'loss': 0.04, 'grad_norm': 0.05455070361495018, 'learning_rate': 1.737277336810124e-05, 'epoch': 11.73}\n","{'loss': 0.0279, 'grad_norm': 0.04734053090214729, 'learning_rate': 1.7358016742003937e-05, 'epoch': 11.76}\n","{'loss': 0.0289, 'grad_norm': 0.042814549058675766, 'learning_rate': 1.7343225094356857e-05, 'epoch': 11.8}\n","{'loss': 0.0328, 'grad_norm': 0.04579473286867142, 'learning_rate': 1.7328398495562995e-05, 'epoch': 11.83}\n","{'loss': 0.0383, 'grad_norm': 0.05527153238654137, 'learning_rate': 1.7313537016191706e-05, 'epoch': 11.87}\n","{'loss': 0.0331, 'grad_norm': 0.04673055559396744, 'learning_rate': 1.7298640726978357e-05, 'epoch': 11.9}\n","{'loss': 0.0299, 'grad_norm': 0.045954085886478424, 'learning_rate': 1.7283709698824004e-05, 'epoch': 11.93}\n","{'loss': 0.0428, 'grad_norm': 0.057791538536548615, 'learning_rate': 1.7268744002795043e-05, 'epoch': 11.97}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 2\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.0444, 'grad_norm': 0.08301598578691483, 'learning_rate': 1.7253743710122877e-05, 'epoch': 12.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"20ef0477e0154b24a228b255ab5d8c3f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/32 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_model/checkpoint-1740\n","loading configuration file /home/raza/Downloads/Phi-3-mini-4k-instruct/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 2047,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer config file saved in ./finetuned_model/checkpoint-1740/tokenizer_config.json\n","Special tokens file saved in ./finetuned_model/checkpoint-1740/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.03691443055868149, 'eval_runtime': 6.883, 'eval_samples_per_second': 9.153, 'eval_steps_per_second': 4.649, 'epoch': 12.0}\n","{'loss': 0.0343, 'grad_norm': 0.060254428535699844, 'learning_rate': 1.723870889220358e-05, 'epoch': 12.03}\n","{'loss': 0.0265, 'grad_norm': 0.048848509788513184, 'learning_rate': 1.7223639620597556e-05, 'epoch': 12.07}\n","{'loss': 0.0394, 'grad_norm': 0.07562282681465149, 'learning_rate': 1.720853596702919e-05, 'epoch': 12.1}\n","{'loss': 0.0408, 'grad_norm': 0.04173414781689644, 'learning_rate': 1.7193398003386514e-05, 'epoch': 12.14}\n","{'loss': 0.0352, 'grad_norm': 0.055548179894685745, 'learning_rate': 1.7178225801720865e-05, 'epoch': 12.17}\n","{'loss': 0.0464, 'grad_norm': 0.05498165264725685, 'learning_rate': 1.7163019434246545e-05, 'epoch': 12.21}\n","{'loss': 0.0334, 'grad_norm': 0.052336279302835464, 'learning_rate': 1.7147778973340466e-05, 'epoch': 12.24}\n","{'loss': 0.0255, 'grad_norm': 0.058311499655246735, 'learning_rate': 1.713250449154182e-05, 'epoch': 12.28}\n","{'loss': 0.0306, 'grad_norm': 0.055855583399534225, 'learning_rate': 1.7117196061551714e-05, 'epoch': 12.31}\n","{'loss': 0.0293, 'grad_norm': 0.04470227658748627, 'learning_rate': 1.7101853756232856e-05, 'epoch': 12.35}\n","{'loss': 0.0361, 'grad_norm': 0.06555624306201935, 'learning_rate': 1.708647764860917e-05, 'epoch': 12.38}\n","{'loss': 0.0455, 'grad_norm': 0.07672037929296494, 'learning_rate': 1.7071067811865477e-05, 'epoch': 12.42}\n","{'loss': 0.0307, 'grad_norm': 0.04715678468346596, 'learning_rate': 1.7055624319347134e-05, 'epoch': 12.45}\n","{'loss': 0.0416, 'grad_norm': 0.03956424444913864, 'learning_rate': 1.7040147244559688e-05, 'epoch': 12.48}\n","{'loss': 0.0268, 'grad_norm': 0.07187539339065552, 'learning_rate': 1.702463666116852e-05, 'epoch': 12.52}\n","{'loss': 0.031, 'grad_norm': 0.04288358986377716, 'learning_rate': 1.700909264299851e-05, 'epoch': 12.55}\n","{'loss': 0.041, 'grad_norm': 0.090511754155159, 'learning_rate': 1.699351526403367e-05, 'epoch': 12.59}\n","{'loss': 0.0384, 'grad_norm': 0.04810505360364914, 'learning_rate': 1.6977904598416803e-05, 'epoch': 12.62}\n","{'loss': 0.0409, 'grad_norm': 0.055186301469802856, 'learning_rate': 1.6962260720449134e-05, 'epoch': 12.66}\n","{'loss': 0.0359, 'grad_norm': 0.06233540177345276, 'learning_rate': 1.6946583704589973e-05, 'epoch': 12.69}\n","{'loss': 0.0294, 'grad_norm': 0.0863535925745964, 'learning_rate': 1.6930873625456362e-05, 'epoch': 12.73}\n","{'loss': 0.0355, 'grad_norm': 0.05517878010869026, 'learning_rate': 1.6915130557822698e-05, 'epoch': 12.76}\n","{'loss': 0.0282, 'grad_norm': 0.04599195346236229, 'learning_rate': 1.6899354576620396e-05, 'epoch': 12.8}\n","{'loss': 0.0274, 'grad_norm': 0.03852878883481026, 'learning_rate': 1.688354575693754e-05, 'epoch': 12.83}\n","{'loss': 0.0342, 'grad_norm': 0.04559018835425377, 'learning_rate': 1.6867704174018503e-05, 'epoch': 12.87}\n","{'loss': 0.0257, 'grad_norm': 0.0529106929898262, 'learning_rate': 1.685182990326359e-05, 'epoch': 12.9}\n","{'loss': 0.0284, 'grad_norm': 0.07464558631181717, 'learning_rate': 1.6835923020228714e-05, 'epoch': 12.93}\n","{'loss': 0.0263, 'grad_norm': 0.04650459811091423, 'learning_rate': 1.6819983600624986e-05, 'epoch': 12.97}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 2\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.0398, 'grad_norm': 0.13863010704517365, 'learning_rate': 1.6804011720318394e-05, 'epoch': 13.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b3a07653844d492ebb8f97a920058a7d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/32 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_model/checkpoint-1885\n","loading configuration file /home/raza/Downloads/Phi-3-mini-4k-instruct/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 2047,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer config file saved in ./finetuned_model/checkpoint-1885/tokenizer_config.json\n","Special tokens file saved in ./finetuned_model/checkpoint-1885/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.037013519555330276, 'eval_runtime': 6.8836, 'eval_samples_per_second': 9.152, 'eval_steps_per_second': 4.649, 'epoch': 13.0}\n","{'loss': 0.0297, 'grad_norm': 0.04555593058466911, 'learning_rate': 1.678800745532942e-05, 'epoch': 13.03}\n","{'loss': 0.0335, 'grad_norm': 0.06297636777162552, 'learning_rate': 1.677197088183269e-05, 'epoch': 13.07}\n","{'loss': 0.0321, 'grad_norm': 0.04566813260316849, 'learning_rate': 1.6755902076156606e-05, 'epoch': 13.1}\n","{'loss': 0.0387, 'grad_norm': 0.056620895862579346, 'learning_rate': 1.673980111478298e-05, 'epoch': 13.14}\n","{'loss': 0.0304, 'grad_norm': 0.06986584514379501, 'learning_rate': 1.672366807434668e-05, 'epoch': 13.17}\n","{'loss': 0.028, 'grad_norm': 0.061541054397821426, 'learning_rate': 1.6707503031635258e-05, 'epoch': 13.21}\n","{'loss': 0.0472, 'grad_norm': 0.08779741078615189, 'learning_rate': 1.6691306063588583e-05, 'epoch': 13.24}\n","{'loss': 0.0305, 'grad_norm': 0.04593755304813385, 'learning_rate': 1.6675077247298475e-05, 'epoch': 13.28}\n","{'loss': 0.0344, 'grad_norm': 0.051094409078359604, 'learning_rate': 1.6658816660008344e-05, 'epoch': 13.31}\n","{'loss': 0.027, 'grad_norm': 0.0730811282992363, 'learning_rate': 1.664252437911282e-05, 'epoch': 13.35}\n","{'loss': 0.0344, 'grad_norm': 0.08404891937971115, 'learning_rate': 1.6626200482157378e-05, 'epoch': 13.38}\n","{'loss': 0.0305, 'grad_norm': 0.07751256972551346, 'learning_rate': 1.6609845046837976e-05, 'epoch': 13.42}\n","{'loss': 0.0281, 'grad_norm': 0.04571244493126869, 'learning_rate': 1.659345815100069e-05, 'epoch': 13.45}\n","{'loss': 0.0472, 'grad_norm': 0.092637799680233, 'learning_rate': 1.657703987264133e-05, 'epoch': 13.48}\n","{'loss': 0.0301, 'grad_norm': 0.060957975685596466, 'learning_rate': 1.6560590289905074e-05, 'epoch': 13.52}\n","{'loss': 0.0247, 'grad_norm': 0.07205382734537125, 'learning_rate': 1.6544109481086106e-05, 'epoch': 13.55}\n","{'loss': 0.0403, 'grad_norm': 0.04751019924879074, 'learning_rate': 1.6527597524627226e-05, 'epoch': 13.59}\n","{'loss': 0.0308, 'grad_norm': 0.04597380384802818, 'learning_rate': 1.6511054499119493e-05, 'epoch': 13.62}\n","{'loss': 0.0295, 'grad_norm': 0.04349428042769432, 'learning_rate': 1.6494480483301836e-05, 'epoch': 13.66}\n","{'loss': 0.0289, 'grad_norm': 0.05891786888241768, 'learning_rate': 1.64778755560607e-05, 'epoch': 13.69}\n","{'loss': 0.028, 'grad_norm': 0.05408010259270668, 'learning_rate': 1.646123979642964e-05, 'epoch': 13.73}\n","{'loss': 0.0328, 'grad_norm': 0.07472788542509079, 'learning_rate': 1.6444573283588977e-05, 'epoch': 13.76}\n","{'loss': 0.0359, 'grad_norm': 0.07938793301582336, 'learning_rate': 1.6427876096865394e-05, 'epoch': 13.8}\n","{'loss': 0.0389, 'grad_norm': 0.04951881244778633, 'learning_rate': 1.6411148315731583e-05, 'epoch': 13.83}\n","{'loss': 0.029, 'grad_norm': 0.07992330938577652, 'learning_rate': 1.639439001980585e-05, 'epoch': 13.87}\n","{'loss': 0.0407, 'grad_norm': 0.06618344783782959, 'learning_rate': 1.6377601288851733e-05, 'epoch': 13.9}\n","{'loss': 0.037, 'grad_norm': 0.044962573796510696, 'learning_rate': 1.636078220277764e-05, 'epoch': 13.93}\n","{'loss': 0.0301, 'grad_norm': 0.08713405579328537, 'learning_rate': 1.6343932841636455e-05, 'epoch': 13.97}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 2\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.0333, 'grad_norm': 0.1010560616850853, 'learning_rate': 1.6327053285625164e-05, 'epoch': 14.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"84ab9fc0eee748628330292db1776e42","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/32 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_model/checkpoint-2030\n","loading configuration file /home/raza/Downloads/Phi-3-mini-4k-instruct/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 2047,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer config file saved in ./finetuned_model/checkpoint-2030/tokenizer_config.json\n","Special tokens file saved in ./finetuned_model/checkpoint-2030/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.03675984963774681, 'eval_runtime': 6.8835, 'eval_samples_per_second': 9.152, 'eval_steps_per_second': 4.649, 'epoch': 14.0}\n","{'loss': 0.0429, 'grad_norm': 0.07168961316347122, 'learning_rate': 1.631014361508446e-05, 'epoch': 14.03}\n","{'loss': 0.0307, 'grad_norm': 0.03159947693347931, 'learning_rate': 1.6293203910498375e-05, 'epoch': 14.07}\n","{'loss': 0.0306, 'grad_norm': 0.05173318460583687, 'learning_rate': 1.6276234252493903e-05, 'epoch': 14.1}\n","{'loss': 0.0324, 'grad_norm': 0.043427225202322006, 'learning_rate': 1.6259234721840595e-05, 'epoch': 14.14}\n","{'loss': 0.0283, 'grad_norm': 0.04613537713885307, 'learning_rate': 1.624220539945018e-05, 'epoch': 14.17}\n","{'loss': 0.0406, 'grad_norm': 0.05572952702641487, 'learning_rate': 1.6225146366376198e-05, 'epoch': 14.21}\n","{'loss': 0.0287, 'grad_norm': 0.05731779709458351, 'learning_rate': 1.6208057703813595e-05, 'epoch': 14.24}\n","{'loss': 0.034, 'grad_norm': 0.04489654675126076, 'learning_rate': 1.6190939493098344e-05, 'epoch': 14.28}\n","{'loss': 0.0284, 'grad_norm': 0.046183254569768906, 'learning_rate': 1.6173791815707053e-05, 'epoch': 14.31}\n","{'loss': 0.0351, 'grad_norm': 0.07914863526821136, 'learning_rate': 1.6156614753256583e-05, 'epoch': 14.35}\n","{'loss': 0.0271, 'grad_norm': 0.04782870411872864, 'learning_rate': 1.6139408387503667e-05, 'epoch': 14.38}\n","{'loss': 0.0282, 'grad_norm': 0.06566663831472397, 'learning_rate': 1.6122172800344494e-05, 'epoch': 14.42}\n","{'loss': 0.0328, 'grad_norm': 0.045072007924318314, 'learning_rate': 1.6104908073814348e-05, 'epoch': 14.45}\n","{'loss': 0.0345, 'grad_norm': 0.04897656291723251, 'learning_rate': 1.608761429008721e-05, 'epoch': 14.48}\n","{'loss': 0.0334, 'grad_norm': 0.047160759568214417, 'learning_rate': 1.6070291531475342e-05, 'epoch': 14.52}\n","{'loss': 0.0329, 'grad_norm': 0.06273768097162247, 'learning_rate': 1.6052939880428942e-05, 'epoch': 14.55}\n","{'loss': 0.026, 'grad_norm': 0.05707639083266258, 'learning_rate': 1.6035559419535714e-05, 'epoch': 14.59}\n","{'loss': 0.0327, 'grad_norm': 0.04923278093338013, 'learning_rate': 1.6018150231520486e-05, 'epoch': 14.62}\n","{'loss': 0.0283, 'grad_norm': 0.04474756866693497, 'learning_rate': 1.6000712399244813e-05, 'epoch': 14.66}\n","{'loss': 0.0298, 'grad_norm': 0.05853843316435814, 'learning_rate': 1.5983246005706592e-05, 'epoch': 14.69}\n","{'loss': 0.0268, 'grad_norm': 0.04419025778770447, 'learning_rate': 1.5965751134039665e-05, 'epoch': 14.73}\n","{'loss': 0.0301, 'grad_norm': 0.05333225056529045, 'learning_rate': 1.5948227867513416e-05, 'epoch': 14.76}\n","{'loss': 0.0308, 'grad_norm': 0.0818222165107727, 'learning_rate': 1.5930676289532373e-05, 'epoch': 14.8}\n","{'loss': 0.0378, 'grad_norm': 0.06709103286266327, 'learning_rate': 1.5913096483635827e-05, 'epoch': 14.83}\n","{'loss': 0.0388, 'grad_norm': 0.07042071223258972, 'learning_rate': 1.5895488533497415e-05, 'epoch': 14.87}\n","{'loss': 0.0429, 'grad_norm': 0.05135782063007355, 'learning_rate': 1.5877852522924733e-05, 'epoch': 14.9}\n","{'loss': 0.0306, 'grad_norm': 0.048453059047460556, 'learning_rate': 1.586018853585894e-05, 'epoch': 14.93}\n","{'loss': 0.0342, 'grad_norm': 0.046767596155405045, 'learning_rate': 1.5842496656374347e-05, 'epoch': 14.97}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 2\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.0359, 'grad_norm': 0.09685233980417252, 'learning_rate': 1.5824776968678024e-05, 'epoch': 15.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f96a57a6f13548668aa4db9bc705138c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/32 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_model/checkpoint-2175\n","loading configuration file /home/raza/Downloads/Phi-3-mini-4k-instruct/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 2047,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer config file saved in ./finetuned_model/checkpoint-2175/tokenizer_config.json\n","Special tokens file saved in ./finetuned_model/checkpoint-2175/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.03635180741548538, 'eval_runtime': 6.8842, 'eval_samples_per_second': 9.151, 'eval_steps_per_second': 4.648, 'epoch': 15.0}\n","{'loss': 0.0238, 'grad_norm': 0.054951753467321396, 'learning_rate': 1.5807029557109398e-05, 'epoch': 15.03}\n","{'loss': 0.0425, 'grad_norm': 0.07482010871171951, 'learning_rate': 1.578925450613986e-05, 'epoch': 15.07}\n","{'loss': 0.0325, 'grad_norm': 0.07376702129840851, 'learning_rate': 1.577145190037234e-05, 'epoch': 15.1}\n","{'loss': 0.0346, 'grad_norm': 0.04637366160750389, 'learning_rate': 1.5753621824540924e-05, 'epoch': 15.14}\n","{'loss': 0.032, 'grad_norm': 0.06512972712516785, 'learning_rate': 1.573576436351046e-05, 'epoch': 15.17}\n","{'loss': 0.028, 'grad_norm': 0.04253850877285004, 'learning_rate': 1.5717879602276123e-05, 'epoch': 15.21}\n","{'loss': 0.0257, 'grad_norm': 0.07758267968893051, 'learning_rate': 1.5699967625963032e-05, 'epoch': 15.24}\n","{'loss': 0.0353, 'grad_norm': 0.06861064583063126, 'learning_rate': 1.568202851982584e-05, 'epoch': 15.28}\n","{'loss': 0.031, 'grad_norm': 0.0700257420539856, 'learning_rate': 1.566406236924833e-05, 'epoch': 15.31}\n","{'loss': 0.0376, 'grad_norm': 0.054333437234163284, 'learning_rate': 1.5646069259743007e-05, 'epoch': 15.35}\n","{'loss': 0.0426, 'grad_norm': 0.07041538506746292, 'learning_rate': 1.5628049276950687e-05, 'epoch': 15.38}\n","{'loss': 0.0295, 'grad_norm': 0.0442606583237648, 'learning_rate': 1.56100025066401e-05, 'epoch': 15.42}\n","{'loss': 0.028, 'grad_norm': 0.0512809120118618, 'learning_rate': 1.5591929034707468e-05, 'epoch': 15.45}\n","{'loss': 0.0367, 'grad_norm': 0.07048402726650238, 'learning_rate': 1.5573828947176114e-05, 'epoch': 15.48}\n","{'loss': 0.0329, 'grad_norm': 0.05877768248319626, 'learning_rate': 1.5555702330196024e-05, 'epoch': 15.52}\n","{'loss': 0.0316, 'grad_norm': 0.07489001750946045, 'learning_rate': 1.5537549270043474e-05, 'epoch': 15.55}\n","{'loss': 0.0257, 'grad_norm': 0.0525888167321682, 'learning_rate': 1.5519369853120584e-05, 'epoch': 15.59}\n","{'loss': 0.0322, 'grad_norm': 0.11325828731060028, 'learning_rate': 1.5501164165954935e-05, 'epoch': 15.62}\n","{'loss': 0.0276, 'grad_norm': 0.05265168845653534, 'learning_rate': 1.548293229519914e-05, 'epoch': 15.66}\n","{'loss': 0.0386, 'grad_norm': 0.05207366496324539, 'learning_rate': 1.5464674327630437e-05, 'epoch': 15.69}\n","{'loss': 0.0335, 'grad_norm': 0.07166244834661484, 'learning_rate': 1.5446390350150272e-05, 'epoch': 15.73}\n","{'loss': 0.035, 'grad_norm': 0.043455541133880615, 'learning_rate': 1.5428080449783898e-05, 'epoch': 15.76}\n","{'loss': 0.0385, 'grad_norm': 0.05542965978384018, 'learning_rate': 1.5409744713679942e-05, 'epoch': 15.8}\n","{'loss': 0.0282, 'grad_norm': 0.0652826577425003, 'learning_rate': 1.5391383229110005e-05, 'epoch': 15.83}\n","{'loss': 0.0283, 'grad_norm': 0.05151999741792679, 'learning_rate': 1.5372996083468242e-05, 'epoch': 15.87}\n","{'loss': 0.0357, 'grad_norm': 0.09186895936727524, 'learning_rate': 1.535458336427094e-05, 'epoch': 15.9}\n","{'loss': 0.0323, 'grad_norm': 0.06168440356850624, 'learning_rate': 1.533614515915612e-05, 'epoch': 15.93}\n","{'loss': 0.0273, 'grad_norm': 0.04469918832182884, 'learning_rate': 1.5317681555883087e-05, 'epoch': 15.97}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 2\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.0277, 'grad_norm': 0.07079000771045685, 'learning_rate': 1.529919264233205e-05, 'epoch': 16.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"eaa10a6c302149dab77bb58c8986aa93","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/32 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_model/checkpoint-2320\n","loading configuration file /home/raza/Downloads/Phi-3-mini-4k-instruct/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 2047,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer config file saved in ./finetuned_model/checkpoint-2320/tokenizer_config.json\n","Special tokens file saved in ./finetuned_model/checkpoint-2320/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.036526620388031006, 'eval_runtime': 6.8837, 'eval_samples_per_second': 9.152, 'eval_steps_per_second': 4.649, 'epoch': 16.0}\n","{'loss': 0.0392, 'grad_norm': 0.0987226590514183, 'learning_rate': 1.528067850650368e-05, 'epoch': 16.03}\n","{'loss': 0.0263, 'grad_norm': 0.05120842531323433, 'learning_rate': 1.5262139236518695e-05, 'epoch': 16.07}\n","{'loss': 0.0368, 'grad_norm': 0.06633025407791138, 'learning_rate': 1.5243574920617445e-05, 'epoch': 16.1}\n","{'loss': 0.0259, 'grad_norm': 0.05393323674798012, 'learning_rate': 1.5224985647159489e-05, 'epoch': 16.14}\n","{'loss': 0.0326, 'grad_norm': 0.034708861261606216, 'learning_rate': 1.5206371504623175e-05, 'epoch': 16.17}\n","{'loss': 0.0369, 'grad_norm': 0.06610293686389923, 'learning_rate': 1.5187732581605217e-05, 'epoch': 16.21}\n","{'loss': 0.0412, 'grad_norm': 0.07524990290403366, 'learning_rate': 1.5169068966820275e-05, 'epoch': 16.24}\n","{'loss': 0.0308, 'grad_norm': 0.04937271401286125, 'learning_rate': 1.5150380749100545e-05, 'epoch': 16.28}\n","{'loss': 0.0325, 'grad_norm': 0.05142116919159889, 'learning_rate': 1.5131668017395304e-05, 'epoch': 16.31}\n","{'loss': 0.0356, 'grad_norm': 0.041633639484643936, 'learning_rate': 1.511293086077052e-05, 'epoch': 16.35}\n","{'loss': 0.0317, 'grad_norm': 0.055959124118089676, 'learning_rate': 1.509416936840842e-05, 'epoch': 16.38}\n","{'loss': 0.0331, 'grad_norm': 0.051172804087400436, 'learning_rate': 1.5075383629607043e-05, 'epoch': 16.42}\n","{'loss': 0.0285, 'grad_norm': 0.0672377347946167, 'learning_rate': 1.5056573733779848e-05, 'epoch': 16.45}\n","{'loss': 0.0281, 'grad_norm': 0.052304886281490326, 'learning_rate': 1.5037739770455263e-05, 'epoch': 16.48}\n","{'loss': 0.0215, 'grad_norm': 0.05202903226017952, 'learning_rate': 1.501888182927628e-05, 'epoch': 16.52}\n","{'loss': 0.0307, 'grad_norm': 0.08179890364408493, 'learning_rate': 1.5000000000000002e-05, 'epoch': 16.55}\n","{'loss': 0.0384, 'grad_norm': 0.04698830470442772, 'learning_rate': 1.4981094372497243e-05, 'epoch': 16.59}\n","{'loss': 0.0284, 'grad_norm': 0.05568935349583626, 'learning_rate': 1.4962165036752085e-05, 'epoch': 16.62}\n","{'loss': 0.0244, 'grad_norm': 0.05585860833525658, 'learning_rate': 1.4943212082861448e-05, 'epoch': 16.66}\n","{'loss': 0.0298, 'grad_norm': 0.03803607076406479, 'learning_rate': 1.4924235601034673e-05, 'epoch': 16.69}\n","{'loss': 0.0324, 'grad_norm': 0.06884980201721191, 'learning_rate': 1.4905235681593079e-05, 'epoch': 16.73}\n","{'loss': 0.041, 'grad_norm': 0.06157742068171501, 'learning_rate': 1.4886212414969551e-05, 'epoch': 16.76}\n","{'loss': 0.0268, 'grad_norm': 0.10599108040332794, 'learning_rate': 1.4867165891708082e-05, 'epoch': 16.8}\n","{'loss': 0.0337, 'grad_norm': 0.053290434181690216, 'learning_rate': 1.4848096202463373e-05, 'epoch': 16.83}\n","{'loss': 0.0312, 'grad_norm': 0.056683097034692764, 'learning_rate': 1.4829003438000374e-05, 'epoch': 16.87}\n","{'loss': 0.0262, 'grad_norm': 0.08813132345676422, 'learning_rate': 1.4809887689193878e-05, 'epoch': 16.9}\n","{'loss': 0.0282, 'grad_norm': 0.053080033510923386, 'learning_rate': 1.4790749047028065e-05, 'epoch': 16.93}\n","{'loss': 0.0313, 'grad_norm': 0.07942002266645432, 'learning_rate': 1.4771587602596085e-05, 'epoch': 16.97}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 2\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.0449, 'grad_norm': 0.11406335979700089, 'learning_rate': 1.4752403447099617e-05, 'epoch': 17.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bb6f9d4b18724994809cbdaa571cd809","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/32 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_model/checkpoint-2465\n","loading configuration file /home/raza/Downloads/Phi-3-mini-4k-instruct/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 2047,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer config file saved in ./finetuned_model/checkpoint-2465/tokenizer_config.json\n","Special tokens file saved in ./finetuned_model/checkpoint-2465/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.03681216761469841, 'eval_runtime': 6.8787, 'eval_samples_per_second': 9.159, 'eval_steps_per_second': 4.652, 'epoch': 17.0}\n","{'loss': 0.0295, 'grad_norm': 0.05704876407980919, 'learning_rate': 1.4733196671848435e-05, 'epoch': 17.03}\n","{'loss': 0.0295, 'grad_norm': 0.04998396337032318, 'learning_rate': 1.4713967368259981e-05, 'epoch': 17.07}\n","{'loss': 0.0331, 'grad_norm': 0.051984161138534546, 'learning_rate': 1.469471562785891e-05, 'epoch': 17.1}\n","{'loss': 0.0343, 'grad_norm': 0.09759477525949478, 'learning_rate': 1.4675441542276685e-05, 'epoch': 17.14}\n","{'loss': 0.024, 'grad_norm': 0.046006713062524796, 'learning_rate': 1.4656145203251116e-05, 'epoch': 17.17}\n","{'loss': 0.0287, 'grad_norm': 0.06949015706777573, 'learning_rate': 1.463682670262593e-05, 'epoch': 17.21}\n","{'loss': 0.0271, 'grad_norm': 0.049049653112888336, 'learning_rate': 1.4617486132350343e-05, 'epoch': 17.24}\n","{'loss': 0.03, 'grad_norm': 0.06276753544807434, 'learning_rate': 1.45981235844786e-05, 'epoch': 17.28}\n","{'loss': 0.0443, 'grad_norm': 0.06088899448513985, 'learning_rate': 1.4578739151169567e-05, 'epoch': 17.31}\n","{'loss': 0.0266, 'grad_norm': 0.0677013024687767, 'learning_rate': 1.4559332924686276e-05, 'epoch': 17.35}\n","{'loss': 0.0275, 'grad_norm': 0.05451132357120514, 'learning_rate': 1.4539904997395468e-05, 'epoch': 17.38}\n","{'loss': 0.0317, 'grad_norm': 0.060070451349020004, 'learning_rate': 1.45204554617672e-05, 'epoch': 17.42}\n","{'loss': 0.0254, 'grad_norm': 0.03467504680156708, 'learning_rate': 1.4500984410374353e-05, 'epoch': 17.45}\n","{'loss': 0.0313, 'grad_norm': 0.12161093950271606, 'learning_rate': 1.4481491935892227e-05, 'epoch': 17.48}\n","{'loss': 0.0293, 'grad_norm': 0.051709894090890884, 'learning_rate': 1.4461978131098089e-05, 'epoch': 17.52}\n","{'loss': 0.031, 'grad_norm': 0.08723916858434677, 'learning_rate': 1.4442443088870727e-05, 'epoch': 17.55}\n","{'loss': 0.0306, 'grad_norm': 0.06833870708942413, 'learning_rate': 1.4422886902190014e-05, 'epoch': 17.59}\n","{'loss': 0.0446, 'grad_norm': 0.0646633431315422, 'learning_rate': 1.440330966413646e-05, 'epoch': 17.62}\n","{'loss': 0.0274, 'grad_norm': 0.0535915307700634, 'learning_rate': 1.4383711467890776e-05, 'epoch': 17.66}\n","{'loss': 0.0354, 'grad_norm': 0.05199693515896797, 'learning_rate': 1.436409240673342e-05, 'epoch': 17.69}\n","{'loss': 0.0273, 'grad_norm': 0.04143739119172096, 'learning_rate': 1.4344452574044173e-05, 'epoch': 17.73}\n","{'loss': 0.0421, 'grad_norm': 0.08081749081611633, 'learning_rate': 1.4324792063301662e-05, 'epoch': 17.76}\n","{'loss': 0.024, 'grad_norm': 0.06775330007076263, 'learning_rate': 1.4305110968082953e-05, 'epoch': 17.8}\n","{'loss': 0.032, 'grad_norm': 0.052145473659038544, 'learning_rate': 1.4285409382063074e-05, 'epoch': 17.83}\n","{'loss': 0.0232, 'grad_norm': 0.061720650643110275, 'learning_rate': 1.4265687399014584e-05, 'epoch': 17.87}\n","{'loss': 0.0394, 'grad_norm': 0.09091775119304657, 'learning_rate': 1.4245945112807133e-05, 'epoch': 17.9}\n","{'loss': 0.0335, 'grad_norm': 0.072240449488163, 'learning_rate': 1.4226182617406996e-05, 'epoch': 17.93}\n","{'loss': 0.0337, 'grad_norm': 0.04447132721543312, 'learning_rate': 1.4206400006876644e-05, 'epoch': 17.97}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 2\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.0337, 'grad_norm': 0.17334814369678497, 'learning_rate': 1.4186597375374283e-05, 'epoch': 18.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b6a3992f467f417eb4490560a5029a40","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/32 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_model/checkpoint-2610\n","loading configuration file /home/raza/Downloads/Phi-3-mini-4k-instruct/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 2047,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer config file saved in ./finetuned_model/checkpoint-2610/tokenizer_config.json\n","Special tokens file saved in ./finetuned_model/checkpoint-2610/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.03613695129752159, 'eval_runtime': 6.8796, 'eval_samples_per_second': 9.158, 'eval_steps_per_second': 4.651, 'epoch': 18.0}\n","{'loss': 0.0251, 'grad_norm': 0.056629788130521774, 'learning_rate': 1.416677481715342e-05, 'epoch': 18.03}\n","{'loss': 0.0264, 'grad_norm': 0.06882836669683456, 'learning_rate': 1.4146932426562391e-05, 'epoch': 18.07}\n","{'loss': 0.0274, 'grad_norm': 0.05286971479654312, 'learning_rate': 1.4127070298043949e-05, 'epoch': 18.1}\n","{'loss': 0.0337, 'grad_norm': 0.07517164945602417, 'learning_rate': 1.4107188526134774e-05, 'epoch': 18.14}\n","{'loss': 0.0348, 'grad_norm': 0.05001625046133995, 'learning_rate': 1.408728720546505e-05, 'epoch': 18.17}\n","{'loss': 0.0287, 'grad_norm': 0.10535594075918198, 'learning_rate': 1.4067366430758004e-05, 'epoch': 18.21}\n","{'loss': 0.0281, 'grad_norm': 0.05088945850729942, 'learning_rate': 1.4047426296829455e-05, 'epoch': 18.24}\n","{'loss': 0.0225, 'grad_norm': 0.05663256347179413, 'learning_rate': 1.4027466898587375e-05, 'epoch': 18.28}\n","{'loss': 0.0295, 'grad_norm': 0.09750093519687653, 'learning_rate': 1.4007488331031409e-05, 'epoch': 18.31}\n","{'loss': 0.0408, 'grad_norm': 0.07179373502731323, 'learning_rate': 1.3987490689252463e-05, 'epoch': 18.35}\n","{'loss': 0.0301, 'grad_norm': 0.046388961374759674, 'learning_rate': 1.3967474068432212e-05, 'epoch': 18.38}\n","{'loss': 0.0288, 'grad_norm': 0.0436394028365612, 'learning_rate': 1.3947438563842672e-05, 'epoch': 18.42}\n","{'loss': 0.0254, 'grad_norm': 0.06355295330286026, 'learning_rate': 1.3927384270845744e-05, 'epoch': 18.45}\n","{'loss': 0.0336, 'grad_norm': 0.06849576532840729, 'learning_rate': 1.3907311284892737e-05, 'epoch': 18.48}\n","{'loss': 0.0339, 'grad_norm': 0.0484602153301239, 'learning_rate': 1.3887219701523958e-05, 'epoch': 18.52}\n","{'loss': 0.0312, 'grad_norm': 0.09157517552375793, 'learning_rate': 1.3867109616368208e-05, 'epoch': 18.55}\n","{'loss': 0.0324, 'grad_norm': 0.05186466500163078, 'learning_rate': 1.3846981125142363e-05, 'epoch': 18.59}\n","{'loss': 0.0283, 'grad_norm': 0.079151950776577, 'learning_rate': 1.3826834323650899e-05, 'epoch': 18.62}\n","{'loss': 0.0398, 'grad_norm': 0.0593113973736763, 'learning_rate': 1.3806669307785447e-05, 'epoch': 18.66}\n","{'loss': 0.0325, 'grad_norm': 0.047603119164705276, 'learning_rate': 1.3786486173524331e-05, 'epoch': 18.69}\n","{'loss': 0.0305, 'grad_norm': 0.05853001028299332, 'learning_rate': 1.3766285016932109e-05, 'epoch': 18.73}\n","{'loss': 0.0274, 'grad_norm': 0.04680601507425308, 'learning_rate': 1.3746065934159123e-05, 'epoch': 18.76}\n","{'loss': 0.025, 'grad_norm': 0.06763024628162384, 'learning_rate': 1.372582902144103e-05, 'epoch': 18.8}\n","{'loss': 0.0383, 'grad_norm': 0.06106105446815491, 'learning_rate': 1.3705574375098365e-05, 'epoch': 18.83}\n","{'loss': 0.0368, 'grad_norm': 0.052272453904151917, 'learning_rate': 1.3685302091536052e-05, 'epoch': 18.87}\n","{'loss': 0.023, 'grad_norm': 0.032951343804597855, 'learning_rate': 1.3665012267242974e-05, 'epoch': 18.9}\n","{'loss': 0.0375, 'grad_norm': 0.05671706795692444, 'learning_rate': 1.3644704998791501e-05, 'epoch': 18.93}\n","{'loss': 0.0329, 'grad_norm': 0.10137134790420532, 'learning_rate': 1.3624380382837017e-05, 'epoch': 18.97}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 2\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.0337, 'grad_norm': 0.16306646168231964, 'learning_rate': 1.36040385161175e-05, 'epoch': 19.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7698ee59c32848ed87f163c60af28974","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/32 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_model/checkpoint-2755\n","loading configuration file /home/raza/Downloads/Phi-3-mini-4k-instruct/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 2047,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer config file saved in ./finetuned_model/checkpoint-2755/tokenizer_config.json\n","Special tokens file saved in ./finetuned_model/checkpoint-2755/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.036287784576416016, 'eval_runtime': 6.8886, 'eval_samples_per_second': 9.146, 'eval_steps_per_second': 4.645, 'epoch': 19.0}\n","{'loss': 0.0303, 'grad_norm': 0.04589654877781868, 'learning_rate': 1.3583679495453e-05, 'epoch': 19.03}\n","{'loss': 0.0228, 'grad_norm': 0.08839868754148483, 'learning_rate': 1.3563303417745258e-05, 'epoch': 19.07}\n","{'loss': 0.0368, 'grad_norm': 0.09631358832120895, 'learning_rate': 1.3542910379977158e-05, 'epoch': 19.1}\n","{'loss': 0.0294, 'grad_norm': 0.0846937745809555, 'learning_rate': 1.3522500479212337e-05, 'epoch': 19.14}\n","{'loss': 0.0346, 'grad_norm': 0.057120513170957565, 'learning_rate': 1.3502073812594677e-05, 'epoch': 19.17}\n","{'loss': 0.0264, 'grad_norm': 0.07025638967752457, 'learning_rate': 1.3481630477347864e-05, 'epoch': 19.21}\n","{'loss': 0.0263, 'grad_norm': 0.05678292363882065, 'learning_rate': 1.346117057077493e-05, 'epoch': 19.24}\n","{'loss': 0.0336, 'grad_norm': 0.0666596069931984, 'learning_rate': 1.3440694190257768e-05, 'epoch': 19.28}\n","{'loss': 0.0286, 'grad_norm': 0.0932924821972847, 'learning_rate': 1.342020143325669e-05, 'epoch': 19.31}\n","{'loss': 0.0273, 'grad_norm': 0.07096005231142044, 'learning_rate': 1.3399692397309943e-05, 'epoch': 19.35}\n","{'loss': 0.0318, 'grad_norm': 0.048432618379592896, 'learning_rate': 1.3379167180033272e-05, 'epoch': 19.38}\n","{'loss': 0.0242, 'grad_norm': 0.05158837139606476, 'learning_rate': 1.3358625879119424e-05, 'epoch': 19.42}\n","{'loss': 0.0375, 'grad_norm': 0.07127074897289276, 'learning_rate': 1.333806859233771e-05, 'epoch': 19.45}\n","{'loss': 0.0306, 'grad_norm': 0.05672803148627281, 'learning_rate': 1.3317495417533523e-05, 'epoch': 19.48}\n","{'loss': 0.0269, 'grad_norm': 0.053282566368579865, 'learning_rate': 1.3296906452627874e-05, 'epoch': 19.52}\n","{'loss': 0.0357, 'grad_norm': 0.05745093151926994, 'learning_rate': 1.3276301795616937e-05, 'epoch': 19.55}\n","{'loss': 0.0325, 'grad_norm': 0.06278028339147568, 'learning_rate': 1.3255681544571568e-05, 'epoch': 19.59}\n","{'loss': 0.0295, 'grad_norm': 0.057164233177900314, 'learning_rate': 1.3235045797636851e-05, 'epoch': 19.62}\n","{'loss': 0.039, 'grad_norm': 0.0936010405421257, 'learning_rate': 1.3214394653031616e-05, 'epoch': 19.66}\n","{'loss': 0.0329, 'grad_norm': 0.07717987895011902, 'learning_rate': 1.3193728209047993e-05, 'epoch': 19.69}\n","{'loss': 0.0328, 'grad_norm': 0.05687883868813515, 'learning_rate': 1.3173046564050923e-05, 'epoch': 19.73}\n","{'loss': 0.026, 'grad_norm': 0.08601488918066025, 'learning_rate': 1.31523498164777e-05, 'epoch': 19.76}\n","{'loss': 0.0297, 'grad_norm': 0.11740206182003021, 'learning_rate': 1.3131638064837496e-05, 'epoch': 19.8}\n","{'loss': 0.0275, 'grad_norm': 0.0654677003622055, 'learning_rate': 1.3110911407710909e-05, 'epoch': 19.83}\n","{'loss': 0.0273, 'grad_norm': 0.04998829960823059, 'learning_rate': 1.3090169943749475e-05, 'epoch': 19.87}\n","{'loss': 0.0323, 'grad_norm': 0.06718463450670242, 'learning_rate': 1.3069413771675202e-05, 'epoch': 19.9}\n","{'loss': 0.0246, 'grad_norm': 0.04173761606216431, 'learning_rate': 1.3048642990280109e-05, 'epoch': 19.93}\n","{'loss': 0.0358, 'grad_norm': 0.05801498144865036, 'learning_rate': 1.3027857698425748e-05, 'epoch': 19.97}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 2\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.0321, 'grad_norm': 0.0897749736905098, 'learning_rate': 1.300705799504273e-05, 'epoch': 20.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ad271d043feb4103b95a5fdbfad55cbd","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/32 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_model/checkpoint-2900\n","loading configuration file /home/raza/Downloads/Phi-3-mini-4k-instruct/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 2047,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer config file saved in ./finetuned_model/checkpoint-2900/tokenizer_config.json\n","Special tokens file saved in ./finetuned_model/checkpoint-2900/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.03651963174343109, 'eval_runtime': 6.8832, 'eval_samples_per_second': 9.153, 'eval_steps_per_second': 4.649, 'epoch': 20.0}\n","{'loss': 0.0245, 'grad_norm': 0.05447490140795708, 'learning_rate': 1.2986243979130277e-05, 'epoch': 20.03}\n","{'loss': 0.0238, 'grad_norm': 0.06545262038707733, 'learning_rate': 1.296541574975571e-05, 'epoch': 20.07}\n","{'loss': 0.0395, 'grad_norm': 0.09281449019908905, 'learning_rate': 1.2944573406054021e-05, 'epoch': 20.1}\n","{'loss': 0.0326, 'grad_norm': 0.058882568031549454, 'learning_rate': 1.2923717047227368e-05, 'epoch': 20.14}\n","{'loss': 0.031, 'grad_norm': 0.07338576018810272, 'learning_rate': 1.2902846772544625e-05, 'epoch': 20.17}\n","{'loss': 0.0256, 'grad_norm': 0.055072613060474396, 'learning_rate': 1.2881962681340894e-05, 'epoch': 20.21}\n","{'loss': 0.0269, 'grad_norm': 0.06100992485880852, 'learning_rate': 1.2861064873017044e-05, 'epoch': 20.24}\n","{'loss': 0.0329, 'grad_norm': 0.03943958878517151, 'learning_rate': 1.284015344703923e-05, 'epoch': 20.28}\n","{'loss': 0.0358, 'grad_norm': 0.04258330538868904, 'learning_rate': 1.2819228502938417e-05, 'epoch': 20.31}\n","{'loss': 0.0251, 'grad_norm': 0.033073827624320984, 'learning_rate': 1.2798290140309924e-05, 'epoch': 20.35}\n","{'loss': 0.0276, 'grad_norm': 0.1070316880941391, 'learning_rate': 1.2777338458812924e-05, 'epoch': 20.38}\n","{'loss': 0.0331, 'grad_norm': 0.07275520265102386, 'learning_rate': 1.2756373558169992e-05, 'epoch': 20.42}\n","{'loss': 0.0441, 'grad_norm': 0.06096148490905762, 'learning_rate': 1.2735395538166625e-05, 'epoch': 20.45}\n","{'loss': 0.0341, 'grad_norm': 0.07523469626903534, 'learning_rate': 1.2714404498650743e-05, 'epoch': 20.48}\n","{'loss': 0.0334, 'grad_norm': 0.0565221942961216, 'learning_rate': 1.2693400539532263e-05, 'epoch': 20.52}\n","{'loss': 0.0315, 'grad_norm': 0.06598483771085739, 'learning_rate': 1.267238376078257e-05, 'epoch': 20.55}\n","{'loss': 0.0304, 'grad_norm': 0.06181446835398674, 'learning_rate': 1.2651354262434082e-05, 'epoch': 20.59}\n","{'loss': 0.025, 'grad_norm': 0.05779333412647247, 'learning_rate': 1.2630312144579748e-05, 'epoch': 20.62}\n","{'loss': 0.0244, 'grad_norm': 0.0835380032658577, 'learning_rate': 1.260925750737259e-05, 'epoch': 20.66}\n","{'loss': 0.0263, 'grad_norm': 0.051484230905771255, 'learning_rate': 1.2588190451025209e-05, 'epoch': 20.69}\n","{'loss': 0.0301, 'grad_norm': 0.0841417983174324, 'learning_rate': 1.2567111075809319e-05, 'epoch': 20.73}\n","{'loss': 0.0255, 'grad_norm': 0.08434902131557465, 'learning_rate': 1.2546019482055276e-05, 'epoch': 20.76}\n","{'loss': 0.0349, 'grad_norm': 0.07404223084449768, 'learning_rate': 1.252491577015158e-05, 'epoch': 20.8}\n","{'loss': 0.0354, 'grad_norm': 0.04472830146551132, 'learning_rate': 1.2503800040544417e-05, 'epoch': 20.83}\n","{'loss': 0.0276, 'grad_norm': 0.05672184005379677, 'learning_rate': 1.2482672393737164e-05, 'epoch': 20.87}\n","{'loss': 0.0291, 'grad_norm': 0.0744582861661911, 'learning_rate': 1.2461532930289932e-05, 'epoch': 20.9}\n","{'loss': 0.0277, 'grad_norm': 0.06900342553853989, 'learning_rate': 1.2440381750819066e-05, 'epoch': 20.93}\n","{'loss': 0.0291, 'grad_norm': 0.05008727312088013, 'learning_rate': 1.2419218955996677e-05, 'epoch': 20.97}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 2\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.0263, 'grad_norm': 0.15478652715682983, 'learning_rate': 1.2398044646550167e-05, 'epoch': 21.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e8827c8687ca46be824c580d4fb9e59c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/32 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_model/checkpoint-3045\n","loading configuration file /home/raza/Downloads/Phi-3-mini-4k-instruct/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 2047,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer config file saved in ./finetuned_model/checkpoint-3045/tokenizer_config.json\n","Special tokens file saved in ./finetuned_model/checkpoint-3045/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.03689410164952278, 'eval_runtime': 6.8812, 'eval_samples_per_second': 9.155, 'eval_steps_per_second': 4.65, 'epoch': 21.0}\n","{'loss': 0.0318, 'grad_norm': 0.0811372920870781, 'learning_rate': 1.2376858923261732e-05, 'epoch': 21.03}\n","{'loss': 0.0337, 'grad_norm': 0.06318046152591705, 'learning_rate': 1.2355661886967904e-05, 'epoch': 21.07}\n","{'loss': 0.0233, 'grad_norm': 0.07216648757457733, 'learning_rate': 1.2334453638559057e-05, 'epoch': 21.1}\n","{'loss': 0.0288, 'grad_norm': 0.07515560835599899, 'learning_rate': 1.231323427897893e-05, 'epoch': 21.14}\n","{'loss': 0.0338, 'grad_norm': 0.05739833042025566, 'learning_rate': 1.2292003909224144e-05, 'epoch': 21.17}\n","{'loss': 0.0256, 'grad_norm': 0.06019795313477516, 'learning_rate': 1.2270762630343734e-05, 'epoch': 21.21}\n","{'loss': 0.0237, 'grad_norm': 0.06364704668521881, 'learning_rate': 1.2249510543438652e-05, 'epoch': 21.24}\n","{'loss': 0.0314, 'grad_norm': 0.10226250439882278, 'learning_rate': 1.2228247749661293e-05, 'epoch': 21.28}\n","{'loss': 0.0276, 'grad_norm': 0.05498169735074043, 'learning_rate': 1.2206974350215016e-05, 'epoch': 21.31}\n","{'loss': 0.0265, 'grad_norm': 0.0746898502111435, 'learning_rate': 1.2185690446353646e-05, 'epoch': 21.35}\n","{'loss': 0.0224, 'grad_norm': 0.05698957294225693, 'learning_rate': 1.2164396139381029e-05, 'epoch': 21.38}\n","{'loss': 0.0358, 'grad_norm': 0.0508158802986145, 'learning_rate': 1.2143091530650508e-05, 'epoch': 21.42}\n","{'loss': 0.0275, 'grad_norm': 0.0619584321975708, 'learning_rate': 1.2121776721564465e-05, 'epoch': 21.45}\n","{'loss': 0.0279, 'grad_norm': 0.04394645616412163, 'learning_rate': 1.2100451813573826e-05, 'epoch': 21.48}\n","{'loss': 0.0308, 'grad_norm': 0.0800526961684227, 'learning_rate': 1.2079116908177592e-05, 'epoch': 21.52}\n","{'loss': 0.0341, 'grad_norm': 0.07325641065835953, 'learning_rate': 1.205777210692235e-05, 'epoch': 21.55}\n","{'loss': 0.0449, 'grad_norm': 0.08460141718387604, 'learning_rate': 1.2036417511401775e-05, 'epoch': 21.59}\n","{'loss': 0.033, 'grad_norm': 0.060219503939151764, 'learning_rate': 1.2015053223256173e-05, 'epoch': 21.62}\n","{'loss': 0.0356, 'grad_norm': 0.08237902075052261, 'learning_rate': 1.1993679344171973e-05, 'epoch': 21.66}\n","{'loss': 0.0308, 'grad_norm': 0.06903170794248581, 'learning_rate': 1.1972295975881263e-05, 'epoch': 21.69}\n","{'loss': 0.0242, 'grad_norm': 0.05072947219014168, 'learning_rate': 1.1950903220161286e-05, 'epoch': 21.73}\n","{'loss': 0.0359, 'grad_norm': 0.09470553696155548, 'learning_rate': 1.192950117883397e-05, 'epoch': 21.76}\n","{'loss': 0.0273, 'grad_norm': 0.05493750050663948, 'learning_rate': 1.190808995376545e-05, 'epoch': 21.8}\n","{'loss': 0.0276, 'grad_norm': 0.0878690555691719, 'learning_rate': 1.1886669646865554e-05, 'epoch': 21.83}\n","{'loss': 0.0302, 'grad_norm': 0.055040616542100906, 'learning_rate': 1.1865240360087349e-05, 'epoch': 21.87}\n","{'loss': 0.0289, 'grad_norm': 0.09559401124715805, 'learning_rate': 1.1843802195426634e-05, 'epoch': 21.9}\n","{'loss': 0.0245, 'grad_norm': 0.05802898854017258, 'learning_rate': 1.1822355254921478e-05, 'epoch': 21.93}\n","{'loss': 0.021, 'grad_norm': 0.08386190980672836, 'learning_rate': 1.1800899640651699e-05, 'epoch': 21.97}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 2\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.0451, 'grad_norm': 0.14230026304721832, 'learning_rate': 1.177943545473842e-05, 'epoch': 22.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1b896c2d9bc249bfa60865641c82c871","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/32 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_model/checkpoint-3190\n","loading configuration file /home/raza/Downloads/Phi-3-mini-4k-instruct/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 2047,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer config file saved in ./finetuned_model/checkpoint-3190/tokenizer_config.json\n","Special tokens file saved in ./finetuned_model/checkpoint-3190/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.03686317428946495, 'eval_runtime': 6.8791, 'eval_samples_per_second': 9.158, 'eval_steps_per_second': 4.652, 'epoch': 22.0}\n","{'loss': 0.0309, 'grad_norm': 0.04719972237944603, 'learning_rate': 1.1757962799343548e-05, 'epoch': 22.03}\n","{'loss': 0.0273, 'grad_norm': 0.07361526787281036, 'learning_rate': 1.1736481776669307e-05, 'epoch': 22.07}\n","{'loss': 0.0288, 'grad_norm': 0.06346013396978378, 'learning_rate': 1.1714992488957743e-05, 'epoch': 22.1}\n","{'loss': 0.0285, 'grad_norm': 0.10267509520053864, 'learning_rate': 1.1693495038490247e-05, 'epoch': 22.14}\n","{'loss': 0.0279, 'grad_norm': 0.05362101271748543, 'learning_rate': 1.1671989527587057e-05, 'epoch': 22.17}\n","{'loss': 0.0262, 'grad_norm': 0.07745955139398575, 'learning_rate': 1.1650476058606776e-05, 'epoch': 22.21}\n","{'loss': 0.0279, 'grad_norm': 0.05433015152812004, 'learning_rate': 1.162895473394589e-05, 'epoch': 22.24}\n","{'loss': 0.0352, 'grad_norm': 0.08607536554336548, 'learning_rate': 1.1607425656038263e-05, 'epoch': 22.28}\n","{'loss': 0.0264, 'grad_norm': 0.10063958913087845, 'learning_rate': 1.1585888927354672e-05, 'epoch': 22.31}\n","{'loss': 0.0322, 'grad_norm': 0.07242310792207718, 'learning_rate': 1.156434465040231e-05, 'epoch': 22.35}\n","{'loss': 0.039, 'grad_norm': 0.08978548645973206, 'learning_rate': 1.154279292772429e-05, 'epoch': 22.38}\n","{'loss': 0.0294, 'grad_norm': 0.05312163382768631, 'learning_rate': 1.1521233861899168e-05, 'epoch': 22.42}\n","{'loss': 0.0218, 'grad_norm': 0.06183489039540291, 'learning_rate': 1.149966755554045e-05, 'epoch': 22.45}\n","{'loss': 0.0376, 'grad_norm': 0.0658138245344162, 'learning_rate': 1.1478094111296109e-05, 'epoch': 22.48}\n","{'loss': 0.0321, 'grad_norm': 0.09293483197689056, 'learning_rate': 1.1456513631848081e-05, 'epoch': 22.52}\n","{'loss': 0.0259, 'grad_norm': 0.06216366961598396, 'learning_rate': 1.1434926219911792e-05, 'epoch': 22.55}\n","{'loss': 0.0243, 'grad_norm': 0.05384458974003792, 'learning_rate': 1.1413331978235677e-05, 'epoch': 22.59}\n","{'loss': 0.0348, 'grad_norm': 0.061741262674331665, 'learning_rate': 1.1391731009600655e-05, 'epoch': 22.62}\n","{'loss': 0.0448, 'grad_norm': 0.06836092472076416, 'learning_rate': 1.1370123416819683e-05, 'epoch': 22.66}\n","{'loss': 0.0289, 'grad_norm': 0.08786769956350327, 'learning_rate': 1.1348509302737232e-05, 'epoch': 22.69}\n","{'loss': 0.0272, 'grad_norm': 0.10658702999353409, 'learning_rate': 1.1326888770228823e-05, 'epoch': 22.73}\n","{'loss': 0.0284, 'grad_norm': 0.05014980211853981, 'learning_rate': 1.130526192220052e-05, 'epoch': 22.76}\n","{'loss': 0.0234, 'grad_norm': 0.05820716172456741, 'learning_rate': 1.1283628861588444e-05, 'epoch': 22.8}\n","{'loss': 0.0263, 'grad_norm': 0.06622881442308426, 'learning_rate': 1.12619896913583e-05, 'epoch': 22.83}\n","{'loss': 0.0255, 'grad_norm': 0.05358552187681198, 'learning_rate': 1.1240344514504855e-05, 'epoch': 22.87}\n","{'loss': 0.0263, 'grad_norm': 0.06386435776948929, 'learning_rate': 1.1218693434051475e-05, 'epoch': 22.9}\n","{'loss': 0.0221, 'grad_norm': 0.06614772230386734, 'learning_rate': 1.1197036553049626e-05, 'epoch': 22.93}\n","{'loss': 0.0342, 'grad_norm': 0.07354394346475601, 'learning_rate': 1.1175373974578378e-05, 'epoch': 22.97}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 2\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.0296, 'grad_norm': 0.07165136933326721, 'learning_rate': 1.115370580174392e-05, 'epoch': 23.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4b60602ad7c74a37a8e6c61da061e703","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/32 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_model/checkpoint-3335\n","loading configuration file /home/raza/Downloads/Phi-3-mini-4k-instruct/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 2047,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer config file saved in ./finetuned_model/checkpoint-3335/tokenizer_config.json\n","Special tokens file saved in ./finetuned_model/checkpoint-3335/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.036772679537534714, 'eval_runtime': 6.882, 'eval_samples_per_second': 9.154, 'eval_steps_per_second': 4.65, 'epoch': 23.0}\n","{'loss': 0.027, 'grad_norm': 0.05987037345767021, 'learning_rate': 1.113203213767907e-05, 'epoch': 23.03}\n","{'loss': 0.0342, 'grad_norm': 0.10208912193775177, 'learning_rate': 1.1110353085542778e-05, 'epoch': 23.07}\n","{'loss': 0.0314, 'grad_norm': 0.04447310045361519, 'learning_rate': 1.1088668748519646e-05, 'epoch': 23.1}\n","{'loss': 0.0271, 'grad_norm': 0.06204051896929741, 'learning_rate': 1.1066979229819427e-05, 'epoch': 23.14}\n","{'loss': 0.0319, 'grad_norm': 0.05547104775905609, 'learning_rate': 1.1045284632676535e-05, 'epoch': 23.17}\n","{'loss': 0.0265, 'grad_norm': 0.06184665113687515, 'learning_rate': 1.102358506034956e-05, 'epoch': 23.21}\n","{'loss': 0.0273, 'grad_norm': 0.08924055844545364, 'learning_rate': 1.1001880616120764e-05, 'epoch': 23.24}\n","{'loss': 0.0244, 'grad_norm': 0.11256001144647598, 'learning_rate': 1.098017140329561e-05, 'epoch': 23.28}\n","{'loss': 0.0245, 'grad_norm': 0.06302274763584137, 'learning_rate': 1.0958457525202241e-05, 'epoch': 23.31}\n","{'loss': 0.0258, 'grad_norm': 0.08037762343883514, 'learning_rate': 1.0936739085191025e-05, 'epoch': 23.35}\n","{'loss': 0.0243, 'grad_norm': 0.05402451753616333, 'learning_rate': 1.0915016186634027e-05, 'epoch': 23.38}\n","{'loss': 0.0291, 'grad_norm': 0.04937563091516495, 'learning_rate': 1.0893288932924538e-05, 'epoch': 23.42}\n","{'loss': 0.0357, 'grad_norm': 0.09564203768968582, 'learning_rate': 1.0871557427476585e-05, 'epoch': 23.45}\n","{'loss': 0.0243, 'grad_norm': 0.05772425979375839, 'learning_rate': 1.0849821773724419e-05, 'epoch': 23.48}\n","{'loss': 0.0305, 'grad_norm': 0.0676145851612091, 'learning_rate': 1.0828082075122044e-05, 'epoch': 23.52}\n","{'loss': 0.0345, 'grad_norm': 0.05572952330112457, 'learning_rate': 1.0806338435142718e-05, 'epoch': 23.55}\n","{'loss': 0.0344, 'grad_norm': 0.05118347331881523, 'learning_rate': 1.0784590957278452e-05, 'epoch': 23.59}\n","{'loss': 0.0307, 'grad_norm': 0.08189037442207336, 'learning_rate': 1.0762839745039526e-05, 'epoch': 23.62}\n","{'loss': 0.0252, 'grad_norm': 0.11250890791416168, 'learning_rate': 1.0741084901953995e-05, 'epoch': 23.66}\n","{'loss': 0.0249, 'grad_norm': 0.05551500245928764, 'learning_rate': 1.0719326531567195e-05, 'epoch': 23.69}\n","{'loss': 0.0274, 'grad_norm': 0.09283963590860367, 'learning_rate': 1.0697564737441254e-05, 'epoch': 23.73}\n","{'loss': 0.0384, 'grad_norm': 0.054316196590662, 'learning_rate': 1.0675799623154593e-05, 'epoch': 23.76}\n","{'loss': 0.0256, 'grad_norm': 0.0661352127790451, 'learning_rate': 1.0654031292301432e-05, 'epoch': 23.8}\n","{'loss': 0.026, 'grad_norm': 0.06783047318458557, 'learning_rate': 1.0632259848491307e-05, 'epoch': 23.83}\n","{'loss': 0.0297, 'grad_norm': 0.09671425074338913, 'learning_rate': 1.0610485395348571e-05, 'epoch': 23.87}\n","{'loss': 0.0373, 'grad_norm': 0.049647536128759384, 'learning_rate': 1.058870803651189e-05, 'epoch': 23.9}\n","{'loss': 0.0302, 'grad_norm': 0.06819980591535568, 'learning_rate': 1.0566927875633776e-05, 'epoch': 23.93}\n","{'loss': 0.0328, 'grad_norm': 0.03945153206586838, 'learning_rate': 1.0545145016380065e-05, 'epoch': 23.97}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 2\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.0219, 'grad_norm': 0.14267316460609436, 'learning_rate': 1.0523359562429441e-05, 'epoch': 24.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1b8f71c5d54d4f76b39c149e7c5e7d53","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/32 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_model/checkpoint-3480\n","loading configuration file /home/raza/Downloads/Phi-3-mini-4k-instruct/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 2047,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer config file saved in ./finetuned_model/checkpoint-3480/tokenizer_config.json\n","Special tokens file saved in ./finetuned_model/checkpoint-3480/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.036675747483968735, 'eval_runtime': 6.8825, 'eval_samples_per_second': 9.154, 'eval_steps_per_second': 4.649, 'epoch': 24.0}\n","{'loss': 0.0263, 'grad_norm': 0.05836401879787445, 'learning_rate': 1.0501571617472934e-05, 'epoch': 24.03}\n","{'loss': 0.034, 'grad_norm': 0.09701675176620483, 'learning_rate': 1.047978128521344e-05, 'epoch': 24.07}\n","{'loss': 0.0339, 'grad_norm': 0.09909562021493912, 'learning_rate': 1.045798866936521e-05, 'epoch': 24.1}\n","{'loss': 0.0224, 'grad_norm': 0.05955342575907707, 'learning_rate': 1.0436193873653362e-05, 'epoch': 24.14}\n","{'loss': 0.0426, 'grad_norm': 0.0828840434551239, 'learning_rate': 1.0414397001813396e-05, 'epoch': 24.17}\n","{'loss': 0.0204, 'grad_norm': 0.053488776087760925, 'learning_rate': 1.0392598157590687e-05, 'epoch': 24.21}\n","{'loss': 0.0322, 'grad_norm': 0.07507229596376419, 'learning_rate': 1.0370797444740008e-05, 'epoch': 24.24}\n","{'loss': 0.0276, 'grad_norm': 0.0776604562997818, 'learning_rate': 1.0348994967025012e-05, 'epoch': 24.28}\n","{'loss': 0.0213, 'grad_norm': 0.07605043798685074, 'learning_rate': 1.0327190828217763e-05, 'epoch': 24.31}\n","{'loss': 0.0284, 'grad_norm': 0.057575445622205734, 'learning_rate': 1.0305385132098229e-05, 'epoch': 24.35}\n","{'loss': 0.0308, 'grad_norm': 0.05718689784407616, 'learning_rate': 1.0283577982453784e-05, 'epoch': 24.38}\n","{'loss': 0.0233, 'grad_norm': 0.05821367725729942, 'learning_rate': 1.0261769483078734e-05, 'epoch': 24.42}\n","{'loss': 0.0306, 'grad_norm': 0.06624434888362885, 'learning_rate': 1.0239959737773791e-05, 'epoch': 24.45}\n","{'loss': 0.0266, 'grad_norm': 0.07595096528530121, 'learning_rate': 1.0218148850345613e-05, 'epoch': 24.48}\n","{'loss': 0.0277, 'grad_norm': 0.0695660412311554, 'learning_rate': 1.0196336924606282e-05, 'epoch': 24.52}\n","{'loss': 0.0293, 'grad_norm': 0.09571924805641174, 'learning_rate': 1.0174524064372837e-05, 'epoch': 24.55}\n","{'loss': 0.0233, 'grad_norm': 0.06526840478181839, 'learning_rate': 1.0152710373466746e-05, 'epoch': 24.59}\n","{'loss': 0.0288, 'grad_norm': 0.08778543025255203, 'learning_rate': 1.0130895955713445e-05, 'epoch': 24.62}\n","{'loss': 0.0256, 'grad_norm': 0.044096268713474274, 'learning_rate': 1.0109080914941825e-05, 'epoch': 24.66}\n","{'loss': 0.0345, 'grad_norm': 0.047039326280355453, 'learning_rate': 1.008726535498374e-05, 'epoch': 24.69}\n","{'loss': 0.0299, 'grad_norm': 0.07132918387651443, 'learning_rate': 1.0065449379673519e-05, 'epoch': 24.73}\n","{'loss': 0.0342, 'grad_norm': 0.052489493042230606, 'learning_rate': 1.0043633092847468e-05, 'epoch': 24.76}\n","{'loss': 0.024, 'grad_norm': 0.07620694488286972, 'learning_rate': 1.002181659834337e-05, 'epoch': 24.8}\n","{'loss': 0.0296, 'grad_norm': 0.0506821870803833, 'learning_rate': 1e-05, 'epoch': 24.83}\n","{'loss': 0.0285, 'grad_norm': 0.07623045891523361, 'learning_rate': 9.978183401656632e-06, 'epoch': 24.87}\n","{'loss': 0.0342, 'grad_norm': 0.1086258515715599, 'learning_rate': 9.956366907152536e-06, 'epoch': 24.9}\n","{'loss': 0.0253, 'grad_norm': 0.11495289206504822, 'learning_rate': 9.934550620326483e-06, 'epoch': 24.93}\n","{'loss': 0.028, 'grad_norm': 0.06910905987024307, 'learning_rate': 9.912734645016262e-06, 'epoch': 24.97}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 2\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.0308, 'grad_norm': 0.0747794359922409, 'learning_rate': 9.890919085058179e-06, 'epoch': 25.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d585f73eb3c244dc8297b2c7911e9f79","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/32 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_model/checkpoint-3625\n","loading configuration file /home/raza/Downloads/Phi-3-mini-4k-instruct/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 2047,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer config file saved in ./finetuned_model/checkpoint-3625/tokenizer_config.json\n","Special tokens file saved in ./finetuned_model/checkpoint-3625/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.0372241847217083, 'eval_runtime': 6.8825, 'eval_samples_per_second': 9.154, 'eval_steps_per_second': 4.649, 'epoch': 25.0}\n","{'loss': 0.0271, 'grad_norm': 0.0794016644358635, 'learning_rate': 9.869104044286558e-06, 'epoch': 25.03}\n","{'loss': 0.0342, 'grad_norm': 0.0633072480559349, 'learning_rate': 9.847289626533257e-06, 'epoch': 25.07}\n","{'loss': 0.0305, 'grad_norm': 0.07754866033792496, 'learning_rate': 9.825475935627165e-06, 'epoch': 25.1}\n","{'loss': 0.0273, 'grad_norm': 0.08987481147050858, 'learning_rate': 9.80366307539372e-06, 'epoch': 25.14}\n","{'loss': 0.0238, 'grad_norm': 0.0560021847486496, 'learning_rate': 9.78185114965439e-06, 'epoch': 25.17}\n","{'loss': 0.0277, 'grad_norm': 0.052824635058641434, 'learning_rate': 9.760040262226214e-06, 'epoch': 25.21}\n","{'loss': 0.0392, 'grad_norm': 0.0658341720700264, 'learning_rate': 9.738230516921272e-06, 'epoch': 25.24}\n","{'loss': 0.0273, 'grad_norm': 0.06198159605264664, 'learning_rate': 9.716422017546219e-06, 'epoch': 25.28}\n","{'loss': 0.0273, 'grad_norm': 0.08101822435855865, 'learning_rate': 9.694614867901776e-06, 'epoch': 25.31}\n","{'loss': 0.0203, 'grad_norm': 0.059675779193639755, 'learning_rate': 9.67280917178224e-06, 'epoch': 25.35}\n","{'loss': 0.0268, 'grad_norm': 0.07204492390155792, 'learning_rate': 9.651005032974994e-06, 'epoch': 25.38}\n","{'loss': 0.0261, 'grad_norm': 0.13624343276023865, 'learning_rate': 9.629202555259997e-06, 'epoch': 25.42}\n","{'loss': 0.0369, 'grad_norm': 0.10305682569742203, 'learning_rate': 9.607401842409318e-06, 'epoch': 25.45}\n","{'loss': 0.0293, 'grad_norm': 0.0783674567937851, 'learning_rate': 9.58560299818661e-06, 'epoch': 25.48}\n","{'loss': 0.0357, 'grad_norm': 0.07053633034229279, 'learning_rate': 9.563806126346643e-06, 'epoch': 25.52}\n","{'loss': 0.0224, 'grad_norm': 0.08428824692964554, 'learning_rate': 9.542011330634796e-06, 'epoch': 25.55}\n","{'loss': 0.0332, 'grad_norm': 0.09530571103096008, 'learning_rate': 9.520218714786564e-06, 'epoch': 25.59}\n","{'loss': 0.0301, 'grad_norm': 0.13316218554973602, 'learning_rate': 9.498428382527066e-06, 'epoch': 25.62}\n","{'loss': 0.0288, 'grad_norm': 0.08102241158485413, 'learning_rate': 9.476640437570562e-06, 'epoch': 25.66}\n","{'loss': 0.0249, 'grad_norm': 0.08295547217130661, 'learning_rate': 9.454854983619936e-06, 'epoch': 25.69}\n","{'loss': 0.0267, 'grad_norm': 0.05073942616581917, 'learning_rate': 9.433072124366224e-06, 'epoch': 25.73}\n","{'loss': 0.0246, 'grad_norm': 0.0466499850153923, 'learning_rate': 9.41129196348811e-06, 'epoch': 25.76}\n","{'loss': 0.0292, 'grad_norm': 0.07519828528165817, 'learning_rate': 9.38951460465143e-06, 'epoch': 25.8}\n","{'loss': 0.0216, 'grad_norm': 0.05511855334043503, 'learning_rate': 9.367740151508695e-06, 'epoch': 25.83}\n","{'loss': 0.0284, 'grad_norm': 0.07293477654457092, 'learning_rate': 9.34596870769857e-06, 'epoch': 25.87}\n","{'loss': 0.0283, 'grad_norm': 0.08798342943191528, 'learning_rate': 9.32420037684541e-06, 'epoch': 25.9}\n","{'loss': 0.0287, 'grad_norm': 0.05791597068309784, 'learning_rate': 9.302435262558748e-06, 'epoch': 25.93}\n","{'loss': 0.0325, 'grad_norm': 0.07817631214857101, 'learning_rate': 9.280673468432807e-06, 'epoch': 25.97}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 2\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.0299, 'grad_norm': 0.12294723838567734, 'learning_rate': 9.258915098046008e-06, 'epoch': 26.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2d3517e16e784bda80f59dd21afed046","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/32 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_model/checkpoint-3770\n","loading configuration file /home/raza/Downloads/Phi-3-mini-4k-instruct/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 2047,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer config file saved in ./finetuned_model/checkpoint-3770/tokenizer_config.json\n","Special tokens file saved in ./finetuned_model/checkpoint-3770/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.037072669714689255, 'eval_runtime': 6.884, 'eval_samples_per_second': 9.152, 'eval_steps_per_second': 4.648, 'epoch': 26.0}\n","{'loss': 0.0235, 'grad_norm': 0.06891174614429474, 'learning_rate': 9.237160254960477e-06, 'epoch': 26.03}\n","{'loss': 0.0233, 'grad_norm': 0.05304296314716339, 'learning_rate': 9.215409042721553e-06, 'epoch': 26.07}\n","{'loss': 0.0227, 'grad_norm': 0.0881737768650055, 'learning_rate': 9.193661564857283e-06, 'epoch': 26.1}\n","{'loss': 0.0324, 'grad_norm': 0.10912938416004181, 'learning_rate': 9.17191792487796e-06, 'epoch': 26.14}\n","{'loss': 0.0265, 'grad_norm': 0.08438055962324142, 'learning_rate': 9.150178226275584e-06, 'epoch': 26.17}\n","{'loss': 0.032, 'grad_norm': 0.07056000828742981, 'learning_rate': 9.128442572523418e-06, 'epoch': 26.21}\n","{'loss': 0.0244, 'grad_norm': 0.08611530065536499, 'learning_rate': 9.106711067075464e-06, 'epoch': 26.24}\n","{'loss': 0.0287, 'grad_norm': 0.07677388936281204, 'learning_rate': 9.084983813365977e-06, 'epoch': 26.28}\n","{'loss': 0.0304, 'grad_norm': 0.08595331758260727, 'learning_rate': 9.06326091480898e-06, 'epoch': 26.31}\n","{'loss': 0.0241, 'grad_norm': 0.08691651374101639, 'learning_rate': 9.04154247479776e-06, 'epoch': 26.35}\n","{'loss': 0.0349, 'grad_norm': 0.13332439959049225, 'learning_rate': 9.019828596704394e-06, 'epoch': 26.38}\n","{'loss': 0.0223, 'grad_norm': 0.0667630061507225, 'learning_rate': 8.99811938387924e-06, 'epoch': 26.42}\n","{'loss': 0.0313, 'grad_norm': 0.05786430835723877, 'learning_rate': 8.976414939650443e-06, 'epoch': 26.45}\n","{'loss': 0.0292, 'grad_norm': 0.04525059089064598, 'learning_rate': 8.954715367323468e-06, 'epoch': 26.48}\n","{'loss': 0.0294, 'grad_norm': 0.05925028398633003, 'learning_rate': 8.933020770180574e-06, 'epoch': 26.52}\n","{'loss': 0.0266, 'grad_norm': 0.07431481778621674, 'learning_rate': 8.911331251480357e-06, 'epoch': 26.55}\n","{'loss': 0.0285, 'grad_norm': 0.06616278737783432, 'learning_rate': 8.889646914457225e-06, 'epoch': 26.59}\n","{'loss': 0.028, 'grad_norm': 0.07791529595851898, 'learning_rate': 8.867967862320935e-06, 'epoch': 26.62}\n","{'loss': 0.0219, 'grad_norm': 0.07664564251899719, 'learning_rate': 8.846294198256085e-06, 'epoch': 26.66}\n","{'loss': 0.0306, 'grad_norm': 0.038451530039310455, 'learning_rate': 8.824626025421625e-06, 'epoch': 26.69}\n","{'loss': 0.0379, 'grad_norm': 0.08651850372552872, 'learning_rate': 8.802963446950378e-06, 'epoch': 26.73}\n","{'loss': 0.024, 'grad_norm': 0.06333901733160019, 'learning_rate': 8.781306565948528e-06, 'epoch': 26.76}\n","{'loss': 0.031, 'grad_norm': 0.05626966431736946, 'learning_rate': 8.75965548549515e-06, 'epoch': 26.8}\n","{'loss': 0.023, 'grad_norm': 0.06660017371177673, 'learning_rate': 8.738010308641705e-06, 'epoch': 26.83}\n","{'loss': 0.0341, 'grad_norm': 0.07026420533657074, 'learning_rate': 8.716371138411557e-06, 'epoch': 26.87}\n","{'loss': 0.0235, 'grad_norm': 0.06921932846307755, 'learning_rate': 8.694738077799487e-06, 'epoch': 26.9}\n","{'loss': 0.0306, 'grad_norm': 0.088338203728199, 'learning_rate': 8.673111229771182e-06, 'epoch': 26.93}\n","{'loss': 0.0345, 'grad_norm': 0.07774729281663895, 'learning_rate': 8.651490697262773e-06, 'epoch': 26.97}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 2\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.0316, 'grad_norm': 0.12536221742630005, 'learning_rate': 8.629876583180322e-06, 'epoch': 27.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c6a4834c32234d9d8783b721b747a4d0","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/32 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_model/checkpoint-3915\n","loading configuration file /home/raza/Downloads/Phi-3-mini-4k-instruct/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 2047,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer config file saved in ./finetuned_model/checkpoint-3915/tokenizer_config.json\n","Special tokens file saved in ./finetuned_model/checkpoint-3915/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.0373259037733078, 'eval_runtime': 6.8826, 'eval_samples_per_second': 9.154, 'eval_steps_per_second': 4.649, 'epoch': 27.0}\n","{'loss': 0.0265, 'grad_norm': 0.05809590592980385, 'learning_rate': 8.60826899039935e-06, 'epoch': 27.03}\n","{'loss': 0.0272, 'grad_norm': 0.05742407962679863, 'learning_rate': 8.586668021764328e-06, 'epoch': 27.07}\n","{'loss': 0.0249, 'grad_norm': 0.06598392874002457, 'learning_rate': 8.56507378008821e-06, 'epoch': 27.1}\n","{'loss': 0.0302, 'grad_norm': 0.08548672497272491, 'learning_rate': 8.543486368151926e-06, 'epoch': 27.14}\n","{'loss': 0.0312, 'grad_norm': 0.08268078416585922, 'learning_rate': 8.521905888703894e-06, 'epoch': 27.17}\n","{'loss': 0.0275, 'grad_norm': 0.11927108466625214, 'learning_rate': 8.50033244445955e-06, 'epoch': 27.21}\n","{'loss': 0.0197, 'grad_norm': 0.06505869328975677, 'learning_rate': 8.478766138100834e-06, 'epoch': 27.24}\n","{'loss': 0.0266, 'grad_norm': 0.08993908762931824, 'learning_rate': 8.457207072275712e-06, 'epoch': 27.28}\n","{'loss': 0.037, 'grad_norm': 0.08734691143035889, 'learning_rate': 8.43565534959769e-06, 'epoch': 27.31}\n","{'loss': 0.0259, 'grad_norm': 0.06146436557173729, 'learning_rate': 8.41411107264533e-06, 'epoch': 27.35}\n","{'loss': 0.0331, 'grad_norm': 0.09276694059371948, 'learning_rate': 8.392574343961739e-06, 'epoch': 27.38}\n","{'loss': 0.0356, 'grad_norm': 0.08257555961608887, 'learning_rate': 8.371045266054114e-06, 'epoch': 27.42}\n","{'loss': 0.035, 'grad_norm': 0.060373254120349884, 'learning_rate': 8.349523941393224e-06, 'epoch': 27.45}\n","{'loss': 0.021, 'grad_norm': 0.07055329531431198, 'learning_rate': 8.328010472412943e-06, 'epoch': 27.48}\n","{'loss': 0.0259, 'grad_norm': 0.07846732437610626, 'learning_rate': 8.306504961509755e-06, 'epoch': 27.52}\n","{'loss': 0.0284, 'grad_norm': 0.05554363131523132, 'learning_rate': 8.285007511042259e-06, 'epoch': 27.55}\n","{'loss': 0.0264, 'grad_norm': 0.12084215879440308, 'learning_rate': 8.263518223330698e-06, 'epoch': 27.59}\n","{'loss': 0.0244, 'grad_norm': 0.06658022850751877, 'learning_rate': 8.242037200656455e-06, 'epoch': 27.62}\n","{'loss': 0.0246, 'grad_norm': 0.07251347601413727, 'learning_rate': 8.220564545261585e-06, 'epoch': 27.66}\n","{'loss': 0.0243, 'grad_norm': 0.08837411552667618, 'learning_rate': 8.199100359348303e-06, 'epoch': 27.69}\n","{'loss': 0.0298, 'grad_norm': 0.15214738249778748, 'learning_rate': 8.177644745078525e-06, 'epoch': 27.73}\n","{'loss': 0.0323, 'grad_norm': 0.07705926895141602, 'learning_rate': 8.156197804573368e-06, 'epoch': 27.76}\n","{'loss': 0.0315, 'grad_norm': 0.07148968428373337, 'learning_rate': 8.134759639912655e-06, 'epoch': 27.8}\n","{'loss': 0.0269, 'grad_norm': 0.06983460485935211, 'learning_rate': 8.11333035313445e-06, 'epoch': 27.83}\n","{'loss': 0.0278, 'grad_norm': 0.08636202663183212, 'learning_rate': 8.091910046234552e-06, 'epoch': 27.87}\n","{'loss': 0.0245, 'grad_norm': 0.07148649543523788, 'learning_rate': 8.070498821166031e-06, 'epoch': 27.9}\n","{'loss': 0.0226, 'grad_norm': 0.0981387048959732, 'learning_rate': 8.04909677983872e-06, 'epoch': 27.93}\n","{'loss': 0.0339, 'grad_norm': 0.047655537724494934, 'learning_rate': 8.027704024118742e-06, 'epoch': 27.97}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 2\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.0229, 'grad_norm': 0.07921142876148224, 'learning_rate': 8.00632065582803e-06, 'epoch': 28.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ae9ed25f9fff4a13bbcbcebe54c0949d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/32 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_model/checkpoint-4060\n","loading configuration file /home/raza/Downloads/Phi-3-mini-4k-instruct/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 2047,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer config file saved in ./finetuned_model/checkpoint-4060/tokenizer_config.json\n","Special tokens file saved in ./finetuned_model/checkpoint-4060/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.037367962300777435, 'eval_runtime': 6.8822, 'eval_samples_per_second': 9.154, 'eval_steps_per_second': 4.65, 'epoch': 28.0}\n","{'loss': 0.0312, 'grad_norm': 0.08048124611377716, 'learning_rate': 7.984946776743829e-06, 'epoch': 28.03}\n","{'loss': 0.023, 'grad_norm': 0.08054837584495544, 'learning_rate': 7.963582488598227e-06, 'epoch': 28.07}\n","{'loss': 0.0327, 'grad_norm': 0.0971958115696907, 'learning_rate': 7.942227893077652e-06, 'epoch': 28.1}\n","{'loss': 0.0233, 'grad_norm': 0.09293553978204727, 'learning_rate': 7.92088309182241e-06, 'epoch': 28.14}\n","{'loss': 0.0203, 'grad_norm': 0.12084190547466278, 'learning_rate': 7.899548186426177e-06, 'epoch': 28.17}\n","{'loss': 0.0331, 'grad_norm': 0.05095755308866501, 'learning_rate': 7.878223278435539e-06, 'epoch': 28.21}\n","{'loss': 0.0334, 'grad_norm': 0.08053430169820786, 'learning_rate': 7.856908469349495e-06, 'epoch': 28.24}\n","{'loss': 0.0236, 'grad_norm': 0.06441955268383026, 'learning_rate': 7.835603860618973e-06, 'epoch': 28.28}\n","{'loss': 0.0246, 'grad_norm': 0.06414038687944412, 'learning_rate': 7.814309553646357e-06, 'epoch': 28.31}\n","{'loss': 0.0393, 'grad_norm': 0.057921964675188065, 'learning_rate': 7.793025649784991e-06, 'epoch': 28.35}\n","{'loss': 0.0286, 'grad_norm': 0.06992053985595703, 'learning_rate': 7.771752250338712e-06, 'epoch': 28.38}\n","{'loss': 0.0262, 'grad_norm': 0.1118554174900055, 'learning_rate': 7.750489456561351e-06, 'epoch': 28.42}\n","{'loss': 0.0329, 'grad_norm': 0.12274186313152313, 'learning_rate': 7.72923736965627e-06, 'epoch': 28.45}\n","{'loss': 0.0243, 'grad_norm': 0.07365406304597855, 'learning_rate': 7.70799609077586e-06, 'epoch': 28.48}\n","{'loss': 0.0257, 'grad_norm': 0.08354116976261139, 'learning_rate': 7.686765721021077e-06, 'epoch': 28.52}\n","{'loss': 0.0217, 'grad_norm': 0.0851234421133995, 'learning_rate': 7.66554636144095e-06, 'epoch': 28.55}\n","{'loss': 0.0304, 'grad_norm': 0.08288409560918808, 'learning_rate': 7.644338113032101e-06, 'epoch': 28.59}\n","{'loss': 0.0206, 'grad_norm': 0.07113584876060486, 'learning_rate': 7.623141076738271e-06, 'epoch': 28.62}\n","{'loss': 0.0307, 'grad_norm': 0.048036810010671616, 'learning_rate': 7.601955353449838e-06, 'epoch': 28.66}\n","{'loss': 0.0292, 'grad_norm': 0.06108575314283371, 'learning_rate': 7.580781044003324e-06, 'epoch': 28.69}\n","{'loss': 0.0272, 'grad_norm': 0.08570826798677444, 'learning_rate': 7.559618249180935e-06, 'epoch': 28.73}\n","{'loss': 0.0276, 'grad_norm': 0.09000545740127563, 'learning_rate': 7.53846706971007e-06, 'epoch': 28.76}\n","{'loss': 0.0229, 'grad_norm': 0.07239729166030884, 'learning_rate': 7.5173276062628364e-06, 'epoch': 28.8}\n","{'loss': 0.0308, 'grad_norm': 0.09574836492538452, 'learning_rate': 7.496199959455584e-06, 'epoch': 28.83}\n","{'loss': 0.028, 'grad_norm': 0.06299983710050583, 'learning_rate': 7.4750842298484205e-06, 'epoch': 28.87}\n","{'loss': 0.0248, 'grad_norm': 0.11387293040752411, 'learning_rate': 7.4539805179447234e-06, 'epoch': 28.9}\n","{'loss': 0.0289, 'grad_norm': 0.09080372750759125, 'learning_rate': 7.4328889241906795e-06, 'epoch': 28.93}\n","{'loss': 0.0237, 'grad_norm': 0.08252125233411789, 'learning_rate': 7.411809548974792e-06, 'epoch': 28.97}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 2\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.0315, 'grad_norm': 0.06944422423839569, 'learning_rate': 7.3907424926274115e-06, 'epoch': 29.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"eb871097ec5c46c09ffc2730eef98760","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/32 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_model/checkpoint-4205\n","loading configuration file /home/raza/Downloads/Phi-3-mini-4k-instruct/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 2047,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer config file saved in ./finetuned_model/checkpoint-4205/tokenizer_config.json\n","Special tokens file saved in ./finetuned_model/checkpoint-4205/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.03777090832591057, 'eval_runtime': 6.8834, 'eval_samples_per_second': 9.152, 'eval_steps_per_second': 4.649, 'epoch': 29.0}\n","{'loss': 0.0285, 'grad_norm': 0.062428951263427734, 'learning_rate': 7.3696878554202525e-06, 'epoch': 29.03}\n","{'loss': 0.0221, 'grad_norm': 0.06354544311761856, 'learning_rate': 7.348645737565919e-06, 'epoch': 29.07}\n","{'loss': 0.0209, 'grad_norm': 0.07725328207015991, 'learning_rate': 7.327616239217432e-06, 'epoch': 29.1}\n","{'loss': 0.0387, 'grad_norm': 0.08969204127788544, 'learning_rate': 7.306599460467741e-06, 'epoch': 29.14}\n","{'loss': 0.0256, 'grad_norm': 0.09614239633083344, 'learning_rate': 7.285595501349259e-06, 'epoch': 29.17}\n","{'loss': 0.0241, 'grad_norm': 0.0980062335729599, 'learning_rate': 7.26460446183338e-06, 'epoch': 29.21}\n","{'loss': 0.0314, 'grad_norm': 0.08231943100690842, 'learning_rate': 7.243626441830009e-06, 'epoch': 29.24}\n","{'loss': 0.0317, 'grad_norm': 0.07075371593236923, 'learning_rate': 7.2226615411870796e-06, 'epoch': 29.28}\n","{'loss': 0.0293, 'grad_norm': 0.1178261786699295, 'learning_rate': 7.201709859690081e-06, 'epoch': 29.31}\n","{'loss': 0.0219, 'grad_norm': 0.0790090262889862, 'learning_rate': 7.180771497061587e-06, 'epoch': 29.35}\n","{'loss': 0.0211, 'grad_norm': 0.0895763412117958, 'learning_rate': 7.159846552960774e-06, 'epoch': 29.38}\n","{'loss': 0.0252, 'grad_norm': 0.10642556846141815, 'learning_rate': 7.13893512698296e-06, 'epoch': 29.42}\n","{'loss': 0.0258, 'grad_norm': 0.1059831753373146, 'learning_rate': 7.118037318659108e-06, 'epoch': 29.45}\n","{'loss': 0.026, 'grad_norm': 0.07318364083766937, 'learning_rate': 7.097153227455379e-06, 'epoch': 29.48}\n","{'loss': 0.0278, 'grad_norm': 0.061824288219213486, 'learning_rate': 7.076282952772634e-06, 'epoch': 29.52}\n","{'loss': 0.0251, 'grad_norm': 0.059238020330667496, 'learning_rate': 7.055426593945982e-06, 'epoch': 29.55}\n","{'loss': 0.0281, 'grad_norm': 0.08069410175085068, 'learning_rate': 7.034584250244292e-06, 'epoch': 29.59}\n","{'loss': 0.0237, 'grad_norm': 0.05572619289159775, 'learning_rate': 7.0137560208697264e-06, 'epoch': 29.62}\n","{'loss': 0.0221, 'grad_norm': 0.057085487991571426, 'learning_rate': 6.992942004957271e-06, 'epoch': 29.66}\n","{'loss': 0.0425, 'grad_norm': 0.14038430154323578, 'learning_rate': 6.972142301574256e-06, 'epoch': 29.69}\n","{'loss': 0.0236, 'grad_norm': 0.08796985447406769, 'learning_rate': 6.951357009719893e-06, 'epoch': 29.73}\n","{'loss': 0.0346, 'grad_norm': 0.09041126817464828, 'learning_rate': 6.9305862283248005e-06, 'epoch': 29.76}\n","{'loss': 0.0305, 'grad_norm': 0.0973849669098854, 'learning_rate': 6.909830056250527e-06, 'epoch': 29.8}\n","{'loss': 0.0275, 'grad_norm': 0.05853103846311569, 'learning_rate': 6.889088592289092e-06, 'epoch': 29.83}\n","{'loss': 0.0283, 'grad_norm': 0.06901436299085617, 'learning_rate': 6.8683619351625065e-06, 'epoch': 29.87}\n","{'loss': 0.0226, 'grad_norm': 0.062311701476573944, 'learning_rate': 6.847650183522307e-06, 'epoch': 29.9}\n","{'loss': 0.0292, 'grad_norm': 0.09949322044849396, 'learning_rate': 6.826953435949081e-06, 'epoch': 29.93}\n","{'loss': 0.0357, 'grad_norm': 0.0744461938738823, 'learning_rate': 6.806271790952008e-06, 'epoch': 29.97}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 2\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.0223, 'grad_norm': 0.18426059186458588, 'learning_rate': 6.785605346968387e-06, 'epoch': 30.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0b27753b01c84d80984dd2cc38f956bb","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/32 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_model/checkpoint-4350\n","loading configuration file /home/raza/Downloads/Phi-3-mini-4k-instruct/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 2047,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer config file saved in ./finetuned_model/checkpoint-4350/tokenizer_config.json\n","Special tokens file saved in ./finetuned_model/checkpoint-4350/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.038366787135601044, 'eval_runtime': 6.8843, 'eval_samples_per_second': 9.151, 'eval_steps_per_second': 4.648, 'epoch': 30.0}\n","{'loss': 0.0257, 'grad_norm': 0.11836399137973785, 'learning_rate': 6.7649542023631545e-06, 'epoch': 30.03}\n","{'loss': 0.023, 'grad_norm': 0.13316339254379272, 'learning_rate': 6.744318455428436e-06, 'epoch': 30.07}\n","{'loss': 0.0281, 'grad_norm': 0.07308385521173477, 'learning_rate': 6.723698204383067e-06, 'epoch': 30.1}\n","{'loss': 0.0311, 'grad_norm': 0.058335743844509125, 'learning_rate': 6.70309354737213e-06, 'epoch': 30.14}\n","{'loss': 0.0233, 'grad_norm': 0.09873541444540024, 'learning_rate': 6.682504582466482e-06, 'epoch': 30.17}\n","{'loss': 0.0217, 'grad_norm': 0.05101218447089195, 'learning_rate': 6.661931407662292e-06, 'epoch': 30.21}\n","{'loss': 0.0346, 'grad_norm': 0.06977202743291855, 'learning_rate': 6.6413741208805795e-06, 'epoch': 30.24}\n","{'loss': 0.0349, 'grad_norm': 0.14045605063438416, 'learning_rate': 6.6208328199667305e-06, 'epoch': 30.28}\n","{'loss': 0.0378, 'grad_norm': 0.09309227019548416, 'learning_rate': 6.600307602690057e-06, 'epoch': 30.31}\n","{'loss': 0.03, 'grad_norm': 0.08435215801000595, 'learning_rate': 6.579798566743314e-06, 'epoch': 30.35}\n","{'loss': 0.0351, 'grad_norm': 0.0637584999203682, 'learning_rate': 6.5593058097422315e-06, 'epoch': 30.38}\n","{'loss': 0.0264, 'grad_norm': 0.058396074920892715, 'learning_rate': 6.538829429225068e-06, 'epoch': 30.42}\n","{'loss': 0.0284, 'grad_norm': 0.09680839627981186, 'learning_rate': 6.518369522652136e-06, 'epoch': 30.45}\n","{'loss': 0.0288, 'grad_norm': 0.090425044298172, 'learning_rate': 6.497926187405326e-06, 'epoch': 30.48}\n","{'loss': 0.0286, 'grad_norm': 0.0663478672504425, 'learning_rate': 6.4774995207876654e-06, 'epoch': 30.52}\n","{'loss': 0.0249, 'grad_norm': 0.07579783350229263, 'learning_rate': 6.4570896200228415e-06, 'epoch': 30.55}\n","{'loss': 0.0313, 'grad_norm': 0.12711971998214722, 'learning_rate': 6.436696582254742e-06, 'epoch': 30.59}\n","{'loss': 0.0223, 'grad_norm': 0.08422811329364777, 'learning_rate': 6.4163205045469975e-06, 'epoch': 30.62}\n","{'loss': 0.0252, 'grad_norm': 0.07213345170021057, 'learning_rate': 6.3959614838825045e-06, 'epoch': 30.66}\n","{'loss': 0.0235, 'grad_norm': 0.09385041147470474, 'learning_rate': 6.375619617162985e-06, 'epoch': 30.69}\n","{'loss': 0.0215, 'grad_norm': 0.07502000033855438, 'learning_rate': 6.355295001208504e-06, 'epoch': 30.73}\n","{'loss': 0.0253, 'grad_norm': 0.07468320429325104, 'learning_rate': 6.334987732757028e-06, 'epoch': 30.76}\n","{'loss': 0.0214, 'grad_norm': 0.07496282458305359, 'learning_rate': 6.314697908463951e-06, 'epoch': 30.8}\n","{'loss': 0.027, 'grad_norm': 0.0925789400935173, 'learning_rate': 6.294425624901638e-06, 'epoch': 30.83}\n","{'loss': 0.0224, 'grad_norm': 0.0755564495921135, 'learning_rate': 6.274170978558971e-06, 'epoch': 30.87}\n","{'loss': 0.0298, 'grad_norm': 0.10039842873811722, 'learning_rate': 6.25393406584088e-06, 'epoch': 30.9}\n","{'loss': 0.027, 'grad_norm': 0.10456332564353943, 'learning_rate': 6.233714983067893e-06, 'epoch': 30.93}\n","{'loss': 0.0242, 'grad_norm': 0.07217749208211899, 'learning_rate': 6.2135138264756715e-06, 'epoch': 30.97}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 2\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.0261, 'grad_norm': 0.1751624047756195, 'learning_rate': 6.1933306922145556e-06, 'epoch': 31.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0a587d21b5f74b3f8405405ccc9e6b41","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/32 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_model/checkpoint-4495\n","loading configuration file /home/raza/Downloads/Phi-3-mini-4k-instruct/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 2047,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer config file saved in ./finetuned_model/checkpoint-4495/tokenizer_config.json\n","Special tokens file saved in ./finetuned_model/checkpoint-4495/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.03801579028367996, 'eval_runtime': 6.8828, 'eval_samples_per_second': 9.153, 'eval_steps_per_second': 4.649, 'epoch': 31.0}\n","{'loss': 0.0328, 'grad_norm': 0.07143480330705643, 'learning_rate': 6.173165676349103e-06, 'epoch': 31.03}\n","{'loss': 0.0287, 'grad_norm': 0.05812644213438034, 'learning_rate': 6.153018874857639e-06, 'epoch': 31.07}\n","{'loss': 0.0268, 'grad_norm': 0.06656871736049652, 'learning_rate': 6.132890383631796e-06, 'epoch': 31.1}\n","{'loss': 0.0225, 'grad_norm': 0.05654679238796234, 'learning_rate': 6.112780298476044e-06, 'epoch': 31.14}\n","{'loss': 0.0202, 'grad_norm': 0.06989990174770355, 'learning_rate': 6.092688715107265e-06, 'epoch': 31.17}\n","{'loss': 0.0272, 'grad_norm': 0.09292610734701157, 'learning_rate': 6.072615729154261e-06, 'epoch': 31.21}\n","{'loss': 0.0229, 'grad_norm': 0.11813348531723022, 'learning_rate': 6.052561436157329e-06, 'epoch': 31.24}\n","{'loss': 0.0269, 'grad_norm': 0.08890306949615479, 'learning_rate': 6.0325259315677895e-06, 'epoch': 31.28}\n","{'loss': 0.0255, 'grad_norm': 0.06499143689870834, 'learning_rate': 6.0125093107475385e-06, 'epoch': 31.31}\n","{'loss': 0.0215, 'grad_norm': 0.05740702524781227, 'learning_rate': 5.9925116689685925e-06, 'epoch': 31.35}\n","{'loss': 0.0239, 'grad_norm': 0.08789348602294922, 'learning_rate': 5.97253310141263e-06, 'epoch': 31.38}\n","{'loss': 0.0301, 'grad_norm': 0.061523228883743286, 'learning_rate': 5.952573703170548e-06, 'epoch': 31.42}\n","{'loss': 0.0319, 'grad_norm': 0.18148308992385864, 'learning_rate': 5.932633569242e-06, 'epoch': 31.45}\n","{'loss': 0.0243, 'grad_norm': 0.0763377845287323, 'learning_rate': 5.912712794534954e-06, 'epoch': 31.48}\n","{'loss': 0.0327, 'grad_norm': 0.090861976146698, 'learning_rate': 5.89281147386523e-06, 'epoch': 31.52}\n","{'loss': 0.0202, 'grad_norm': 0.10441679507493973, 'learning_rate': 5.872929701956054e-06, 'epoch': 31.55}\n","{'loss': 0.0282, 'grad_norm': 0.08050727099180222, 'learning_rate': 5.853067573437612e-06, 'epoch': 31.59}\n","{'loss': 0.0252, 'grad_norm': 0.10685250908136368, 'learning_rate': 5.833225182846587e-06, 'epoch': 31.62}\n","{'loss': 0.0339, 'grad_norm': 0.0674719363451004, 'learning_rate': 5.813402624625722e-06, 'epoch': 31.66}\n","{'loss': 0.0284, 'grad_norm': 0.12795667350292206, 'learning_rate': 5.793599993123363e-06, 'epoch': 31.69}\n","{'loss': 0.035, 'grad_norm': 0.08993836492300034, 'learning_rate': 5.773817382593008e-06, 'epoch': 31.73}\n","{'loss': 0.0273, 'grad_norm': 0.07365873456001282, 'learning_rate': 5.754054887192871e-06, 'epoch': 31.76}\n","{'loss': 0.0259, 'grad_norm': 0.06639392673969269, 'learning_rate': 5.7343126009854215e-06, 'epoch': 31.8}\n","{'loss': 0.0252, 'grad_norm': 0.11162912845611572, 'learning_rate': 5.714590617936931e-06, 'epoch': 31.83}\n","{'loss': 0.0328, 'grad_norm': 0.1026640385389328, 'learning_rate': 5.694889031917047e-06, 'epoch': 31.87}\n","{'loss': 0.032, 'grad_norm': 0.09962542355060577, 'learning_rate': 5.675207936698337e-06, 'epoch': 31.9}\n","{'loss': 0.025, 'grad_norm': 0.06219135969877243, 'learning_rate': 5.65554742595583e-06, 'epoch': 31.93}\n","{'loss': 0.023, 'grad_norm': 0.11597328633069992, 'learning_rate': 5.635907593266578e-06, 'epoch': 31.97}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 2\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.0207, 'grad_norm': 0.13573183119297028, 'learning_rate': 5.616288532109225e-06, 'epoch': 32.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8539d51741e1444d965b9bb01b611e3b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/32 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_model/checkpoint-4640\n","loading configuration file /home/raza/Downloads/Phi-3-mini-4k-instruct/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 2047,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer config file saved in ./finetuned_model/checkpoint-4640/tokenizer_config.json\n","Special tokens file saved in ./finetuned_model/checkpoint-4640/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.038618940860033035, 'eval_runtime': 6.8827, 'eval_samples_per_second': 9.153, 'eval_steps_per_second': 4.649, 'epoch': 32.0}\n","{'loss': 0.0239, 'grad_norm': 0.10173540562391281, 'learning_rate': 5.596690335863542e-06, 'epoch': 32.03}\n","{'loss': 0.0222, 'grad_norm': 0.08784297108650208, 'learning_rate': 5.5771130978099896e-06, 'epoch': 32.07}\n","{'loss': 0.021, 'grad_norm': 0.062066901475191116, 'learning_rate': 5.5575569111292725e-06, 'epoch': 32.1}\n","{'loss': 0.0337, 'grad_norm': 0.07865682244300842, 'learning_rate': 5.5380218689019125e-06, 'epoch': 32.14}\n","{'loss': 0.028, 'grad_norm': 0.07559805363416672, 'learning_rate': 5.518508064107776e-06, 'epoch': 32.17}\n","{'loss': 0.0264, 'grad_norm': 0.08731958270072937, 'learning_rate': 5.499015589625649e-06, 'epoch': 32.21}\n","{'loss': 0.023, 'grad_norm': 0.05950476974248886, 'learning_rate': 5.479544538232804e-06, 'epoch': 32.24}\n","{'loss': 0.027, 'grad_norm': 0.06714548915624619, 'learning_rate': 5.460095002604533e-06, 'epoch': 32.28}\n","{'loss': 0.0229, 'grad_norm': 0.05872376263141632, 'learning_rate': 5.44066707531373e-06, 'epoch': 32.31}\n","{'loss': 0.0301, 'grad_norm': 0.15729743242263794, 'learning_rate': 5.421260848830432e-06, 'epoch': 32.35}\n","{'loss': 0.0349, 'grad_norm': 0.11012230813503265, 'learning_rate': 5.401876415521402e-06, 'epoch': 32.38}\n","{'loss': 0.0243, 'grad_norm': 0.07607968896627426, 'learning_rate': 5.382513867649663e-06, 'epoch': 32.42}\n","{'loss': 0.0285, 'grad_norm': 0.0808902159333229, 'learning_rate': 5.36317329737407e-06, 'epoch': 32.45}\n","{'loss': 0.0316, 'grad_norm': 0.09959904104471207, 'learning_rate': 5.343854796748886e-06, 'epoch': 32.48}\n","{'loss': 0.0221, 'grad_norm': 0.11649841070175171, 'learning_rate': 5.324558457723319e-06, 'epoch': 32.52}\n","{'loss': 0.0321, 'grad_norm': 0.059923313558101654, 'learning_rate': 5.305284372141095e-06, 'epoch': 32.55}\n","{'loss': 0.0279, 'grad_norm': 0.06562859565019608, 'learning_rate': 5.286032631740023e-06, 'epoch': 32.59}\n","{'loss': 0.0343, 'grad_norm': 0.07082541286945343, 'learning_rate': 5.2668033281515676e-06, 'epoch': 32.62}\n","{'loss': 0.025, 'grad_norm': 0.11099527776241302, 'learning_rate': 5.247596552900387e-06, 'epoch': 32.66}\n","{'loss': 0.0232, 'grad_norm': 0.08804929256439209, 'learning_rate': 5.228412397403916e-06, 'epoch': 32.69}\n","{'loss': 0.0247, 'grad_norm': 0.12461686879396439, 'learning_rate': 5.2092509529719375e-06, 'epoch': 32.73}\n","{'loss': 0.0332, 'grad_norm': 0.09250260144472122, 'learning_rate': 5.190112310806126e-06, 'epoch': 32.76}\n","{'loss': 0.0259, 'grad_norm': 0.10197262465953827, 'learning_rate': 5.170996561999631e-06, 'epoch': 32.8}\n","{'loss': 0.0209, 'grad_norm': 0.056249432265758514, 'learning_rate': 5.151903797536631e-06, 'epoch': 32.83}\n","{'loss': 0.0198, 'grad_norm': 0.06915593892335892, 'learning_rate': 5.13283410829192e-06, 'epoch': 32.87}\n","{'loss': 0.0262, 'grad_norm': 0.117491714656353, 'learning_rate': 5.1137875850304545e-06, 'epoch': 32.9}\n","{'loss': 0.0344, 'grad_norm': 0.11623496562242508, 'learning_rate': 5.094764318406921e-06, 'epoch': 32.93}\n","{'loss': 0.0233, 'grad_norm': 0.13048744201660156, 'learning_rate': 5.075764398965331e-06, 'epoch': 32.97}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 2\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.0255, 'grad_norm': 0.11431938409805298, 'learning_rate': 5.056787917138557e-06, 'epoch': 33.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4a110bf6f37b4723b8b24bc62bb41b39","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/32 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_model/checkpoint-4785\n","loading configuration file /home/raza/Downloads/Phi-3-mini-4k-instruct/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 2047,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer config file saved in ./finetuned_model/checkpoint-4785/tokenizer_config.json\n","Special tokens file saved in ./finetuned_model/checkpoint-4785/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.03875565901398659, 'eval_runtime': 6.883, 'eval_samples_per_second': 9.153, 'eval_steps_per_second': 4.649, 'epoch': 33.0}\n","{'loss': 0.0253, 'grad_norm': 0.07996451109647751, 'learning_rate': 5.037834963247922e-06, 'epoch': 33.03}\n","{'loss': 0.0276, 'grad_norm': 0.09105274081230164, 'learning_rate': 5.0189056275027595e-06, 'epoch': 33.07}\n","{'loss': 0.0264, 'grad_norm': 0.09459497034549713, 'learning_rate': 5.000000000000003e-06, 'epoch': 33.1}\n","{'loss': 0.025, 'grad_norm': 0.07542718201875687, 'learning_rate': 4.981118170723726e-06, 'epoch': 33.14}\n","{'loss': 0.0284, 'grad_norm': 0.08119719475507736, 'learning_rate': 4.962260229544738e-06, 'epoch': 33.17}\n","{'loss': 0.0234, 'grad_norm': 0.09797924757003784, 'learning_rate': 4.943426266220156e-06, 'epoch': 33.21}\n","{'loss': 0.0217, 'grad_norm': 0.07478044927120209, 'learning_rate': 4.924616370392962e-06, 'epoch': 33.24}\n","{'loss': 0.0284, 'grad_norm': 0.08827169239521027, 'learning_rate': 4.9058306315915826e-06, 'epoch': 33.28}\n","{'loss': 0.0205, 'grad_norm': 0.10851317644119263, 'learning_rate': 4.887069139229481e-06, 'epoch': 33.31}\n","{'loss': 0.0347, 'grad_norm': 0.14658823609352112, 'learning_rate': 4.8683319826047e-06, 'epoch': 33.35}\n","{'loss': 0.0227, 'grad_norm': 0.08636319637298584, 'learning_rate': 4.849619250899458e-06, 'epoch': 33.38}\n","{'loss': 0.0237, 'grad_norm': 0.06447073072195053, 'learning_rate': 4.830931033179725e-06, 'epoch': 33.42}\n","{'loss': 0.0239, 'grad_norm': 0.0674467533826828, 'learning_rate': 4.812267418394784e-06, 'epoch': 33.45}\n","{'loss': 0.0312, 'grad_norm': 0.06674312055110931, 'learning_rate': 4.793628495376826e-06, 'epoch': 33.48}\n","{'loss': 0.031, 'grad_norm': 0.07354339957237244, 'learning_rate': 4.775014352840512e-06, 'epoch': 33.52}\n","{'loss': 0.0238, 'grad_norm': 0.09549779444932938, 'learning_rate': 4.756425079382553e-06, 'epoch': 33.55}\n","{'loss': 0.0203, 'grad_norm': 0.09869778156280518, 'learning_rate': 4.7378607634813045e-06, 'epoch': 33.59}\n","{'loss': 0.0206, 'grad_norm': 0.14120464026927948, 'learning_rate': 4.7193214934963204e-06, 'epoch': 33.62}\n","{'loss': 0.0311, 'grad_norm': 0.08707637339830399, 'learning_rate': 4.700807357667953e-06, 'epoch': 33.66}\n","{'loss': 0.0253, 'grad_norm': 0.09221784770488739, 'learning_rate': 4.682318444116915e-06, 'epoch': 33.69}\n","{'loss': 0.024, 'grad_norm': 0.08930703997612, 'learning_rate': 4.663854840843885e-06, 'epoch': 33.73}\n","{'loss': 0.0197, 'grad_norm': 0.07676155865192413, 'learning_rate': 4.645416635729063e-06, 'epoch': 33.76}\n","{'loss': 0.0299, 'grad_norm': 0.09363333135843277, 'learning_rate': 4.627003916531761e-06, 'epoch': 33.8}\n","{'loss': 0.0361, 'grad_norm': 0.09321869164705276, 'learning_rate': 4.608616770889998e-06, 'epoch': 33.83}\n","{'loss': 0.0312, 'grad_norm': 0.09762419760227203, 'learning_rate': 4.590255286320062e-06, 'epoch': 33.87}\n","{'loss': 0.0301, 'grad_norm': 0.06486049294471741, 'learning_rate': 4.571919550216107e-06, 'epoch': 33.9}\n","{'loss': 0.0303, 'grad_norm': 0.0802728533744812, 'learning_rate': 4.5536096498497295e-06, 'epoch': 33.93}\n","{'loss': 0.0234, 'grad_norm': 0.07918307185173035, 'learning_rate': 4.535325672369567e-06, 'epoch': 33.97}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 2\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.0297, 'grad_norm': 0.09263128787279129, 'learning_rate': 4.517067704800864e-06, 'epoch': 34.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c817730d3cbf4bd599c109d8f4336b46","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/32 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_model/checkpoint-4930\n","loading configuration file /home/raza/Downloads/Phi-3-mini-4k-instruct/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 2047,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer config file saved in ./finetuned_model/checkpoint-4930/tokenizer_config.json\n","Special tokens file saved in ./finetuned_model/checkpoint-4930/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.03889624401926994, 'eval_runtime': 6.8825, 'eval_samples_per_second': 9.154, 'eval_steps_per_second': 4.649, 'epoch': 34.0}\n","{'loss': 0.0245, 'grad_norm': 0.08507437258958817, 'learning_rate': 4.498835834045067e-06, 'epoch': 34.03}\n","{'loss': 0.0249, 'grad_norm': 0.07654853910207748, 'learning_rate': 4.480630146879419e-06, 'epoch': 34.07}\n","{'loss': 0.0243, 'grad_norm': 0.1466064751148224, 'learning_rate': 4.462450729956531e-06, 'epoch': 34.1}\n","{'loss': 0.0311, 'grad_norm': 0.10216330736875534, 'learning_rate': 4.444297669803981e-06, 'epoch': 34.14}\n","{'loss': 0.0217, 'grad_norm': 0.09037411957979202, 'learning_rate': 4.42617105282389e-06, 'epoch': 34.17}\n","{'loss': 0.0278, 'grad_norm': 0.10828156024217606, 'learning_rate': 4.408070965292534e-06, 'epoch': 34.21}\n","{'loss': 0.0308, 'grad_norm': 0.13355080783367157, 'learning_rate': 4.389997493359905e-06, 'epoch': 34.24}\n","{'loss': 0.0211, 'grad_norm': 0.07465239614248276, 'learning_rate': 4.371950723049314e-06, 'epoch': 34.28}\n","{'loss': 0.0242, 'grad_norm': 0.10366224497556686, 'learning_rate': 4.353930740256997e-06, 'epoch': 34.31}\n","{'loss': 0.026, 'grad_norm': 0.08876001834869385, 'learning_rate': 4.335937630751675e-06, 'epoch': 34.35}\n","{'loss': 0.0301, 'grad_norm': 0.0936891958117485, 'learning_rate': 4.317971480174161e-06, 'epoch': 34.38}\n","{'loss': 0.0255, 'grad_norm': 0.08918496966362, 'learning_rate': 4.30003237403697e-06, 'epoch': 34.42}\n","{'loss': 0.0224, 'grad_norm': 0.12293841689825058, 'learning_rate': 4.282120397723879e-06, 'epoch': 34.45}\n","{'loss': 0.0273, 'grad_norm': 0.0888415053486824, 'learning_rate': 4.264235636489542e-06, 'epoch': 34.48}\n","{'loss': 0.0245, 'grad_norm': 0.07853855937719345, 'learning_rate': 4.246378175459075e-06, 'epoch': 34.52}\n","{'loss': 0.022, 'grad_norm': 0.11365964263677597, 'learning_rate': 4.228548099627665e-06, 'epoch': 34.55}\n","{'loss': 0.0281, 'grad_norm': 0.096350759267807, 'learning_rate': 4.210745493860146e-06, 'epoch': 34.59}\n","{'loss': 0.0341, 'grad_norm': 0.05830096825957298, 'learning_rate': 4.192970442890602e-06, 'epoch': 34.62}\n","{'loss': 0.042, 'grad_norm': 0.0953899696469307, 'learning_rate': 4.17522303132198e-06, 'epoch': 34.66}\n","{'loss': 0.0234, 'grad_norm': 0.060490529984235764, 'learning_rate': 4.157503343625659e-06, 'epoch': 34.69}\n","{'loss': 0.0251, 'grad_norm': 0.10003358870744705, 'learning_rate': 4.1398114641410655e-06, 'epoch': 34.73}\n","{'loss': 0.0223, 'grad_norm': 0.10258440673351288, 'learning_rate': 4.12214747707527e-06, 'epoch': 34.76}\n","{'loss': 0.0216, 'grad_norm': 0.078115314245224, 'learning_rate': 4.1045114665025905e-06, 'epoch': 34.8}\n","{'loss': 0.0274, 'grad_norm': 0.07159154862165451, 'learning_rate': 4.086903516364179e-06, 'epoch': 34.83}\n","{'loss': 0.0277, 'grad_norm': 0.07816150784492493, 'learning_rate': 4.06932371046763e-06, 'epoch': 34.87}\n","{'loss': 0.0218, 'grad_norm': 0.08955695480108261, 'learning_rate': 4.051772132486589e-06, 'epoch': 34.9}\n","{'loss': 0.028, 'grad_norm': 0.07791706919670105, 'learning_rate': 4.0342488659603354e-06, 'epoch': 34.93}\n","{'loss': 0.0324, 'grad_norm': 0.06789617240428925, 'learning_rate': 4.01675399429341e-06, 'epoch': 34.97}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 2\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.0252, 'grad_norm': 0.14006060361862183, 'learning_rate': 3.999287600755192e-06, 'epoch': 35.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7ad0ced814244f9aba926862b6c9e6b9","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/32 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_model/checkpoint-5075\n","loading configuration file /home/raza/Downloads/Phi-3-mini-4k-instruct/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 2047,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer config file saved in ./finetuned_model/checkpoint-5075/tokenizer_config.json\n","Special tokens file saved in ./finetuned_model/checkpoint-5075/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.03956887125968933, 'eval_runtime': 6.8826, 'eval_samples_per_second': 9.153, 'eval_steps_per_second': 4.649, 'epoch': 35.0}\n","{'loss': 0.0252, 'grad_norm': 0.08424044400453568, 'learning_rate': 3.981849768479516e-06, 'epoch': 35.03}\n","{'loss': 0.0232, 'grad_norm': 0.07743138819932938, 'learning_rate': 3.964440580464286e-06, 'epoch': 35.07}\n","{'loss': 0.0213, 'grad_norm': 0.07195182144641876, 'learning_rate': 3.9470601195710575e-06, 'epoch': 35.1}\n","{'loss': 0.0348, 'grad_norm': 0.11507519334554672, 'learning_rate': 3.929708468524655e-06, 'epoch': 35.14}\n","{'loss': 0.0279, 'grad_norm': 0.09240017086267471, 'learning_rate': 3.912385709912794e-06, 'epoch': 35.17}\n","{'loss': 0.0224, 'grad_norm': 0.10958930850028992, 'learning_rate': 3.895091926185653e-06, 'epoch': 35.21}\n","{'loss': 0.029, 'grad_norm': 0.06571801751852036, 'learning_rate': 3.877827199655506e-06, 'epoch': 35.24}\n","{'loss': 0.0253, 'grad_norm': 0.08239578455686569, 'learning_rate': 3.860591612496335e-06, 'epoch': 35.28}\n","{'loss': 0.0246, 'grad_norm': 0.08951668441295624, 'learning_rate': 3.8433852467434175e-06, 'epoch': 35.31}\n","{'loss': 0.0207, 'grad_norm': 0.08952835202217102, 'learning_rate': 3.826208184292952e-06, 'epoch': 35.35}\n","{'loss': 0.0319, 'grad_norm': 0.12403514981269836, 'learning_rate': 3.8090605069016596e-06, 'epoch': 35.38}\n","{'loss': 0.0236, 'grad_norm': 0.07881258428096771, 'learning_rate': 3.7919422961864084e-06, 'epoch': 35.42}\n","{'loss': 0.0205, 'grad_norm': 0.11027618497610092, 'learning_rate': 3.774853633623806e-06, 'epoch': 35.45}\n","{'loss': 0.0218, 'grad_norm': 0.07233811169862747, 'learning_rate': 3.7577946005498224e-06, 'epoch': 35.48}\n","{'loss': 0.0311, 'grad_norm': 0.08124539256095886, 'learning_rate': 3.7407652781594094e-06, 'epoch': 35.52}\n","{'loss': 0.0267, 'grad_norm': 0.1206916943192482, 'learning_rate': 3.7237657475060994e-06, 'epoch': 35.55}\n","{'loss': 0.0207, 'grad_norm': 0.10638292878866196, 'learning_rate': 3.7067960895016277e-06, 'epoch': 35.59}\n","{'loss': 0.0208, 'grad_norm': 0.11274930089712143, 'learning_rate': 3.6898563849155433e-06, 'epoch': 35.62}\n","{'loss': 0.0264, 'grad_norm': 0.08694540709257126, 'learning_rate': 3.67294671437484e-06, 'epoch': 35.66}\n","{'loss': 0.0193, 'grad_norm': 0.10167855024337769, 'learning_rate': 3.6560671583635467e-06, 'epoch': 35.69}\n","{'loss': 0.0268, 'grad_norm': 0.12195208668708801, 'learning_rate': 3.6392177972223596e-06, 'epoch': 35.73}\n","{'loss': 0.0279, 'grad_norm': 0.06792642176151276, 'learning_rate': 3.6223987111482684e-06, 'epoch': 35.76}\n","{'loss': 0.0247, 'grad_norm': 0.122085802257061, 'learning_rate': 3.6056099801941535e-06, 'epoch': 35.8}\n","{'loss': 0.0255, 'grad_norm': 0.09743767976760864, 'learning_rate': 3.5888516842684194e-06, 'epoch': 35.83}\n","{'loss': 0.0411, 'grad_norm': 0.08486204594373703, 'learning_rate': 3.5721239031346067e-06, 'epoch': 35.87}\n","{'loss': 0.0294, 'grad_norm': 0.10139314830303192, 'learning_rate': 3.555426716411028e-06, 'epoch': 35.9}\n","{'loss': 0.0325, 'grad_norm': 0.07737813889980316, 'learning_rate': 3.5387602035703637e-06, 'epoch': 35.93}\n","{'loss': 0.029, 'grad_norm': 0.10594803839921951, 'learning_rate': 3.522124443939302e-06, 'epoch': 35.97}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 2\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.0288, 'grad_norm': 0.1966600865125656, 'learning_rate': 3.505519516698165e-06, 'epoch': 36.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5d249d49161d4930bb2a674ea7ee788a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/32 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_model/checkpoint-5220\n","loading configuration file /home/raza/Downloads/Phi-3-mini-4k-instruct/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 2047,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer config file saved in ./finetuned_model/checkpoint-5220/tokenizer_config.json\n","Special tokens file saved in ./finetuned_model/checkpoint-5220/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.038995057344436646, 'eval_runtime': 6.8828, 'eval_samples_per_second': 9.153, 'eval_steps_per_second': 4.649, 'epoch': 36.0}\n","{'loss': 0.0311, 'grad_norm': 0.07635992765426636, 'learning_rate': 3.4889455008805107e-06, 'epoch': 36.03}\n","{'loss': 0.0249, 'grad_norm': 0.08673406392335892, 'learning_rate': 3.472402475372778e-06, 'epoch': 36.07}\n","{'loss': 0.027, 'grad_norm': 0.095638707280159, 'learning_rate': 3.455890518913897e-06, 'epoch': 36.1}\n","{'loss': 0.0206, 'grad_norm': 0.07479849457740784, 'learning_rate': 3.4394097100949286e-06, 'epoch': 36.14}\n","{'loss': 0.029, 'grad_norm': 0.1109759658575058, 'learning_rate': 3.4229601273586757e-06, 'epoch': 36.17}\n","{'loss': 0.0194, 'grad_norm': 0.06763631105422974, 'learning_rate': 3.4065418489993118e-06, 'epoch': 36.21}\n","{'loss': 0.0239, 'grad_norm': 0.08367322385311127, 'learning_rate': 3.390154953162026e-06, 'epoch': 36.24}\n","{'loss': 0.0306, 'grad_norm': 0.07817166298627853, 'learning_rate': 3.3737995178426276e-06, 'epoch': 36.28}\n","{'loss': 0.0254, 'grad_norm': 0.10218240320682526, 'learning_rate': 3.3574756208871862e-06, 'epoch': 36.31}\n","{'loss': 0.0215, 'grad_norm': 0.11489427834749222, 'learning_rate': 3.3411833399916584e-06, 'epoch': 36.35}\n","{'loss': 0.0294, 'grad_norm': 0.10583864897489548, 'learning_rate': 3.324922752701528e-06, 'epoch': 36.38}\n","{'loss': 0.0211, 'grad_norm': 0.09908312559127808, 'learning_rate': 3.308693936411421e-06, 'epoch': 36.42}\n","{'loss': 0.0291, 'grad_norm': 0.1190650686621666, 'learning_rate': 3.2924969683647424e-06, 'epoch': 36.45}\n","{'loss': 0.0371, 'grad_norm': 0.10743642598390579, 'learning_rate': 3.2763319256533177e-06, 'epoch': 36.48}\n","{'loss': 0.0214, 'grad_norm': 0.0816774070262909, 'learning_rate': 3.2601988852170207e-06, 'epoch': 36.52}\n","{'loss': 0.0224, 'grad_norm': 0.07384311407804489, 'learning_rate': 3.2440979238433977e-06, 'epoch': 36.55}\n","{'loss': 0.0235, 'grad_norm': 0.09569568186998367, 'learning_rate': 3.228029118167311e-06, 'epoch': 36.59}\n","{'loss': 0.026, 'grad_norm': 0.08687568455934525, 'learning_rate': 3.2119925446705824e-06, 'epoch': 36.62}\n","{'loss': 0.0261, 'grad_norm': 0.12525884807109833, 'learning_rate': 3.195988279681609e-06, 'epoch': 36.66}\n","{'loss': 0.0239, 'grad_norm': 0.12499942630529404, 'learning_rate': 3.1800163993750166e-06, 'epoch': 36.69}\n","{'loss': 0.024, 'grad_norm': 0.08546924591064453, 'learning_rate': 3.1640769797712865e-06, 'epoch': 36.73}\n","{'loss': 0.0226, 'grad_norm': 0.12852488458156586, 'learning_rate': 3.148170096736408e-06, 'epoch': 36.76}\n","{'loss': 0.0231, 'grad_norm': 0.07433801889419556, 'learning_rate': 3.1322958259815016e-06, 'epoch': 36.8}\n","{'loss': 0.0197, 'grad_norm': 0.08051259815692902, 'learning_rate': 3.116454243062459e-06, 'epoch': 36.83}\n","{'loss': 0.0236, 'grad_norm': 0.08498778939247131, 'learning_rate': 3.1006454233796035e-06, 'epoch': 36.87}\n","{'loss': 0.0211, 'grad_norm': 0.11059141904115677, 'learning_rate': 3.0848694421773075e-06, 'epoch': 36.9}\n","{'loss': 0.0288, 'grad_norm': 0.11227806657552719, 'learning_rate': 3.069126374543643e-06, 'epoch': 36.93}\n","{'loss': 0.0379, 'grad_norm': 0.06145022436976433, 'learning_rate': 3.0534162954100264e-06, 'epoch': 36.97}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 2\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.0416, 'grad_norm': 0.30879873037338257, 'learning_rate': 3.0377392795508687e-06, 'epoch': 37.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cc5d27b509534b9d9738f86fe04e45fa","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/32 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_model/checkpoint-5365\n","loading configuration file /home/raza/Downloads/Phi-3-mini-4k-instruct/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 2047,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer config file saved in ./finetuned_model/checkpoint-5365/tokenizer_config.json\n","Special tokens file saved in ./finetuned_model/checkpoint-5365/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.0395057387650013, 'eval_runtime': 6.8849, 'eval_samples_per_second': 9.15, 'eval_steps_per_second': 4.648, 'epoch': 37.0}\n","{'loss': 0.0296, 'grad_norm': 0.10499446839094162, 'learning_rate': 3.0220954015832004e-06, 'epoch': 37.03}\n","{'loss': 0.0205, 'grad_norm': 0.11291871219873428, 'learning_rate': 3.0064847359663284e-06, 'epoch': 37.07}\n","{'loss': 0.022, 'grad_norm': 0.10649887472391129, 'learning_rate': 2.990907357001491e-06, 'epoch': 37.1}\n","{'loss': 0.0251, 'grad_norm': 0.10441746562719345, 'learning_rate': 2.975363338831484e-06, 'epoch': 37.14}\n","{'loss': 0.0194, 'grad_norm': 0.11416199803352356, 'learning_rate': 2.9598527554403187e-06, 'epoch': 37.17}\n","{'loss': 0.036, 'grad_norm': 0.10180635005235672, 'learning_rate': 2.944375680652869e-06, 'epoch': 37.21}\n","{'loss': 0.0266, 'grad_norm': 0.10282158851623535, 'learning_rate': 2.9289321881345257e-06, 'epoch': 37.24}\n","{'loss': 0.0242, 'grad_norm': 0.09098181128501892, 'learning_rate': 2.913522351390834e-06, 'epoch': 37.28}\n","{'loss': 0.0253, 'grad_norm': 0.08084426075220108, 'learning_rate': 2.898146243767146e-06, 'epoch': 37.31}\n","{'loss': 0.0273, 'grad_norm': 0.06553561985492706, 'learning_rate': 2.8828039384482874e-06, 'epoch': 37.35}\n","{'loss': 0.0324, 'grad_norm': 0.08078205585479736, 'learning_rate': 2.867495508458186e-06, 'epoch': 37.38}\n","{'loss': 0.0265, 'grad_norm': 0.10542765259742737, 'learning_rate': 2.8522210266595386e-06, 'epoch': 37.42}\n","{'loss': 0.0258, 'grad_norm': 0.07602835446596146, 'learning_rate': 2.8369805657534576e-06, 'epoch': 37.45}\n","{'loss': 0.0328, 'grad_norm': 0.14921356737613678, 'learning_rate': 2.821774198279138e-06, 'epoch': 37.48}\n","{'loss': 0.0277, 'grad_norm': 0.07107236981391907, 'learning_rate': 2.8066019966134907e-06, 'epoch': 37.52}\n","{'loss': 0.025, 'grad_norm': 0.12174341082572937, 'learning_rate': 2.791464032970812e-06, 'epoch': 37.55}\n","{'loss': 0.0284, 'grad_norm': 0.08756944537162781, 'learning_rate': 2.776360379402445e-06, 'epoch': 37.59}\n","{'loss': 0.0298, 'grad_norm': 0.09015161544084549, 'learning_rate': 2.761291107796421e-06, 'epoch': 37.62}\n","{'loss': 0.0214, 'grad_norm': 0.07144419848918915, 'learning_rate': 2.746256289877126e-06, 'epoch': 37.66}\n","{'loss': 0.024, 'grad_norm': 0.10245063155889511, 'learning_rate': 2.7312559972049603e-06, 'epoch': 37.69}\n","{'loss': 0.0274, 'grad_norm': 0.1491713523864746, 'learning_rate': 2.716290301175999e-06, 'epoch': 37.73}\n","{'loss': 0.0223, 'grad_norm': 0.10090012848377228, 'learning_rate': 2.7013592730216464e-06, 'epoch': 37.76}\n","{'loss': 0.0193, 'grad_norm': 0.09066130965948105, 'learning_rate': 2.6864629838082957e-06, 'epoch': 37.8}\n","{'loss': 0.0253, 'grad_norm': 0.14675676822662354, 'learning_rate': 2.671601504437007e-06, 'epoch': 37.83}\n","{'loss': 0.0282, 'grad_norm': 0.07801873981952667, 'learning_rate': 2.656774905643147e-06, 'epoch': 37.87}\n","{'loss': 0.0252, 'grad_norm': 0.1078856885433197, 'learning_rate': 2.641983257996067e-06, 'epoch': 37.9}\n","{'loss': 0.0226, 'grad_norm': 0.07533867657184601, 'learning_rate': 2.6272266318987606e-06, 'epoch': 37.93}\n","{'loss': 0.0302, 'grad_norm': 0.09477278590202332, 'learning_rate': 2.61250509758754e-06, 'epoch': 37.97}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 2\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.0233, 'grad_norm': 0.15586329996585846, 'learning_rate': 2.5978187251316823e-06, 'epoch': 38.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"51b72ea3bd2b4472a7e72be160839cb4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/32 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_model/checkpoint-5510\n","loading configuration file /home/raza/Downloads/Phi-3-mini-4k-instruct/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 2047,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer config file saved in ./finetuned_model/checkpoint-5510/tokenizer_config.json\n","Special tokens file saved in ./finetuned_model/checkpoint-5510/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.03939200937747955, 'eval_runtime': 6.8833, 'eval_samples_per_second': 9.153, 'eval_steps_per_second': 4.649, 'epoch': 38.0}\n","{'loss': 0.0233, 'grad_norm': 0.08370925486087799, 'learning_rate': 2.5831675844331094e-06, 'epoch': 38.03}\n","{'loss': 0.0337, 'grad_norm': 0.08594640344381332, 'learning_rate': 2.5685517452260566e-06, 'epoch': 38.07}\n","{'loss': 0.0273, 'grad_norm': 0.07532823830842972, 'learning_rate': 2.5539712770767377e-06, 'epoch': 38.1}\n","{'loss': 0.0297, 'grad_norm': 0.11896180361509323, 'learning_rate': 2.539426249383006e-06, 'epoch': 38.14}\n","{'loss': 0.0312, 'grad_norm': 0.08756357431411743, 'learning_rate': 2.5249167313740307e-06, 'epoch': 38.17}\n","{'loss': 0.023, 'grad_norm': 0.05668226629495621, 'learning_rate': 2.5104427921099783e-06, 'epoch': 38.21}\n","{'loss': 0.0274, 'grad_norm': 0.09591224789619446, 'learning_rate': 2.496004500481661e-06, 'epoch': 38.24}\n","{'loss': 0.0261, 'grad_norm': 0.09206698834896088, 'learning_rate': 2.4816019252102274e-06, 'epoch': 38.28}\n","{'loss': 0.0257, 'grad_norm': 0.07908158749341965, 'learning_rate': 2.4672351348468225e-06, 'epoch': 38.31}\n","{'loss': 0.0262, 'grad_norm': 0.09331623464822769, 'learning_rate': 2.45290419777228e-06, 'epoch': 38.35}\n","{'loss': 0.0279, 'grad_norm': 0.13114219903945923, 'learning_rate': 2.438609182196773e-06, 'epoch': 38.38}\n","{'loss': 0.0245, 'grad_norm': 0.06796292960643768, 'learning_rate': 2.4243501561595027e-06, 'epoch': 38.42}\n","{'loss': 0.0299, 'grad_norm': 0.08147355169057846, 'learning_rate': 2.4101271875283818e-06, 'epoch': 38.45}\n","{'loss': 0.0205, 'grad_norm': 0.10776033252477646, 'learning_rate': 2.395940343999691e-06, 'epoch': 38.48}\n","{'loss': 0.0242, 'grad_norm': 0.1569456160068512, 'learning_rate': 2.3817896930977755e-06, 'epoch': 38.52}\n","{'loss': 0.0315, 'grad_norm': 0.06566551327705383, 'learning_rate': 2.3676753021747113e-06, 'epoch': 38.55}\n","{'loss': 0.0237, 'grad_norm': 0.10707708448171616, 'learning_rate': 2.353597238409997e-06, 'epoch': 38.59}\n","{'loss': 0.0284, 'grad_norm': 0.13435937464237213, 'learning_rate': 2.339555568810221e-06, 'epoch': 38.62}\n","{'loss': 0.0238, 'grad_norm': 0.08886375278234482, 'learning_rate': 2.325550360208747e-06, 'epoch': 38.66}\n","{'loss': 0.0238, 'grad_norm': 0.10030695050954819, 'learning_rate': 2.3115816792654057e-06, 'epoch': 38.69}\n","{'loss': 0.0262, 'grad_norm': 0.1142391562461853, 'learning_rate': 2.29764959246616e-06, 'epoch': 38.73}\n","{'loss': 0.0217, 'grad_norm': 0.11230023205280304, 'learning_rate': 2.2837541661228024e-06, 'epoch': 38.76}\n","{'loss': 0.0236, 'grad_norm': 0.06858336925506592, 'learning_rate': 2.26989546637263e-06, 'epoch': 38.8}\n","{'loss': 0.0259, 'grad_norm': 0.07073118537664413, 'learning_rate': 2.256073559178145e-06, 'epoch': 38.83}\n","{'loss': 0.0228, 'grad_norm': 0.10639005154371262, 'learning_rate': 2.242288510326719e-06, 'epoch': 38.87}\n","{'loss': 0.0202, 'grad_norm': 0.07790974527597427, 'learning_rate': 2.2285403854302912e-06, 'epoch': 38.9}\n","{'loss': 0.0248, 'grad_norm': 0.08584322780370712, 'learning_rate': 2.2148292499250668e-06, 'epoch': 38.93}\n","{'loss': 0.0273, 'grad_norm': 0.09311367571353912, 'learning_rate': 2.201155169071184e-06, 'epoch': 38.97}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 2\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.0244, 'grad_norm': 0.2423626333475113, 'learning_rate': 2.1875182079524173e-06, 'epoch': 39.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9c44d0c6e6f84eeab8135b65a8afbc76","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/32 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_model/checkpoint-5655\n","loading configuration file /home/raza/Downloads/Phi-3-mini-4k-instruct/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 2047,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer config file saved in ./finetuned_model/checkpoint-5655/tokenizer_config.json\n","Special tokens file saved in ./finetuned_model/checkpoint-5655/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.04043509438633919, 'eval_runtime': 6.8802, 'eval_samples_per_second': 9.157, 'eval_steps_per_second': 4.651, 'epoch': 39.0}\n","{'loss': 0.0234, 'grad_norm': 0.13826708495616913, 'learning_rate': 2.173918431475861e-06, 'epoch': 39.03}\n","{'loss': 0.0306, 'grad_norm': 0.09875701367855072, 'learning_rate': 2.160355904371635e-06, 'epoch': 39.07}\n","{'loss': 0.0327, 'grad_norm': 0.10653316974639893, 'learning_rate': 2.146830691192553e-06, 'epoch': 39.1}\n","{'loss': 0.0269, 'grad_norm': 0.10948364436626434, 'learning_rate': 2.1333428563138304e-06, 'epoch': 39.14}\n","{'loss': 0.0229, 'grad_norm': 0.10778020322322845, 'learning_rate': 2.119892463932781e-06, 'epoch': 39.17}\n","{'loss': 0.0197, 'grad_norm': 0.13354970514774323, 'learning_rate': 2.106479578068501e-06, 'epoch': 39.21}\n","{'loss': 0.0238, 'grad_norm': 0.09070738404989243, 'learning_rate': 2.093104262561569e-06, 'epoch': 39.24}\n","{'loss': 0.0199, 'grad_norm': 0.10155506432056427, 'learning_rate': 2.0797665810737386e-06, 'epoch': 39.28}\n","{'loss': 0.0346, 'grad_norm': 0.143678218126297, 'learning_rate': 2.0664665970876496e-06, 'epoch': 39.31}\n","{'loss': 0.0234, 'grad_norm': 0.09838606417179108, 'learning_rate': 2.0532043739065054e-06, 'epoch': 39.35}\n","{'loss': 0.0239, 'grad_norm': 0.11514409631490707, 'learning_rate': 2.0399799746537806e-06, 'epoch': 39.38}\n","{'loss': 0.025, 'grad_norm': 0.13565219938755035, 'learning_rate': 2.02679346227293e-06, 'epoch': 39.42}\n","{'loss': 0.0212, 'grad_norm': 0.09168180078268051, 'learning_rate': 2.013644899527074e-06, 'epoch': 39.45}\n","{'loss': 0.0203, 'grad_norm': 0.0986408069729805, 'learning_rate': 2.0005343489987038e-06, 'epoch': 39.48}\n","{'loss': 0.0222, 'grad_norm': 0.05822521448135376, 'learning_rate': 1.9874618730893947e-06, 'epoch': 39.52}\n","{'loss': 0.0265, 'grad_norm': 0.18570774793624878, 'learning_rate': 1.974427534019493e-06, 'epoch': 39.55}\n","{'loss': 0.0355, 'grad_norm': 0.11017999798059464, 'learning_rate': 1.961431393827827e-06, 'epoch': 39.59}\n","{'loss': 0.0229, 'grad_norm': 0.10786271840333939, 'learning_rate': 1.9484735143714184e-06, 'epoch': 39.62}\n","{'loss': 0.0308, 'grad_norm': 0.08900654315948486, 'learning_rate': 1.9355539573251737e-06, 'epoch': 39.66}\n","{'loss': 0.0249, 'grad_norm': 0.10639463365077972, 'learning_rate': 1.922672784181605e-06, 'epoch': 39.69}\n","{'loss': 0.0204, 'grad_norm': 0.08284074813127518, 'learning_rate': 1.9098300562505266e-06, 'epoch': 39.73}\n","{'loss': 0.0276, 'grad_norm': 0.09678617864847183, 'learning_rate': 1.8970258346587645e-06, 'epoch': 39.76}\n","{'loss': 0.0291, 'grad_norm': 0.10629615187644958, 'learning_rate': 1.8842601803498772e-06, 'epoch': 39.8}\n","{'loss': 0.0288, 'grad_norm': 0.10765337198972702, 'learning_rate': 1.8715331540838488e-06, 'epoch': 39.83}\n","{'loss': 0.0296, 'grad_norm': 0.09911970049142838, 'learning_rate': 1.858844816436809e-06, 'epoch': 39.87}\n","{'loss': 0.0224, 'grad_norm': 0.09126687049865723, 'learning_rate': 1.8461952278007434e-06, 'epoch': 39.9}\n","{'loss': 0.0228, 'grad_norm': 0.14822141826152802, 'learning_rate': 1.833584448383211e-06, 'epoch': 39.93}\n","{'loss': 0.0299, 'grad_norm': 0.10378903895616531, 'learning_rate': 1.8210125382070466e-06, 'epoch': 39.97}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 2\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.0243, 'grad_norm': 0.1276492178440094, 'learning_rate': 1.808479557110081e-06, 'epoch': 40.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2551fe7385f44fdab86c45dd2088d4e5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/32 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_model/checkpoint-5800\n","loading configuration file /home/raza/Downloads/Phi-3-mini-4k-instruct/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 2047,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer config file saved in ./finetuned_model/checkpoint-5800/tokenizer_config.json\n","Special tokens file saved in ./finetuned_model/checkpoint-5800/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.040281616151332855, 'eval_runtime': 6.8812, 'eval_samples_per_second': 9.155, 'eval_steps_per_second': 4.65, 'epoch': 40.0}\n","{'loss': 0.0303, 'grad_norm': 0.15754945576190948, 'learning_rate': 1.7959855647448642e-06, 'epoch': 40.03}\n","{'loss': 0.0225, 'grad_norm': 0.08911509066820145, 'learning_rate': 1.7835306205783643e-06, 'epoch': 40.07}\n","{'loss': 0.0222, 'grad_norm': 0.08978171646595001, 'learning_rate': 1.7711147838916987e-06, 'epoch': 40.1}\n","{'loss': 0.0365, 'grad_norm': 0.1276584416627884, 'learning_rate': 1.7587381137798432e-06, 'epoch': 40.14}\n","{'loss': 0.0232, 'grad_norm': 0.11967837810516357, 'learning_rate': 1.7464006691513624e-06, 'epoch': 40.17}\n","{'loss': 0.0353, 'grad_norm': 0.10685992240905762, 'learning_rate': 1.7341025087281149e-06, 'epoch': 40.21}\n","{'loss': 0.0201, 'grad_norm': 0.10971888899803162, 'learning_rate': 1.7218436910449787e-06, 'epoch': 40.24}\n","{'loss': 0.0209, 'grad_norm': 0.097005195915699, 'learning_rate': 1.709624274449584e-06, 'epoch': 40.28}\n","{'loss': 0.024, 'grad_norm': 0.10588180273771286, 'learning_rate': 1.697444317102015e-06, 'epoch': 40.31}\n","{'loss': 0.0244, 'grad_norm': 0.13846617937088013, 'learning_rate': 1.6853038769745466e-06, 'epoch': 40.35}\n","{'loss': 0.0249, 'grad_norm': 0.17349132895469666, 'learning_rate': 1.6732030118513741e-06, 'epoch': 40.38}\n","{'loss': 0.02, 'grad_norm': 0.11806321144104004, 'learning_rate': 1.6611417793283192e-06, 'epoch': 40.42}\n","{'loss': 0.0237, 'grad_norm': 0.136632040143013, 'learning_rate': 1.6491202368125703e-06, 'epoch': 40.45}\n","{'loss': 0.0264, 'grad_norm': 0.09938143938779831, 'learning_rate': 1.6371384415224046e-06, 'epoch': 40.48}\n","{'loss': 0.0347, 'grad_norm': 0.09473715722560883, 'learning_rate': 1.6251964504869221e-06, 'epoch': 40.52}\n","{'loss': 0.0286, 'grad_norm': 0.08016448467969894, 'learning_rate': 1.6132943205457607e-06, 'epoch': 40.55}\n","{'loss': 0.0181, 'grad_norm': 0.0880369022488594, 'learning_rate': 1.6014321083488372e-06, 'epoch': 40.59}\n","{'loss': 0.0255, 'grad_norm': 0.08249375969171524, 'learning_rate': 1.589609870356076e-06, 'epoch': 40.62}\n","{'loss': 0.026, 'grad_norm': 0.07736066728830338, 'learning_rate': 1.577827662837136e-06, 'epoch': 40.66}\n","{'loss': 0.0341, 'grad_norm': 0.0614280104637146, 'learning_rate': 1.566085541871145e-06, 'epoch': 40.69}\n","{'loss': 0.0229, 'grad_norm': 0.11631938070058823, 'learning_rate': 1.5543835633464321e-06, 'epoch': 40.73}\n","{'loss': 0.029, 'grad_norm': 0.06737994402647018, 'learning_rate': 1.542721782960268e-06, 'epoch': 40.76}\n","{'loss': 0.022, 'grad_norm': 0.11650479584932327, 'learning_rate': 1.5311002562185905e-06, 'epoch': 40.8}\n","{'loss': 0.0258, 'grad_norm': 0.10597164183855057, 'learning_rate': 1.5195190384357405e-06, 'epoch': 40.83}\n","{'loss': 0.0253, 'grad_norm': 0.1338200569152832, 'learning_rate': 1.5079781847342122e-06, 'epoch': 40.87}\n","{'loss': 0.0272, 'grad_norm': 0.07835251092910767, 'learning_rate': 1.4964777500443728e-06, 'epoch': 40.9}\n","{'loss': 0.0201, 'grad_norm': 0.1150444969534874, 'learning_rate': 1.4850177891042128e-06, 'epoch': 40.93}\n","{'loss': 0.0279, 'grad_norm': 0.09705252200365067, 'learning_rate': 1.4735983564590784e-06, 'epoch': 40.97}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 2\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.0223, 'grad_norm': 0.18088559806346893, 'learning_rate': 1.4622195064614241e-06, 'epoch': 41.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ed4467feba0e45c1a1fd022a8c01f25b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/32 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_model/checkpoint-5945\n","loading configuration file /home/raza/Downloads/Phi-3-mini-4k-instruct/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 2047,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer config file saved in ./finetuned_model/checkpoint-5945/tokenizer_config.json\n","Special tokens file saved in ./finetuned_model/checkpoint-5945/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.040360815823078156, 'eval_runtime': 6.8808, 'eval_samples_per_second': 9.156, 'eval_steps_per_second': 4.651, 'epoch': 41.0}\n","{'loss': 0.0211, 'grad_norm': 0.10150832682847977, 'learning_rate': 1.4508812932705364e-06, 'epoch': 41.03}\n","{'loss': 0.0324, 'grad_norm': 0.12289080768823624, 'learning_rate': 1.4395837708522864e-06, 'epoch': 41.07}\n","{'loss': 0.0228, 'grad_norm': 0.09013748914003372, 'learning_rate': 1.4283269929788779e-06, 'epoch': 41.1}\n","{'loss': 0.0285, 'grad_norm': 0.14449919760227203, 'learning_rate': 1.4171110132285771e-06, 'epoch': 41.14}\n","{'loss': 0.0272, 'grad_norm': 0.11975526809692383, 'learning_rate': 1.4059358849854732e-06, 'epoch': 41.17}\n","{'loss': 0.0268, 'grad_norm': 0.10516175627708435, 'learning_rate': 1.3948016614392113e-06, 'epoch': 41.21}\n","{'loss': 0.0194, 'grad_norm': 0.08354433625936508, 'learning_rate': 1.3837083955847418e-06, 'epoch': 41.24}\n","{'loss': 0.0224, 'grad_norm': 0.12986110150814056, 'learning_rate': 1.3726561402220818e-06, 'epoch': 41.28}\n","{'loss': 0.0223, 'grad_norm': 0.12424732744693756, 'learning_rate': 1.3616449479560434e-06, 'epoch': 41.31}\n","{'loss': 0.0215, 'grad_norm': 0.09856356680393219, 'learning_rate': 1.350674871195995e-06, 'epoch': 41.35}\n","{'loss': 0.0235, 'grad_norm': 0.07740522176027298, 'learning_rate': 1.339745962155613e-06, 'epoch': 41.38}\n","{'loss': 0.0232, 'grad_norm': 0.09638021886348724, 'learning_rate': 1.3288582728526277e-06, 'epoch': 41.42}\n","{'loss': 0.0264, 'grad_norm': 0.14769117534160614, 'learning_rate': 1.3180118551085763e-06, 'epoch': 41.45}\n","{'loss': 0.0221, 'grad_norm': 0.10240370780229568, 'learning_rate': 1.3072067605485628e-06, 'epoch': 41.48}\n","{'loss': 0.0178, 'grad_norm': 0.08334419876337051, 'learning_rate': 1.2964430406010032e-06, 'epoch': 41.52}\n","{'loss': 0.0282, 'grad_norm': 0.1413719654083252, 'learning_rate': 1.2857207464973876e-06, 'epoch': 41.55}\n","{'loss': 0.0272, 'grad_norm': 0.08494856208562851, 'learning_rate': 1.2750399292720284e-06, 'epoch': 41.59}\n","{'loss': 0.0293, 'grad_norm': 0.11506876349449158, 'learning_rate': 1.2644006397618325e-06, 'epoch': 41.62}\n","{'loss': 0.0367, 'grad_norm': 0.08028356730937958, 'learning_rate': 1.2538029286060428e-06, 'epoch': 41.66}\n","{'loss': 0.0225, 'grad_norm': 0.09442893415689468, 'learning_rate': 1.2432468462460024e-06, 'epoch': 41.69}\n","{'loss': 0.0244, 'grad_norm': 0.08241074532270432, 'learning_rate': 1.2327324429249232e-06, 'epoch': 41.73}\n","{'loss': 0.0262, 'grad_norm': 0.08412814885377884, 'learning_rate': 1.2222597686876337e-06, 'epoch': 41.76}\n","{'loss': 0.0317, 'grad_norm': 0.10476519912481308, 'learning_rate': 1.2118288733803474e-06, 'epoch': 41.8}\n","{'loss': 0.03, 'grad_norm': 0.1349235624074936, 'learning_rate': 1.2014398066504263e-06, 'epoch': 41.83}\n","{'loss': 0.0265, 'grad_norm': 0.0977984145283699, 'learning_rate': 1.1910926179461446e-06, 'epoch': 41.87}\n","{'loss': 0.0208, 'grad_norm': 0.08722256869077682, 'learning_rate': 1.1807873565164507e-06, 'epoch': 41.9}\n","{'loss': 0.0326, 'grad_norm': 0.12003344297409058, 'learning_rate': 1.1705240714107301e-06, 'epoch': 41.93}\n","{'loss': 0.019, 'grad_norm': 0.09798472374677658, 'learning_rate': 1.160302811478584e-06, 'epoch': 41.97}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 2\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.0324, 'grad_norm': 0.27648141980171204, 'learning_rate': 1.1501236253695823e-06, 'epoch': 42.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"02b6918977f5439a92329146d2495f8b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/32 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_model/checkpoint-6090\n","loading configuration file /home/raza/Downloads/Phi-3-mini-4k-instruct/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 2047,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer config file saved in ./finetuned_model/checkpoint-6090/tokenizer_config.json\n","Special tokens file saved in ./finetuned_model/checkpoint-6090/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.04011122137308121, 'eval_runtime': 6.8817, 'eval_samples_per_second': 9.155, 'eval_steps_per_second': 4.65, 'epoch': 42.0}\n","{'loss': 0.0226, 'grad_norm': 0.12134375423192978, 'learning_rate': 1.1399865615330397e-06, 'epoch': 42.03}\n","{'loss': 0.0278, 'grad_norm': 0.10171687602996826, 'learning_rate': 1.129891668217783e-06, 'epoch': 42.07}\n","{'loss': 0.0231, 'grad_norm': 0.0855947807431221, 'learning_rate': 1.1198389934719277e-06, 'epoch': 42.1}\n","{'loss': 0.0208, 'grad_norm': 0.10351758450269699, 'learning_rate': 1.1098285851426372e-06, 'epoch': 42.14}\n","{'loss': 0.019, 'grad_norm': 0.07987688481807709, 'learning_rate': 1.0998604908759025e-06, 'epoch': 42.17}\n","{'loss': 0.0281, 'grad_norm': 0.10470163077116013, 'learning_rate': 1.0899347581163222e-06, 'epoch': 42.21}\n","{'loss': 0.0242, 'grad_norm': 0.11990683525800705, 'learning_rate': 1.0800514341068592e-06, 'epoch': 42.24}\n","{'loss': 0.0304, 'grad_norm': 0.09033652395009995, 'learning_rate': 1.0702105658886318e-06, 'epoch': 42.28}\n","{'loss': 0.022, 'grad_norm': 0.08647537976503372, 'learning_rate': 1.060412200300679e-06, 'epoch': 42.31}\n","{'loss': 0.023, 'grad_norm': 0.10917229950428009, 'learning_rate': 1.0506563839797501e-06, 'epoch': 42.35}\n","{'loss': 0.0253, 'grad_norm': 0.10662642121315002, 'learning_rate': 1.0409431633600687e-06, 'epoch': 42.38}\n","{'loss': 0.0349, 'grad_norm': 0.14354638755321503, 'learning_rate': 1.0312725846731174e-06, 'epoch': 42.42}\n","{'loss': 0.0248, 'grad_norm': 0.08375125378370285, 'learning_rate': 1.0216446939474234e-06, 'epoch': 42.45}\n","{'loss': 0.0243, 'grad_norm': 0.09323903918266296, 'learning_rate': 1.012059537008332e-06, 'epoch': 42.48}\n","{'loss': 0.0286, 'grad_norm': 0.10325127840042114, 'learning_rate': 1.0025171594777872e-06, 'epoch': 42.52}\n","{'loss': 0.0254, 'grad_norm': 0.08048555999994278, 'learning_rate': 9.930176067741216e-07, 'epoch': 42.55}\n","{'loss': 0.0221, 'grad_norm': 0.1140381246805191, 'learning_rate': 9.835609241118404e-07, 'epoch': 42.59}\n","{'loss': 0.0301, 'grad_norm': 0.10616826266050339, 'learning_rate': 9.74147156501396e-07, 'epoch': 42.62}\n","{'loss': 0.0264, 'grad_norm': 0.10721703618764877, 'learning_rate': 9.647763487489815e-07, 'epoch': 42.66}\n","{'loss': 0.0248, 'grad_norm': 0.09001718461513519, 'learning_rate': 9.55448545456319e-07, 'epoch': 42.69}\n","{'loss': 0.021, 'grad_norm': 0.10133825987577438, 'learning_rate': 9.461637910204468e-07, 'epoch': 42.73}\n","{'loss': 0.0215, 'grad_norm': 0.08903542160987854, 'learning_rate': 9.369221296335007e-07, 'epoch': 42.76}\n","{'loss': 0.0338, 'grad_norm': 0.10885465145111084, 'learning_rate': 9.277236052825078e-07, 'epoch': 42.8}\n","{'loss': 0.0233, 'grad_norm': 0.0886218249797821, 'learning_rate': 9.185682617491865e-07, 'epoch': 42.83}\n","{'loss': 0.0224, 'grad_norm': 0.070683054625988, 'learning_rate': 9.094561426097215e-07, 'epoch': 42.87}\n","{'loss': 0.0253, 'grad_norm': 0.06958668678998947, 'learning_rate': 9.00387291234569e-07, 'epoch': 42.9}\n","{'loss': 0.0354, 'grad_norm': 0.11741827428340912, 'learning_rate': 8.91361750788241e-07, 'epoch': 42.93}\n","{'loss': 0.0286, 'grad_norm': 0.11945416033267975, 'learning_rate': 8.823795642291145e-07, 'epoch': 42.97}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 2\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.0219, 'grad_norm': 0.12824144959449768, 'learning_rate': 8.734407743092078e-07, 'epoch': 43.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3f97ab9e6f51499da9bebf8b8e04bd91","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/32 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_model/checkpoint-6235\n","loading configuration file /home/raza/Downloads/Phi-3-mini-4k-instruct/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 2047,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer config file saved in ./finetuned_model/checkpoint-6235/tokenizer_config.json\n","Special tokens file saved in ./finetuned_model/checkpoint-6235/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.040237557142972946, 'eval_runtime': 6.879, 'eval_samples_per_second': 9.158, 'eval_steps_per_second': 4.652, 'epoch': 43.0}\n","{'loss': 0.028, 'grad_norm': 0.12612122297286987, 'learning_rate': 8.645454235739903e-07, 'epoch': 43.03}\n","{'loss': 0.0219, 'grad_norm': 0.07042775303125381, 'learning_rate': 8.556935543621791e-07, 'epoch': 43.07}\n","{'loss': 0.0232, 'grad_norm': 0.14627523720264435, 'learning_rate': 8.468852088055291e-07, 'epoch': 43.1}\n","{'loss': 0.0241, 'grad_norm': 0.07376807183027267, 'learning_rate': 8.381204288286415e-07, 'epoch': 43.14}\n","{'loss': 0.0256, 'grad_norm': 0.08878016471862793, 'learning_rate': 8.293992561487596e-07, 'epoch': 43.17}\n","{'loss': 0.0225, 'grad_norm': 0.11156313121318817, 'learning_rate': 8.207217322755734e-07, 'epoch': 43.21}\n","{'loss': 0.0223, 'grad_norm': 0.10509289056062698, 'learning_rate': 8.120878985110181e-07, 'epoch': 43.24}\n","{'loss': 0.0277, 'grad_norm': 0.08706406503915787, 'learning_rate': 8.034977959490775e-07, 'epoch': 43.28}\n","{'loss': 0.019, 'grad_norm': 0.07028603553771973, 'learning_rate': 7.949514654755963e-07, 'epoch': 43.31}\n","{'loss': 0.0243, 'grad_norm': 0.112340547144413, 'learning_rate': 7.864489477680759e-07, 'epoch': 43.35}\n","{'loss': 0.0244, 'grad_norm': 0.0847635567188263, 'learning_rate': 7.779902832954833e-07, 'epoch': 43.38}\n","{'loss': 0.0246, 'grad_norm': 0.14712642133235931, 'learning_rate': 7.695755123180593e-07, 'epoch': 43.42}\n","{'loss': 0.0206, 'grad_norm': 0.08526266366243362, 'learning_rate': 7.612046748871327e-07, 'epoch': 43.45}\n","{'loss': 0.0289, 'grad_norm': 0.1148161068558693, 'learning_rate': 7.528778108449197e-07, 'epoch': 43.48}\n","{'loss': 0.028, 'grad_norm': 0.07866527885198593, 'learning_rate': 7.445949598243362e-07, 'epoch': 43.52}\n","{'loss': 0.029, 'grad_norm': 0.09558812528848648, 'learning_rate': 7.363561612488191e-07, 'epoch': 43.55}\n","{'loss': 0.0267, 'grad_norm': 0.11931078881025314, 'learning_rate': 7.281614543321269e-07, 'epoch': 43.59}\n","{'loss': 0.0255, 'grad_norm': 0.09024985134601593, 'learning_rate': 7.200108780781556e-07, 'epoch': 43.62}\n","{'loss': 0.021, 'grad_norm': 0.07353822141885757, 'learning_rate': 7.119044712807577e-07, 'epoch': 43.66}\n","{'loss': 0.0246, 'grad_norm': 0.09793636202812195, 'learning_rate': 7.038422725235561e-07, 'epoch': 43.69}\n","{'loss': 0.0241, 'grad_norm': 0.07059147208929062, 'learning_rate': 6.958243201797554e-07, 'epoch': 43.73}\n","{'loss': 0.0256, 'grad_norm': 0.09609246999025345, 'learning_rate': 6.878506524119644e-07, 'epoch': 43.76}\n","{'loss': 0.0233, 'grad_norm': 0.1348908692598343, 'learning_rate': 6.799213071720156e-07, 'epoch': 43.8}\n","{'loss': 0.0248, 'grad_norm': 0.07985461503267288, 'learning_rate': 6.720363222007786e-07, 'epoch': 43.83}\n","{'loss': 0.0325, 'grad_norm': 0.1424417942762375, 'learning_rate': 6.641957350279838e-07, 'epoch': 43.87}\n","{'loss': 0.0238, 'grad_norm': 0.11368755251169205, 'learning_rate': 6.563995829720449e-07, 'epoch': 43.9}\n","{'loss': 0.0281, 'grad_norm': 0.0862804651260376, 'learning_rate': 6.48647903139884e-07, 'epoch': 43.93}\n","{'loss': 0.0319, 'grad_norm': 0.0900363177061081, 'learning_rate': 6.409407324267448e-07, 'epoch': 43.97}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 2\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.0337, 'grad_norm': 0.1764463186264038, 'learning_rate': 6.332781075160244e-07, 'epoch': 44.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"36834940776348abb7a6d9fb1d0d9003","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/32 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_model/checkpoint-6380\n","loading configuration file /home/raza/Downloads/Phi-3-mini-4k-instruct/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 2047,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer config file saved in ./finetuned_model/checkpoint-6380/tokenizer_config.json\n","Special tokens file saved in ./finetuned_model/checkpoint-6380/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.04036286845803261, 'eval_runtime': 6.8799, 'eval_samples_per_second': 9.157, 'eval_steps_per_second': 4.651, 'epoch': 44.0}\n","{'loss': 0.0262, 'grad_norm': 0.07811702787876129, 'learning_rate': 6.256600648791034e-07, 'epoch': 44.03}\n","{'loss': 0.0361, 'grad_norm': 0.07880964130163193, 'learning_rate': 6.180866407751595e-07, 'epoch': 44.07}\n","{'loss': 0.026, 'grad_norm': 0.10994181782007217, 'learning_rate': 6.105578712510074e-07, 'epoch': 44.1}\n","{'loss': 0.0261, 'grad_norm': 0.08312589675188065, 'learning_rate': 6.030737921409169e-07, 'epoch': 44.14}\n","{'loss': 0.0296, 'grad_norm': 0.10784425586462021, 'learning_rate': 5.956344390664525e-07, 'epoch': 44.17}\n","{'loss': 0.0224, 'grad_norm': 0.09466759115457535, 'learning_rate': 5.882398474362949e-07, 'epoch': 44.21}\n","{'loss': 0.0313, 'grad_norm': 0.10037282109260559, 'learning_rate': 5.80890052446077e-07, 'epoch': 44.24}\n","{'loss': 0.0284, 'grad_norm': 0.0830724909901619, 'learning_rate': 5.735850890782158e-07, 'epoch': 44.28}\n","{'loss': 0.0266, 'grad_norm': 0.09550905972719193, 'learning_rate': 5.663249921017477e-07, 'epoch': 44.31}\n","{'loss': 0.0189, 'grad_norm': 0.10047243535518646, 'learning_rate': 5.591097960721581e-07, 'epoch': 44.35}\n","{'loss': 0.026, 'grad_norm': 0.12990625202655792, 'learning_rate': 5.519395353312195e-07, 'epoch': 44.38}\n","{'loss': 0.0214, 'grad_norm': 0.0783931165933609, 'learning_rate': 5.448142440068316e-07, 'epoch': 44.42}\n","{'loss': 0.0313, 'grad_norm': 0.11856943368911743, 'learning_rate': 5.377339560128536e-07, 'epoch': 44.45}\n","{'loss': 0.0214, 'grad_norm': 0.15102800726890564, 'learning_rate': 5.306987050489442e-07, 'epoch': 44.48}\n","{'loss': 0.0215, 'grad_norm': 0.0787159875035286, 'learning_rate': 5.237085246004015e-07, 'epoch': 44.52}\n","{'loss': 0.021, 'grad_norm': 0.08843119442462921, 'learning_rate': 5.167634479380068e-07, 'epoch': 44.55}\n","{'loss': 0.0203, 'grad_norm': 0.08814619481563568, 'learning_rate': 5.098635081178615e-07, 'epoch': 44.59}\n","{'loss': 0.0314, 'grad_norm': 0.09371841698884964, 'learning_rate': 5.030087379812299e-07, 'epoch': 44.62}\n","{'loss': 0.0256, 'grad_norm': 0.08926252275705338, 'learning_rate': 4.961991701543889e-07, 'epoch': 44.66}\n","{'loss': 0.0275, 'grad_norm': 0.11613336205482483, 'learning_rate': 4.894348370484648e-07, 'epoch': 44.69}\n","{'loss': 0.0196, 'grad_norm': 0.13044029474258423, 'learning_rate': 4.827157708592834e-07, 'epoch': 44.73}\n","{'loss': 0.0268, 'grad_norm': 0.1229361966252327, 'learning_rate': 4.7604200356721644e-07, 'epoch': 44.76}\n","{'loss': 0.018, 'grad_norm': 0.05968868359923363, 'learning_rate': 4.6941356693703034e-07, 'epoch': 44.8}\n","{'loss': 0.035, 'grad_norm': 0.11049354076385498, 'learning_rate': 4.628304925177318e-07, 'epoch': 44.83}\n","{'loss': 0.0248, 'grad_norm': 0.10800574719905853, 'learning_rate': 4.562928116424181e-07, 'epoch': 44.87}\n","{'loss': 0.0236, 'grad_norm': 0.1395532786846161, 'learning_rate': 4.498005554281337e-07, 'epoch': 44.9}\n","{'loss': 0.0243, 'grad_norm': 0.0957525372505188, 'learning_rate': 4.4335375477571497e-07, 'epoch': 44.93}\n","{'loss': 0.0221, 'grad_norm': 0.10882207751274109, 'learning_rate': 4.3695244036964567e-07, 'epoch': 44.97}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 2\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.0253, 'grad_norm': 0.2950080633163452, 'learning_rate': 4.305966426779118e-07, 'epoch': 45.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c6b073d0ad524f6b967f5aaf0f94da3e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/32 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_model/checkpoint-6525\n","loading configuration file /home/raza/Downloads/Phi-3-mini-4k-instruct/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 2047,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer config file saved in ./finetuned_model/checkpoint-6525/tokenizer_config.json\n","Special tokens file saved in ./finetuned_model/checkpoint-6525/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.04043063521385193, 'eval_runtime': 6.879, 'eval_samples_per_second': 9.158, 'eval_steps_per_second': 4.652, 'epoch': 45.0}\n","{'loss': 0.034, 'grad_norm': 0.08923224359750748, 'learning_rate': 4.2428639195185585e-07, 'epoch': 45.03}\n","{'loss': 0.0228, 'grad_norm': 0.08051814883947372, 'learning_rate': 4.180217182260338e-07, 'epoch': 45.07}\n","{'loss': 0.0204, 'grad_norm': 0.08723440766334534, 'learning_rate': 4.118026513180695e-07, 'epoch': 45.1}\n","{'loss': 0.0236, 'grad_norm': 0.10847582668066025, 'learning_rate': 4.056292208285162e-07, 'epoch': 45.14}\n","{'loss': 0.0238, 'grad_norm': 0.08576886355876923, 'learning_rate': 3.99501456140714e-07, 'epoch': 45.17}\n","{'loss': 0.0267, 'grad_norm': 0.07531101256608963, 'learning_rate': 3.9341938642064814e-07, 'epoch': 45.21}\n","{'loss': 0.0286, 'grad_norm': 0.09112495183944702, 'learning_rate': 3.8738304061681107e-07, 'epoch': 45.24}\n","{'loss': 0.021, 'grad_norm': 0.09075148403644562, 'learning_rate': 3.8139244746007276e-07, 'epoch': 45.28}\n","{'loss': 0.0304, 'grad_norm': 0.10856784135103226, 'learning_rate': 3.7544763546352834e-07, 'epoch': 45.31}\n","{'loss': 0.0182, 'grad_norm': 0.08663580566644669, 'learning_rate': 3.6954863292237297e-07, 'epoch': 45.35}\n","{'loss': 0.0259, 'grad_norm': 0.08122503012418747, 'learning_rate': 3.6369546791377054e-07, 'epoch': 45.38}\n","{'loss': 0.0203, 'grad_norm': 0.0897429957985878, 'learning_rate': 3.5788816829670723e-07, 'epoch': 45.42}\n","{'loss': 0.0216, 'grad_norm': 0.08798359334468842, 'learning_rate': 3.5212676171187065e-07, 'epoch': 45.45}\n","{'loss': 0.0287, 'grad_norm': 0.07318049669265747, 'learning_rate': 3.464112755815119e-07, 'epoch': 45.48}\n","{'loss': 0.0325, 'grad_norm': 0.11008528620004654, 'learning_rate': 3.4074173710931804e-07, 'epoch': 45.52}\n","{'loss': 0.0187, 'grad_norm': 0.06365666538476944, 'learning_rate': 3.351181732802811e-07, 'epoch': 45.55}\n","{'loss': 0.0224, 'grad_norm': 0.08711311966180801, 'learning_rate': 3.2954061086056924e-07, 'epoch': 45.59}\n","{'loss': 0.0206, 'grad_norm': 0.14376072585582733, 'learning_rate': 3.2400907639740243e-07, 'epoch': 45.62}\n","{'loss': 0.0311, 'grad_norm': 0.10986071079969406, 'learning_rate': 3.185235962189237e-07, 'epoch': 45.66}\n","{'loss': 0.0213, 'grad_norm': 0.07898424565792084, 'learning_rate': 3.1308419643406915e-07, 'epoch': 45.69}\n","{'loss': 0.0242, 'grad_norm': 0.10217047482728958, 'learning_rate': 3.076909029324571e-07, 'epoch': 45.73}\n","{'loss': 0.0311, 'grad_norm': 0.11441326886415482, 'learning_rate': 3.023437413842478e-07, 'epoch': 45.76}\n","{'loss': 0.0232, 'grad_norm': 0.10213252902030945, 'learning_rate': 2.970427372400353e-07, 'epoch': 45.8}\n","{'loss': 0.0298, 'grad_norm': 0.0910739004611969, 'learning_rate': 2.9178791573071907e-07, 'epoch': 45.83}\n","{'loss': 0.0275, 'grad_norm': 0.07836846262216568, 'learning_rate': 2.865793018673857e-07, 'epoch': 45.87}\n","{'loss': 0.0267, 'grad_norm': 0.06711208075284958, 'learning_rate': 2.8141692044118874e-07, 'epoch': 45.9}\n","{'loss': 0.0275, 'grad_norm': 0.07908805459737778, 'learning_rate': 2.7630079602323447e-07, 'epoch': 45.93}\n","{'loss': 0.029, 'grad_norm': 0.11038461327552795, 'learning_rate': 2.7123095296445743e-07, 'epoch': 45.97}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 2\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.0257, 'grad_norm': 0.23372216522693634, 'learning_rate': 2.662074153955152e-07, 'epoch': 46.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"028e267e23b34aba8167f7560dd24895","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/32 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_model/checkpoint-6670\n","loading configuration file /home/raza/Downloads/Phi-3-mini-4k-instruct/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 2047,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer config file saved in ./finetuned_model/checkpoint-6670/tokenizer_config.json\n","Special tokens file saved in ./finetuned_model/checkpoint-6670/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.04046466946601868, 'eval_runtime': 6.881, 'eval_samples_per_second': 9.156, 'eval_steps_per_second': 4.65, 'epoch': 46.0}\n","{'loss': 0.0224, 'grad_norm': 0.14254069328308105, 'learning_rate': 2.612302072266637e-07, 'epoch': 46.03}\n","{'loss': 0.0323, 'grad_norm': 0.0793161392211914, 'learning_rate': 2.5629935214764866e-07, 'epoch': 46.07}\n","{'loss': 0.027, 'grad_norm': 0.12842874228954315, 'learning_rate': 2.51414873627589e-07, 'epoch': 46.1}\n","{'loss': 0.0234, 'grad_norm': 0.1036059632897377, 'learning_rate': 2.465767949148734e-07, 'epoch': 46.14}\n","{'loss': 0.0225, 'grad_norm': 0.09302526712417603, 'learning_rate': 2.4178513903703847e-07, 'epoch': 46.17}\n","{'loss': 0.0317, 'grad_norm': 0.1154857650399208, 'learning_rate': 2.370399288006664e-07, 'epoch': 46.21}\n","{'loss': 0.0221, 'grad_norm': 0.11320561915636063, 'learning_rate': 2.3234118679127615e-07, 'epoch': 46.24}\n","{'loss': 0.0251, 'grad_norm': 0.09055893868207932, 'learning_rate': 2.2768893537321145e-07, 'epoch': 46.28}\n","{'loss': 0.0256, 'grad_norm': 0.09554978460073471, 'learning_rate': 2.230831966895408e-07, 'epoch': 46.31}\n","{'loss': 0.0188, 'grad_norm': 0.10168929398059845, 'learning_rate': 2.1852399266194312e-07, 'epoch': 46.35}\n","{'loss': 0.0295, 'grad_norm': 0.10300242155790329, 'learning_rate': 2.140113449906167e-07, 'epoch': 46.38}\n","{'loss': 0.0294, 'grad_norm': 0.11962535977363586, 'learning_rate': 2.0954527515416156e-07, 'epoch': 46.42}\n","{'loss': 0.0224, 'grad_norm': 0.07615868747234344, 'learning_rate': 2.0512580440948615e-07, 'epoch': 46.45}\n","{'loss': 0.0228, 'grad_norm': 0.12870675325393677, 'learning_rate': 2.0075295379170413e-07, 'epoch': 46.48}\n","{'loss': 0.0242, 'grad_norm': 0.09179850667715073, 'learning_rate': 1.9642674411403328e-07, 'epoch': 46.52}\n","{'loss': 0.0227, 'grad_norm': 0.08219585567712784, 'learning_rate': 1.921471959676957e-07, 'epoch': 46.55}\n","{'loss': 0.0274, 'grad_norm': 0.08622905611991882, 'learning_rate': 1.8791432972182443e-07, 'epoch': 46.59}\n","{'loss': 0.0281, 'grad_norm': 0.11066929250955582, 'learning_rate': 1.8372816552336025e-07, 'epoch': 46.62}\n","{'loss': 0.0185, 'grad_norm': 0.11607716977596283, 'learning_rate': 1.7958872329696177e-07, 'epoch': 46.66}\n","{'loss': 0.0277, 'grad_norm': 0.12335556000471115, 'learning_rate': 1.754960227449032e-07, 'epoch': 46.69}\n","{'loss': 0.025, 'grad_norm': 0.07818093150854111, 'learning_rate': 1.7145008334698898e-07, 'epoch': 46.73}\n","{'loss': 0.0237, 'grad_norm': 0.12501060962677002, 'learning_rate': 1.6745092436045495e-07, 'epoch': 46.76}\n","{'loss': 0.0262, 'grad_norm': 0.09541743993759155, 'learning_rate': 1.6349856481987835e-07, 'epoch': 46.8}\n","{'loss': 0.0252, 'grad_norm': 0.10803203284740448, 'learning_rate': 1.5959302353709128e-07, 'epoch': 46.83}\n","{'loss': 0.0448, 'grad_norm': 0.11934436857700348, 'learning_rate': 1.5573431910108404e-07, 'epoch': 46.87}\n","{'loss': 0.0191, 'grad_norm': 0.11668309569358826, 'learning_rate': 1.519224698779198e-07, 'epoch': 46.9}\n","{'loss': 0.0275, 'grad_norm': 0.08679690957069397, 'learning_rate': 1.4815749401064894e-07, 'epoch': 46.93}\n","{'loss': 0.0218, 'grad_norm': 0.093439482152462, 'learning_rate': 1.444394094192225e-07, 'epoch': 46.97}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 2\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.0185, 'grad_norm': 0.13084648549556732, 'learning_rate': 1.407682338004046e-07, 'epoch': 47.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"89058c38011842cd9ec0229d48882a02","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/32 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_model/checkpoint-6815\n","loading configuration file /home/raza/Downloads/Phi-3-mini-4k-instruct/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 2047,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer config file saved in ./finetuned_model/checkpoint-6815/tokenizer_config.json\n","Special tokens file saved in ./finetuned_model/checkpoint-6815/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.04047980159521103, 'eval_runtime': 6.8744, 'eval_samples_per_second': 9.164, 'eval_steps_per_second': 4.655, 'epoch': 47.0}\n","{'loss': 0.0239, 'grad_norm': 0.12823744118213654, 'learning_rate': 1.3714398462768563e-07, 'epoch': 47.03}\n","{'loss': 0.0201, 'grad_norm': 0.06434327363967896, 'learning_rate': 1.3356667915121025e-07, 'epoch': 47.07}\n","{'loss': 0.0283, 'grad_norm': 0.12883372604846954, 'learning_rate': 1.3003633439768182e-07, 'epoch': 47.1}\n","{'loss': 0.0218, 'grad_norm': 0.08322731405496597, 'learning_rate': 1.2655296717028808e-07, 'epoch': 47.14}\n","{'loss': 0.0233, 'grad_norm': 0.07925700396299362, 'learning_rate': 1.231165940486234e-07, 'epoch': 47.17}\n","{'loss': 0.0237, 'grad_norm': 0.1715325117111206, 'learning_rate': 1.1972723138860333e-07, 'epoch': 47.21}\n","{'loss': 0.0226, 'grad_norm': 0.09570812433958054, 'learning_rate': 1.1638489532239339e-07, 'epoch': 47.24}\n","{'loss': 0.0365, 'grad_norm': 0.104829803109169, 'learning_rate': 1.1308960175832606e-07, 'epoch': 47.28}\n","{'loss': 0.0221, 'grad_norm': 0.1029215082526207, 'learning_rate': 1.0984136638083176e-07, 'epoch': 47.31}\n","{'loss': 0.0203, 'grad_norm': 0.12538860738277435, 'learning_rate': 1.0664020465035785e-07, 'epoch': 47.35}\n","{'loss': 0.035, 'grad_norm': 0.1062040850520134, 'learning_rate': 1.0348613180329758e-07, 'epoch': 47.38}\n","{'loss': 0.0248, 'grad_norm': 0.09057317674160004, 'learning_rate': 1.0037916285192129e-07, 'epoch': 47.42}\n","{'loss': 0.0199, 'grad_norm': 0.11298234760761261, 'learning_rate': 9.731931258429638e-08, 'epoch': 47.45}\n","{'loss': 0.0226, 'grad_norm': 0.108808234333992, 'learning_rate': 9.43065955642275e-08, 'epoch': 47.48}\n","{'loss': 0.027, 'grad_norm': 0.08327656239271164, 'learning_rate': 9.134102613117757e-08, 'epoch': 47.52}\n","{'loss': 0.0212, 'grad_norm': 0.10743340849876404, 'learning_rate': 8.84226184002046e-08, 'epoch': 47.55}\n","{'loss': 0.0203, 'grad_norm': 0.08609124273061752, 'learning_rate': 8.555138626189619e-08, 'epoch': 47.59}\n","{'loss': 0.0235, 'grad_norm': 0.10967807471752167, 'learning_rate': 8.272734338229727e-08, 'epoch': 47.62}\n","{'loss': 0.0336, 'grad_norm': 0.09022484719753265, 'learning_rate': 7.995050320285025e-08, 'epoch': 47.66}\n","{'loss': 0.0302, 'grad_norm': 0.13105876743793488, 'learning_rate': 7.722087894032948e-08, 'epoch': 47.69}\n","{'loss': 0.0309, 'grad_norm': 0.13126149773597717, 'learning_rate': 7.453848358678018e-08, 'epoch': 47.73}\n","{'loss': 0.0228, 'grad_norm': 0.09845728427171707, 'learning_rate': 7.19033299094496e-08, 'epoch': 47.76}\n","{'loss': 0.0282, 'grad_norm': 0.11886349320411682, 'learning_rate': 6.931543045073708e-08, 'epoch': 47.8}\n","{'loss': 0.019, 'grad_norm': 0.12277045100927353, 'learning_rate': 6.677479752812521e-08, 'epoch': 47.83}\n","{'loss': 0.0224, 'grad_norm': 0.13938705623149872, 'learning_rate': 6.428144323412544e-08, 'epoch': 47.87}\n","{'loss': 0.03, 'grad_norm': 0.10001558065414429, 'learning_rate': 6.18353794362192e-08, 'epoch': 47.9}\n","{'loss': 0.0307, 'grad_norm': 0.11942097544670105, 'learning_rate': 5.943661777680354e-08, 'epoch': 47.93}\n","{'loss': 0.0227, 'grad_norm': 0.08195801824331284, 'learning_rate': 5.708516967313338e-08, 'epoch': 47.97}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 2\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.0279, 'grad_norm': 0.28229308128356934, 'learning_rate': 5.4781046317267103e-08, 'epoch': 48.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1ea292b5729e438bafd85f6ec2672d60","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/32 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_model/checkpoint-6960\n","loading configuration file /home/raza/Downloads/Phi-3-mini-4k-instruct/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 2047,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer config file saved in ./finetuned_model/checkpoint-6960/tokenizer_config.json\n","Special tokens file saved in ./finetuned_model/checkpoint-6960/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.040399596095085144, 'eval_runtime': 6.8756, 'eval_samples_per_second': 9.163, 'eval_steps_per_second': 4.654, 'epoch': 48.0}\n","{'loss': 0.031, 'grad_norm': 0.07313777506351471, 'learning_rate': 5.252425867601329e-08, 'epoch': 48.03}\n","{'loss': 0.0205, 'grad_norm': 0.08075948804616928, 'learning_rate': 5.031481749088296e-08, 'epoch': 48.07}\n","{'loss': 0.0284, 'grad_norm': 0.10634560883045197, 'learning_rate': 4.815273327803183e-08, 'epoch': 48.1}\n","{'loss': 0.029, 'grad_norm': 0.13198979198932648, 'learning_rate': 4.603801632821148e-08, 'epoch': 48.14}\n","{'loss': 0.0248, 'grad_norm': 0.17081913352012634, 'learning_rate': 4.397067670672828e-08, 'epoch': 48.17}\n","{'loss': 0.0266, 'grad_norm': 0.09618455916643143, 'learning_rate': 4.195072425338342e-08, 'epoch': 48.21}\n","{'loss': 0.0304, 'grad_norm': 0.0720328614115715, 'learning_rate': 3.997816858243297e-08, 'epoch': 48.24}\n","{'loss': 0.0241, 'grad_norm': 0.07701475918292999, 'learning_rate': 3.805301908254455e-08, 'epoch': 48.28}\n","{'loss': 0.0314, 'grad_norm': 0.11927307397127151, 'learning_rate': 3.617528491674627e-08, 'epoch': 48.31}\n","{'loss': 0.0201, 'grad_norm': 0.10008901357650757, 'learning_rate': 3.4344975022385654e-08, 'epoch': 48.35}\n","{'loss': 0.0216, 'grad_norm': 0.08656221628189087, 'learning_rate': 3.256209811108968e-08, 'epoch': 48.38}\n","{'loss': 0.0219, 'grad_norm': 0.058462921530008316, 'learning_rate': 3.082666266872036e-08, 'epoch': 48.42}\n","{'loss': 0.0304, 'grad_norm': 0.10459398478269577, 'learning_rate': 2.9138676955333676e-08, 'epoch': 48.45}\n","{'loss': 0.0211, 'grad_norm': 0.08236489444971085, 'learning_rate': 2.7498149005144025e-08, 'epoch': 48.48}\n","{'loss': 0.0261, 'grad_norm': 0.09434594213962555, 'learning_rate': 2.5905086626480947e-08, 'epoch': 48.52}\n","{'loss': 0.0198, 'grad_norm': 0.08429909497499466, 'learning_rate': 2.4359497401758026e-08, 'epoch': 48.55}\n","{'loss': 0.0244, 'grad_norm': 0.11078169196844101, 'learning_rate': 2.2861388687430708e-08, 'epoch': 48.59}\n","{'loss': 0.0281, 'grad_norm': 0.09339611977338791, 'learning_rate': 2.1410767613965212e-08, 'epoch': 48.62}\n","{'loss': 0.022, 'grad_norm': 0.12418387085199356, 'learning_rate': 2.0007641085803e-08, 'epoch': 48.66}\n","{'loss': 0.0225, 'grad_norm': 0.08034924417734146, 'learning_rate': 1.86520157813308e-08, 'epoch': 48.69}\n","{'loss': 0.0247, 'grad_norm': 0.13277795910835266, 'learning_rate': 1.7343898152841765e-08, 'epoch': 48.73}\n","{'loss': 0.0201, 'grad_norm': 0.09938157349824905, 'learning_rate': 1.608329442651213e-08, 'epoch': 48.76}\n","{'loss': 0.0217, 'grad_norm': 0.09618797153234482, 'learning_rate': 1.487021060236904e-08, 'epoch': 48.8}\n","{'loss': 0.0271, 'grad_norm': 0.13955295085906982, 'learning_rate': 1.370465245426167e-08, 'epoch': 48.83}\n","{'loss': 0.0286, 'grad_norm': 0.09879270941019058, 'learning_rate': 1.2586625529832363e-08, 'epoch': 48.87}\n","{'loss': 0.0281, 'grad_norm': 0.12198854237794876, 'learning_rate': 1.1516135150493323e-08, 'epoch': 48.9}\n","{'loss': 0.0272, 'grad_norm': 0.10655929148197174, 'learning_rate': 1.0493186411398848e-08, 'epoch': 48.93}\n","{'loss': 0.0266, 'grad_norm': 0.10964499413967133, 'learning_rate': 9.517784181422018e-09, 'epoch': 48.97}\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 2\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.0249, 'grad_norm': 0.13185715675354004, 'learning_rate': 8.589933103132498e-09, 'epoch': 49.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6eca3cdf12bf4c77a814fe7f3754f7b9","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/32 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_model/checkpoint-7105\n","loading configuration file /home/raza/Downloads/Phi-3-mini-4k-instruct/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 2047,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer config file saved in ./finetuned_model/checkpoint-7105/tokenizer_config.json\n","Special tokens file saved in ./finetuned_model/checkpoint-7105/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.040412537753582, 'eval_runtime': 6.8762, 'eval_samples_per_second': 9.162, 'eval_steps_per_second': 4.654, 'epoch': 49.0}\n","{'loss': 0.0202, 'grad_norm': 0.1499631106853485, 'learning_rate': 7.70963759277099e-09, 'epoch': 49.03}\n","{'loss': 0.032, 'grad_norm': 0.11476847529411316, 'learning_rate': 6.876901840231487e-09, 'epoch': 49.07}\n","{'loss': 0.0258, 'grad_norm': 0.05743570625782013, 'learning_rate': 6.091729809042379e-09, 'epoch': 49.1}\n","{'loss': 0.0183, 'grad_norm': 0.08499053865671158, 'learning_rate': 5.354125236343155e-09, 'epoch': 49.14}\n","{'loss': 0.0282, 'grad_norm': 0.09843312948942184, 'learning_rate': 4.6640916328710705e-09, 'epoch': 49.17}\n","{'loss': 0.0194, 'grad_norm': 0.12889589369297028, 'learning_rate': 4.021632282938947e-09, 'epoch': 49.21}\n","{'loss': 0.0234, 'grad_norm': 0.08438156545162201, 'learning_rate': 3.4267502444274013e-09, 'epoch': 49.24}\n","{'loss': 0.0299, 'grad_norm': 0.1093689575791359, 'learning_rate': 2.879448348762637e-09, 'epoch': 49.28}\n","{'loss': 0.0214, 'grad_norm': 0.09769835323095322, 'learning_rate': 2.379729200908676e-09, 'epoch': 49.31}\n","{'loss': 0.0265, 'grad_norm': 0.08979485929012299, 'learning_rate': 1.9275951793518154e-09, 'epoch': 49.35}\n","{'loss': 0.0211, 'grad_norm': 0.12292589247226715, 'learning_rate': 1.5230484360873043e-09, 'epoch': 49.38}\n","{'loss': 0.0259, 'grad_norm': 0.12535741925239563, 'learning_rate': 1.1660908966171224e-09, 'epoch': 49.42}\n","{'loss': 0.0198, 'grad_norm': 0.09604442119598389, 'learning_rate': 8.567242599299974e-10, 'epoch': 49.45}\n","{'loss': 0.0355, 'grad_norm': 0.0980478972196579, 'learning_rate': 5.949499985025142e-10, 'epoch': 49.48}\n","{'loss': 0.0309, 'grad_norm': 0.13967756927013397, 'learning_rate': 3.807693582869032e-10, 'epoch': 49.52}\n","{'loss': 0.0256, 'grad_norm': 0.09718634933233261, 'learning_rate': 2.1418335870770912e-10, 'epoch': 49.55}\n","{'loss': 0.0273, 'grad_norm': 0.09906734526157379, 'learning_rate': 9.519279265512993e-11, 'epoch': 49.59}\n","{'loss': 0.0251, 'grad_norm': 0.14129866659641266, 'learning_rate': 2.379822648168606e-11, 'epoch': 49.62}\n"]},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_model/checkpoint-7200\n","loading configuration file /home/raza/Downloads/Phi-3-mini-4k-instruct/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 2047,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer config file saved in ./finetuned_model/checkpoint-7200/tokenizer_config.json\n","Special tokens file saved in ./finetuned_model/checkpoint-7200/special_tokens_map.json\n","\n","***** Running Evaluation *****\n","  Num examples = 63\n","  Batch size = 2\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.0219, 'grad_norm': 0.0829143151640892, 'learning_rate': 0.0, 'epoch': 49.66}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a1e289f6b9e24ed88289235e35dd22a6","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/32 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./finetuned_model/checkpoint-7200\n","loading configuration file /home/raza/Downloads/Phi-3-mini-4k-instruct/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 2047,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.47.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer config file saved in ./finetuned_model/checkpoint-7200/tokenizer_config.json\n","Special tokens file saved in ./finetuned_model/checkpoint-7200/special_tokens_map.json\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.04038238525390625, 'eval_runtime': 6.875, 'eval_samples_per_second': 9.164, 'eval_steps_per_second': 4.655, 'epoch': 49.66}\n","{'train_runtime': 9774.2836, 'train_samples_per_second': 2.952, 'train_steps_per_second': 0.737, 'train_loss': 0.05435840782605939, 'epoch': 49.66}\n"]}],"source":["train_result = trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPda54JZ4Qt1ygz8fv4/CV9","mount_file_id":"1Wepf1NnpCuMj69Wj_eFGlQlpKMae0djV","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"021d9fefd4f44d9aa2c01c3ec63cdafb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"089c59f3538c487c991d0917fb6f78ee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0a26ab4ea81e4d5aa2521b9d6dd11b39":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0b51b8cfb11c450cbea1981ec156d676":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e3f453f2b9c64e4e9b69bf87698cbb92","placeholder":"","style":"IPY_MODEL_77be1ea8b2244a499e710b875eb2d988","value":"configuration_phi3.py:100%"}},"10ea66e01d6a44e3b2280e3362fd04fc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1287988ad9c34b478f798e3e115c3a11":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"12a27aa8119d4000af8a039c528eedd8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_46570a2fe95c4e82b4c44551c166f27e","IPY_MODEL_36dfd5ec20124987a31a19fe2ff14861","IPY_MODEL_cb0eb4832cb4446c8bf3087c63a082be"],"layout":"IPY_MODEL_d82e30e6819e4ce1b6c250b9c7f703ff"}},"12dd6a65b0c64c73a9b224f0af33b49f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"17f4bd10c1f54bf781e7062dfda7a3c4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1acdc45992b147a395576115a13d21fe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd78eb50c1bc42caaf122393286de01d","max":306,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0a26ab4ea81e4d5aa2521b9d6dd11b39","value":306}},"25df39f8067f4ce5a9ebd46577b7e9c8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"26a30e8099504d2d9ee5364f45192e95":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27a230a966fe4487a0820cc88a0b3c33":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b96a571cf554509bc06fcecce2ecaf5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c51620748b8460aae4415897e3b464e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_eb52bc275ae946ac80d7bcd5f5b2f5a4","max":3441,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f4f968a603bd4a03a9f0c5aeaaafac69","value":3441}},"2e5e1d8d14b34189bdc8a43deebc3315":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_10ea66e01d6a44e3b2280e3362fd04fc","max":599,"min":0,"orientation":"horizontal","style":"IPY_MODEL_31b291a6e4d0405298a90ff18394a022","value":599}},"31b291a6e4d0405298a90ff18394a022":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"36dfd5ec20124987a31a19fe2ff14861":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8e91f3e759194759824d8b90881674c2","max":1937869,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8086b030aeb54e88b7bcd3b477409a5d","value":1937869}},"38496c2096014bb182b6802726a6c086":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_feaec0fccff045828af84bf58ce002df","placeholder":"","style":"IPY_MODEL_7d57acf29422411c9ce7db5f62e35b59","value":"tokenizer_config.json:100%"}},"3b5dfb8f46d248339023c48bbf1f7070":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"403a7acbeb3947afa41d070c26405317":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9e53479a11894b4fbf7ca835eb070eba","max":499723,"min":0,"orientation":"horizontal","style":"IPY_MODEL_48dcb3035dd44aaabdaf97a18f588813","value":499723}},"418dd516d8fe48acb36d8e1669bc1a2b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7f5d3e9baf544ebb911bff3ad85028df","IPY_MODEL_1acdc45992b147a395576115a13d21fe","IPY_MODEL_764698493c274763995de1558a363891"],"layout":"IPY_MODEL_2b96a571cf554509bc06fcecce2ecaf5"}},"45817db873d14496b8315ff3202c2085":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46570a2fe95c4e82b4c44551c166f27e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_26a30e8099504d2d9ee5364f45192e95","placeholder":"","style":"IPY_MODEL_9eb5f26dbab447d683a2ec0266adc623","value":"tokenizer.json:100%"}},"48dcb3035dd44aaabdaf97a18f588813":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5574de81969b463cafb998c950c44661":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e357a60af21e4751ab236aac707fa043","IPY_MODEL_b4c5f0a1cba84cf19680bdbf723fe583","IPY_MODEL_a420922901f848ff9dc134d45b3ac8c3"],"layout":"IPY_MODEL_c8ef8b0375814985ac4407a855db1388"}},"619d0c0ffa3c4235a310895389501176":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6717b4680eed4786bfd3ee5bf60595ec":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c0c3a855f41420fb5d22c76b9987603":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_983768e254b143d1a50896a1756de2fe","placeholder":"","style":"IPY_MODEL_021d9fefd4f44d9aa2c01c3ec63cdafb","value":"tokenizer.model:100%"}},"6cbad495963049fab25e22bb75f4ba28":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6f2db1dfae4446598a94d8b53e3d4265":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_27a230a966fe4487a0820cc88a0b3c33","placeholder":"","style":"IPY_MODEL_e6d26795de924ae58ac7a49b29d4aaa5","value":"599/599[00:00&lt;00:00,20.8kB/s]"}},"75e1b4e4706047a28125b625e4c4667a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"764698493c274763995de1558a363891":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_45817db873d14496b8315ff3202c2085","placeholder":"","style":"IPY_MODEL_75e1b4e4706047a28125b625e4c4667a","value":"306/306[00:00&lt;00:00,12.0kB/s]"}},"77be1ea8b2244a499e710b875eb2d988":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7d57acf29422411c9ce7db5f62e35b59":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7f5d3e9baf544ebb911bff3ad85028df":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c1c805421c7e409f93f44bdf89d62db3","placeholder":"","style":"IPY_MODEL_6cbad495963049fab25e22bb75f4ba28","value":"added_tokens.json:100%"}},"8086b030aeb54e88b7bcd3b477409a5d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8c8e4c0c6e064fc58a3623374e10fd48":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e91f3e759194759824d8b90881674c2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"983768e254b143d1a50896a1756de2fe":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e53479a11894b4fbf7ca835eb070eba":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9eb5f26dbab447d683a2ec0266adc623":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9f325b15a0df4c62a0b3a4a38aff29f5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0b51b8cfb11c450cbea1981ec156d676","IPY_MODEL_cc4e1df338bb4fa69cac3a89a08cd85b","IPY_MODEL_bc97a7a1ed394598baab90438841d719"],"layout":"IPY_MODEL_619d0c0ffa3c4235a310895389501176"}},"a2050d0434d6436ebd17e368b1d3f8e3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a420922901f848ff9dc134d45b3ac8c3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_25df39f8067f4ce5a9ebd46577b7e9c8","placeholder":"","style":"IPY_MODEL_a975b6fe6d014f2cbd88d6b014d74fea","value":"73.2k/73.2k[00:00&lt;00:00,924kB/s]"}},"a975b6fe6d014f2cbd88d6b014d74fea":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a9ef28aed5f94cef8aa7e4a4fdadb39e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fafd5e01a2c54e399ffdd01d5de30ff4","placeholder":"","style":"IPY_MODEL_e470a1fa5f3840c58a17dd2e051c3db6","value":"500k/500k[00:00&lt;00:00,9.02MB/s]"}},"ab7aff5740fb48469ffc8c4db19696d6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6c0c3a855f41420fb5d22c76b9987603","IPY_MODEL_403a7acbeb3947afa41d070c26405317","IPY_MODEL_a9ef28aed5f94cef8aa7e4a4fdadb39e"],"layout":"IPY_MODEL_1287988ad9c34b478f798e3e115c3a11"}},"b248c17ffe5f4a1b875061fb7f7087fb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e7deaa0d282647be876890482d623908","IPY_MODEL_2e5e1d8d14b34189bdc8a43deebc3315","IPY_MODEL_6f2db1dfae4446598a94d8b53e3d4265"],"layout":"IPY_MODEL_efbec3f178e74e93801570c7281bbaf4"}},"b4c5f0a1cba84cf19680bdbf723fe583":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d0c99c2bf07b40baabe759ebf1cd73f4","max":73193,"min":0,"orientation":"horizontal","style":"IPY_MODEL_089c59f3538c487c991d0917fb6f78ee","value":73193}},"b5bd78f99b52441e8bcdb21a6d9f3102":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bab5ac46b2cf4c038f5d1a6c6b1ba79a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bc97a7a1ed394598baab90438841d719":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bd66add61d8b4ef59b328f64ac7bd882","placeholder":"","style":"IPY_MODEL_d411270eed4a487a957f836011f1c1b3","value":"11.2k/11.2k[00:00&lt;00:00,172kB/s]"}},"bd66add61d8b4ef59b328f64ac7bd882":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c1c805421c7e409f93f44bdf89d62db3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8ef8b0375814985ac4407a855db1388":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb0eb4832cb4446c8bf3087c63a082be":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6717b4680eed4786bfd3ee5bf60595ec","placeholder":"","style":"IPY_MODEL_cf698bce66ab4fffa7c97d0753fc49a7","value":"1.94M/1.94M[00:00&lt;00:00,29.6MB/s]"}},"cc4e1df338bb4fa69cac3a89a08cd85b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3b5dfb8f46d248339023c48bbf1f7070","max":11153,"min":0,"orientation":"horizontal","style":"IPY_MODEL_12dd6a65b0c64c73a9b224f0af33b49f","value":11153}},"cf698bce66ab4fffa7c97d0753fc49a7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d0c99c2bf07b40baabe759ebf1cd73f4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d411270eed4a487a957f836011f1c1b3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d82e30e6819e4ce1b6c250b9c7f703ff":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc47551a2c134381af1e94b7c736a357":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_38496c2096014bb182b6802726a6c086","IPY_MODEL_2c51620748b8460aae4415897e3b464e","IPY_MODEL_e3a6fdc329da4c078e3b2ac7a3bbbef1"],"layout":"IPY_MODEL_b5bd78f99b52441e8bcdb21a6d9f3102"}},"dd78eb50c1bc42caaf122393286de01d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e026252033394ebcbb965a8fd37053bf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e357a60af21e4751ab236aac707fa043":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8c8e4c0c6e064fc58a3623374e10fd48","placeholder":"","style":"IPY_MODEL_bab5ac46b2cf4c038f5d1a6c6b1ba79a","value":"modeling_phi3.py:100%"}},"e3a6fdc329da4c078e3b2ac7a3bbbef1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e026252033394ebcbb965a8fd37053bf","placeholder":"","style":"IPY_MODEL_e670541eb0ca4d4cb08b18176300793c","value":"3.44k/3.44k[00:00&lt;00:00,191kB/s]"}},"e3f453f2b9c64e4e9b69bf87698cbb92":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e470a1fa5f3840c58a17dd2e051c3db6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e670541eb0ca4d4cb08b18176300793c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e6d26795de924ae58ac7a49b29d4aaa5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e7deaa0d282647be876890482d623908":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_17f4bd10c1f54bf781e7062dfda7a3c4","placeholder":"","style":"IPY_MODEL_a2050d0434d6436ebd17e368b1d3f8e3","value":"special_tokens_map.json:100%"}},"eb52bc275ae946ac80d7bcd5f5b2f5a4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"efbec3f178e74e93801570c7281bbaf4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f4f968a603bd4a03a9f0c5aeaaafac69":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fafd5e01a2c54e399ffdd01d5de30ff4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"feaec0fccff045828af84bf58ce002df":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}
