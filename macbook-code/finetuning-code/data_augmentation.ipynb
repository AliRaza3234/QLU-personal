{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "from openai import AsyncOpenAI\n",
    "from jinja2 import Template\n",
    "import pandas as pd\n",
    "import json\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_data = []\n",
    "with open('first_comparison.json') as f:\n",
    "    comparison_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "problematic_data = []\n",
    "problematic_queries = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in comparison_data:\n",
    "    if item.get(\"problem\"):\n",
    "        problematic_data.append(item)\n",
    "        problematic_queries.append(item[\"query\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Locate human resources specialists who exhibit expertise in talent acquisition, employee engagement strategies, performance management, and HRIS system functionality. Candidates should be positioned within the dynamic environment of New York City, New York, while consciously avoiding any associations with the hospitality sector.',\n",
       " 'marketplaces with revenue of USD 50m+, executive level role, based in Nordic countries',\n",
       " 'Please provide HR executives locate in the midwestern united states who have at least 15-years professional experience and have recruiting, talent acquisition or management in their background but who also possess HR generalist experience. They should be at a Senior Director level or above at a company exceeding $2 Billion in revenue',\n",
       " 'GM or VP for grocery companies in finland, make sure they have relevant experience',\n",
       " 'general managers with full end to end P&L experience of at least 200 million at companies in the mobility, assistive device, and rehab, ostomy care, home health care space in MedTech. Assume you are an expert financial analyst in the MedTech space',\n",
       " 'Find VP-level leaders from companies in Western Europe with over 30 years of experience and expertise in corporate finance.',\n",
       " 'owners of ketamine psychiatry clinic in the US']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(problematic_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_AUGMENTATION_SYSTEM_PROMPT = \"\"\"\n",
    "You are an AI agent tasked with data augmentation for recruiter search queries. Your goal is to generate additional queries that are both similar to and diverse from a given sample query. This augmented data will be used to finetune a model, so it's crucial that the generated queries are distinct while still capturing the essence of the original query.\n",
    "\"\"\"\n",
    "DATA_AUGMENTATION_USER_PROMPT = \"\"\"\n",
    "Here is the sample query you will be working with:\n",
    "<sample_query>\n",
    "{{SAMPLE_QUERY}}\n",
    "</sample_query>\n",
    "\n",
    "Your task is to generate two sets of queries based on this sample:\n",
    "\n",
    "1. Similar Queries:\n",
    "Generate 5 queries that are very similar to the sample query. These should:\n",
    "- Maintain the same overall intent and use case\n",
    "- Use similar wording and structure\n",
    "- Include minor variations in specifics (e.g., slightly different job titles, locations, or requirements)\n",
    "- Be distinct enough from each other and the original to provide valuable training data\n",
    "\n",
    "2. Diverse Queries:\n",
    "Generate 5 queries that are more diverse but still related to the sample query. These should:\n",
    "- Explore different aspects or variations of the original query's intent\n",
    "- Use different wording, structure, or focus\n",
    "- Potentially broaden or narrow the scope of the search\n",
    "- Introduce related concepts or requirements not present in the original query\n",
    "- Remain relevant to executive or specialized hiring scenarios\n",
    "\n",
    "Please provide your output in the following JSON format:\n",
    "<output>\n",
    "{\n",
    "  \"similar\": [\n",
    "    \"query1\",\n",
    "    \"query2\",\n",
    "    \"query3\",\n",
    "    \"query4\",\n",
    "    \"query5\"\n",
    "  ],\n",
    "  \"diverse\": [\n",
    "    \"query1\",\n",
    "    \"query2\",\n",
    "    \"query3\",\n",
    "    \"query4\",\n",
    "    \"query5\"\n",
    "  ]\n",
    "}\n",
    "</output>\n",
    "\n",
    "Additional guidelines:\n",
    "- Ensure that each generated query is unique and provides value for model training\n",
    "- Maintain a professional tone appropriate for executive recruitment\n",
    "- Avoid introducing biases or discriminatory language\n",
    "- Keep the queries realistic and relevant to actual hiring scenarios\n",
    "- Do not simply replicate the sample query with minor word changes\n",
    "\n",
    "Remember, the goal is to create a rich, varied dataset that will improve the model's understanding and performance in handling recruiter search queries.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "async def generate_queries_a(query, temperature=0.7, model=\"gpt-4o\", **kwargs):\n",
    "\n",
    "    \"\"\"\n",
    "    Function to run prompts on chatgpt\n",
    "\n",
    "    Args:\n",
    "        key (string): openai api key\n",
    "        messages (list): list of object that has the chat that you want to process with chatgpt. i.e. system prompt, assistant prompt and user prompt\n",
    "        temperature (float, optional): Temperature of gpt for generations. Defaults to 0.7.\n",
    "        model (str, optional): The model you want to use. Defaults to \"gpt-4o-mini\".\n",
    "\n",
    "    Returns:\n",
    "        string: chatgpt result\n",
    "    \"\"\"\n",
    "    # user_message = Template(NER_MANAGEMENT_LEVEL_TITLE_USER_PROMPT).render({\"QUERY\" : query})\n",
    "    user_message = Template(DATA_AUGMENTATION_USER_PROMPT).render({\"SAMPLE_QUERY\" : query})\n",
    "    messages = [\n",
    "            # {\"role\": \"system\", \"content\": NER_MANAGEMENT_LEVEL_TITLE_SYSTEM_PROMPT},\n",
    "            {\"role\": \"system\", \"content\": DATA_AUGMENTATION_SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": user_message},\n",
    "            \n",
    "    ]\n",
    "    openai_object = {\n",
    "        \"model\": model,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": temperature,\n",
    "    }\n",
    "    aclient = AsyncOpenAI(api_key=openai_api_key)\n",
    "\n",
    "    openai_object.update(kwargs)\n",
    "\n",
    "    response = await aclient.chat.completions.create(**openai_object)\n",
    "    response = response.__dict__\n",
    "    response[\"choices\"] = [choice.__dict__ for choice in response[\"choices\"]]\n",
    "    for choice in response[\"choices\"]:\n",
    "        choice[\"message\"] = choice[\"message\"].__dict__\n",
    "    return response\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_queries = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_augmented_queries = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"augmented_data_problem_queries.json\") as f:\n",
    "    augmented_queries = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in augmented_queries:\n",
    "    for key, value in item.items():\n",
    "        list_of_augmented_queries.extend(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"augmented_data_problem_queries.json\", \"w\") as f:  \n",
    "    json.dump(list_of_augmented_queries, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for query in problematic_queries:\n",
    "    response = await generate_queries_a(query)\n",
    "    augmented_queries.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_augmented_queries = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datumspeak",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
