{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_top_google_results(query, num_results=5):\n",
    "    \"\"\"\n",
    "    Fetch the top URL pages from Google search results for a given query without using an API.\n",
    "\n",
    "    Args:\n",
    "        query (str): Search query.\n",
    "        num_results (int): Number of top results to fetch (default: 5).\n",
    "\n",
    "    Returns:\n",
    "        list: A list of URLs of the top search results.\n",
    "    \"\"\"\n",
    "    # Encode the query for the URL\n",
    "    query = query.replace(\" \", \"+\")\n",
    "    google_url = f\"https://www.google.com/search?q={query}&num={num_results}\"\n",
    "\n",
    "    # Set user-agent to mimic a browser\n",
    "    headers = {\n",
    "        \"User-Agent\": (\n",
    "            \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 \"\n",
    "            \"(KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "        )\n",
    "    }\n",
    "\n",
    "    # Send a GET request to Google\n",
    "    response = requests.get(google_url, headers=headers)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    # Parse the response with BeautifulSoup\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # Extract URLs from search results\n",
    "    urls = []\n",
    "    for g in soup.find_all('div', class_='tF2Cxc'):  # Google search result containers\n",
    "        link = g.find('a', href=True)\n",
    "        if link and link['href']:\n",
    "            urls.append(link['href'])\n",
    "            if len(urls) == num_results:\n",
    "                break\n",
    "\n",
    "    return urls\n",
    "\n",
    "# Example usage\n",
    "query = \"apple's revenue in 2024\"\n",
    "top_urls = get_top_google_results(query)\n",
    "\n",
    "urls_list = []\n",
    "\n",
    "print(\"Top 5 URLs:\")\n",
    "for idx, url in enumerate(top_urls, start=1):\n",
    "    print(f\"{idx}: {url}\")\n",
    "    urls_list.append(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from crawl4ai import AsyncWebCrawler, CrawlerRunConfig\n",
    "from crawl4ai.content_filter_strategy import BM25ContentFilter\n",
    "from crawl4ai.markdown_generation_strategy import DefaultMarkdownGenerator\n",
    "\n",
    "async def main(query, url):\n",
    "    # 1) A BM25 filter with a user query\n",
    "    bm25_filter = BM25ContentFilter(\n",
    "        user_query=query,\n",
    "        # Adjust for stricter or looser results\n",
    "        bm25_threshold=1.2  \n",
    "    )\n",
    "\n",
    "    # 2) Insert into a Markdown Generator\n",
    "    md_generator = DefaultMarkdownGenerator(content_filter=bm25_filter)\n",
    "\n",
    "    # 3) Pass to crawler config\n",
    "    config = CrawlerRunConfig(\n",
    "        markdown_generator=md_generator,\n",
    "        word_count_threshold=10,\n",
    "        excluded_tags=[\"nav\", \"footer\", \"header\"],\n",
    "        exclude_external_links=True,\n",
    "        exclude_external_images=True.as_integer_ratio,\n",
    "        process_iframes=True,    \n",
    "        remove_overlay_elements=True\n",
    "    )\n",
    "\n",
    "    \n",
    "\n",
    "    async with AsyncWebCrawler() as crawler:\n",
    "        result = await crawler.arun(\n",
    "            url=url, \n",
    "            config=config\n",
    "        )\n",
    "        if result.success:\n",
    "            print(\"Fit Markdown (BM25 query-based):\")\n",
    "            print(result.markdown)\n",
    "            print('-'*47)\n",
    "        else:\n",
    "            print(\"Error:\", result.error_message)\n",
    "        \n",
    "        return result\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    result = asyncio.run(main(query=\"Private equity backed companies based in Europe\", url=\"https://en.wikipedia.org/wiki/List_of_private_equity_firms\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from typing import List, Union, Tuple\n",
    "import aiohttp\n",
    "import io\n",
    "import pdfplumber\n",
    "from crawl4ai import AsyncWebCrawler, CrawlerRunConfig\n",
    "from crawl4ai.content_filter_strategy import BM25ContentFilter\n",
    "from crawl4ai.markdown_generation_strategy import DefaultMarkdownGenerator\n",
    "\n",
    "async def is_pdf_url(session: aiohttp.ClientSession, url: str) -> bool:\n",
    "    try:\n",
    "        async with session.head(url, allow_redirects=True) as response:\n",
    "            if 'application/pdf' in response.headers.get('Content-Type', '').lower():\n",
    "                return True\n",
    "        async with session.get(url) as response:\n",
    "            chunk = await response.content.read(5)\n",
    "            return chunk.startswith(b'%PDF-')\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "async def extract_pdf_text(session: aiohttp.ClientSession, url: str) -> str:\n",
    "    async with session.get(url) as response:\n",
    "        pdf_content = await response.read()\n",
    "    with pdfplumber.open(io.BytesIO(pdf_content)) as pdf:\n",
    "        return \"\\n\".join(page.extract_text() for page in pdf.pages if page.extract_text())\n",
    "\n",
    "async def process_url(session: aiohttp.ClientSession, url: str, crawler: AsyncWebCrawler, \n",
    "                     config: CrawlerRunConfig) -> Tuple[bool, Union[str, Exception]]:\n",
    "    try:\n",
    "        if await is_pdf_url(session, url):\n",
    "            text = await extract_pdf_text(session, url)\n",
    "            return True, text\n",
    "        else:\n",
    "            result = await crawler.arun(url=url, config=config)\n",
    "            if result.success:\n",
    "                return True, result.markdown\n",
    "            return False, f\"Crawl failed: {result.error_message}\"\n",
    "    except Exception as e:\n",
    "        return False, e\n",
    "\n",
    "async def crawl_parallel(urls: List[str], max_concurrent: int = 3) -> List[Tuple[str, bool, Union[str, Exception]]]:\n",
    "    crawl_config = CrawlerRunConfig(\n",
    "        word_count_threshold=10,\n",
    "        excluded_tags=['script', 'style', 'nav', 'header', 'footer', \n",
    "                      'iframe', 'form', 'button', 'img', 'noscript',\n",
    "                      'svg', 'input', 'meta', 'select', 'textarea'],\n",
    "        exclude_external_links=True,\n",
    "        exclude_external_images=True,\n",
    "        process_iframes=False,\n",
    "        remove_overlay_elements=True\n",
    "    )\n",
    "\n",
    "    crawler = AsyncWebCrawler()\n",
    "    await crawler.start()\n",
    "    \n",
    "    # Create a semaphore to limit concurrent tasks\n",
    "    semaphore = asyncio.Semaphore(max_concurrent)\n",
    "\n",
    "    async def bounded_process_url(url: str) -> Tuple[str, bool, Union[str, Exception]]:\n",
    "        async with semaphore:\n",
    "            try:\n",
    "                async with aiohttp.ClientSession() as session:\n",
    "                    success, content = await process_url(session, url, crawler, crawl_config)\n",
    "                    return url, success, content\n",
    "            except Exception as e:\n",
    "                return url, False, str(e)\n",
    "\n",
    "    try:\n",
    "        # Process all URLs concurrently with bounded parallelism\n",
    "        tasks = [bounded_process_url(url) for url in urls]\n",
    "        results = await asyncio.gather(*tasks)\n",
    "        return results\n",
    "\n",
    "    finally:\n",
    "        await crawler.close()\n",
    "        \n",
    "\n",
    "async def main(urls: List[str]) -> List[Tuple[str, bool, Union[str, Exception]]]:\n",
    "    results = await crawl_parallel(urls,  max_concurrent=10)\n",
    "    \n",
    "    # # Print results (optional)\n",
    "    # for url, success, content in results:\n",
    "    #     if success:\n",
    "    #         print(f\"Successfully processed {url}\")\n",
    "    #         print(content[:200] + \"...\" if len(content) > 200 else content)\n",
    "    #     else:\n",
    "    #         print(f\"Failed to process {url}: {content}\")\n",
    "    #     print('-' * 47)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    urls = ['https://www.designboom.com/technology/meta-true-ar-glasses-orion-smartphones-hands-free-wearable-ai-device-09-26-2024/#:~:text=Meta%20unveils%20Orion%2C%20its%20dubbed,September%2025th%20and%2026th%2C%202024.',\n",
    "   'https://www.pymnts.com/connectedeconomy/2024/zuckerberg-unveils-metas-wearable-tech-plans-for-the-connected-economy/',\n",
    "   'https://sherwood.news/tech/meta-ray-ban-apple-vision-pro-competition/',\n",
    "   'https://www.theverge.com/2024/10/11/24267633/meta-hardware-glasses-quest-andrew-bosworth-interview',\n",
    "   'https://medium.com/@jcorcione/meta-reorganizes-introduces-wearables-unit-despite-job-cuts-d19f1dd10aa6',\n",
    "   \"https://www.aku.edu/admissions/Documents/student-health-services.pdf\",\n",
    "   'https://insidetelecom.com/wearable-technology-competition-between-apple-and-meta/',\n",
    "   'https://twit.tv/posts/tech/meta-and-future-wearable-tech',\n",
    "   'https://en.wikipedia.org/wiki/Smartglasses']\n",
    "    \n",
    "    urls = [\"https://www.google.com/search?q=what+is+the+revenue+of+bykea&rlz=1C5CHFA_enPK1041PK1041&oq=what+is+the+revenue+of+bykea&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIICAEQABgWGB4yDQgCEAAYhgMYgAQYigUyDQgDEAAYhgMYgAQYigUyDQgEEAAYhgMYgAQYigUyDQgFEAAYhgMYgAQYigUyCggGEAAYgAQYogQyCggHEAAYgAQYogQyCggIEAAYgAQYogQyBwgJEAAY7wXSAQg2MTk1ajBqN6gCALACAA&sourceid=chrome&ie=UTF-8\"]\n",
    "\n",
    "    results = await (main(urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import asyncio\n",
    "# from typing import List\n",
    "# from crawl4ai import AsyncWebCrawler, CrawlerRunConfig\n",
    "# from crawl4ai.content_filter_strategy import BM25ContentFilter\n",
    "# from crawl4ai.markdown_generation_strategy import DefaultMarkdownGenerator\n",
    "\n",
    "# async def crawl_parallel(urls: List[str], query: str, max_concurrent: int = 3):\n",
    "#     # Initialize BM25 filter\n",
    "#     bm25_filter = BM25ContentFilter(\n",
    "#         user_query=query,\n",
    "#         bm25_threshold=1.2  # Adjust for stricter or looser results\n",
    "#     )\n",
    "\n",
    "#     # Set up Markdown Generator\n",
    "#     md_generator = DefaultMarkdownGenerator(content_filter=bm25_filter)\n",
    "\n",
    "#     # Configure crawler\n",
    "#     crawl_config = CrawlerRunConfig(\n",
    "#         # markdown_generator=md_generator,\n",
    "#         word_count_threshold=10,\n",
    "#         excluded_tags=['script', 'style', 'nav', 'header', 'footer', \n",
    "#                                     'iframe', 'form', 'button', 'img', 'noscript',\n",
    "#                                     'svg', 'input', 'meta', 'select', 'textarea'],\n",
    "#         exclude_external_links=True,\n",
    "#         exclude_external_images=True,\n",
    "#         process_iframes=False,\n",
    "#         remove_overlay_elements=True\n",
    "#     )\n",
    "\n",
    "#     # Create crawler instance\n",
    "#     crawler = AsyncWebCrawler()\n",
    "#     await crawler.start()\n",
    "#     # Process URLs in parallel batches\n",
    "#     results = []\n",
    "\n",
    "#     try:\n",
    "#         for i in range(0, len(urls), max_concurrent):\n",
    "#             batch = urls[i : i + max_concurrent]\n",
    "#             tasks = [crawler.arun(url=url, config=crawl_config) for url in batch]  # Await coroutine\n",
    "#             batch_results = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "#             results.extend(batch_results)\n",
    "\n",
    "#         # Process results\n",
    "#         for url, result in zip(urls, results):\n",
    "#             if isinstance(result, Exception):\n",
    "#                 print(f\"Error crawling {url}: {result}\")\n",
    "#             elif result.success:\n",
    "#                 print(f\"Markdown for {url} (BM25 query-based):\")\n",
    "#                 print(result.markdown_v2.fit_markdown)\n",
    "#                 print('-' * 47)\n",
    "#                 print(result.markdown)\n",
    "#                 print('-' * 47)\n",
    "#             else:\n",
    "#                 print(f\"Failed to crawl {url}: {result.error_message}\")\n",
    "\n",
    "#     finally:\n",
    "#         # Close the crawler\n",
    "#         await crawler.close()\n",
    "#         return results\n",
    "\n",
    "# async def main(urls):  # Replace with your URLs\n",
    "#     query = \"Apple's Revenue in 2024\"\n",
    "#     results = await crawl_parallel(urls, query, max_concurrent=10)\n",
    "#     return results\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     urls = ['https://www.designboom.com/technology/meta-true-ar-glasses-orion-smartphones-hands-free-wearable-ai-device-09-26-2024/#:~:text=Meta%20unveils%20Orion%2C%20its%20dubbed,September%2025th%20and%2026th%2C%202024.',\n",
    "#    'https://www.pymnts.com/connectedeconomy/2024/zuckerberg-unveils-metas-wearable-tech-plans-for-the-connected-economy/',\n",
    "#    'https://sherwood.news/tech/meta-ray-ban-apple-vision-pro-competition/',\n",
    "#    'https://www.theverge.com/2024/10/11/24267633/meta-hardware-glasses-quest-andrew-bosworth-interview',\n",
    "#    'https://medium.com/@jcorcione/meta-reorganizes-introduces-wearables-unit-despite-job-cuts-d19f1dd10aa6',\n",
    "#    'https://insidetelecom.com/wearable-technology-competition-between-apple-and-meta/',\n",
    "#    'https://twit.tv/posts/tech/meta-and-future-wearable-tech',\n",
    "#    'https://en.wikipedia.org/wiki/Smartglasses']\n",
    "#     urls = [\"https://www.aku.edu/admissions/Documents/student-health-services.pdf\"]\n",
    "#     results = await (main(urls))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import ftfy\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "        \"\"\"Enhanced text cleaning function\"\"\"\n",
    "        try:\n",
    "            # Basic cleaning\n",
    "            text = ftfy.fix_text(text)  # Fix encoding issues\n",
    "            text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text)  # Remove URLs\n",
    "            text = re.sub(r'\\S+@\\S+', '', text)  # Remove Emails\n",
    "            text = re.sub(r'\\[.*?\\]|\\(.*?\\)', '', text)  # Remove markdown links\n",
    "            \n",
    "            # Remove special characters and normalize spaces\n",
    "            text = re.sub(r'[^\\x00-\\x7F]+', '', text)  # Remove non-ASCII characters\n",
    "            text = re.sub(r'[\\r\\n\\t]+', ' ', text)  # Replace newlines and tabs with space\n",
    "            text = re.sub(r'\\s+', ' ', text)  # Normalize whitespace\n",
    "            \n",
    "            # Remove common noise patterns\n",
    "            text = re.sub(r'Share\\s+on\\s+\\w+', '', text, flags=re.IGNORECASE)  # Remove social sharing text\n",
    "            text = re.sub(r'cookie[s]?\\s+policy', '', text, flags=re.IGNORECASE)  # Remove cookie notices\n",
    "            text = re.sub(r'subscribe|sign up|newsletter', '', text, flags=re.IGNORECASE)  # Remove promotional text\n",
    "            \n",
    "            # Remove very long strings (likely garbage)\n",
    "            text = ' '.join(word for word in text.split() if len(word) < 50)\n",
    "            \n",
    "            return text.strip()\n",
    "        except Exception as e:\n",
    "            print(f\"Error in clean_text: {str(e)}\")\n",
    "            return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "snippets = []\n",
    "with open('snippets.json') as f:\n",
    "    snippets = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "snippets_data = []\n",
    "for item in snippets:\n",
    "    snippets_list = []\n",
    "    urls_list = []\n",
    "    for snp in item['query_result']:\n",
    "        snippets_list.append(snp['snippet'])\n",
    "        urls_list.append(snp['link'])\n",
    "    snippets_data.append({'query': item['query'], 'snippets': snippets_list, 'urls': urls_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INIT].... → Crawl4AI 0.4.247\n",
      "[FETCH]... ↓ https://www.theverge.com/2024/10/11/24267633/meta-... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.theverge.com/2024/10/11/24267633/meta-... | Status: True | Total: 0.05s\n",
      "[FETCH]... ↓ https://medium.com/@jcorcione/meta-reorganizes-int... | Status: True | Time: 0.00s\n",
      "[COMPLETE] ● https://medium.com/@jcorcione/meta-reorganizes-int... | Status: True | Total: 0.04s\n",
      "[FETCH]... ↓ https://finance.yahoo.com/news/wearable-devices-bo... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://finance.yahoo.com/news/wearable-devices-bo... | Status: True | Total: 0.05s\n",
      "[FETCH]... ↓ https://sherwood.news/tech/meta-ray-ban-apple-visi... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://sherwood.news/tech/meta-ray-ban-apple-visi... | Status: True | Total: 0.08s\n",
      "[FETCH]... ↓ https://en.wikipedia.org/wiki/Smartglasses... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://en.wikipedia.org/wiki/Smartglasses... | Status: True | Total: 0.05s\n",
      "[FETCH]... ↓ https://www.designboom.com/technology/meta-true-ar... | Status: True | Time: 0.10s\n",
      "[COMPLETE] ● https://www.designboom.com/technology/meta-true-ar... | Status: True | Total: 0.14s\n",
      "[FETCH]... ↓ https://mediagrouponlineinc.com/2024/06/20/meta-re... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://mediagrouponlineinc.com/2024/06/20/meta-re... | Status: True | Total: 0.05s\n",
      "[FETCH]... ↓ https://www.inc.com/kit-eaton/meta-bets-on-augment... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.inc.com/kit-eaton/meta-bets-on-augment... | Status: True | Total: 0.05s\n",
      "[FETCH]... ↓ https://twit.tv/posts/tech/meta-and-future-wearabl... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://twit.tv/posts/tech/meta-and-future-wearabl... | Status: True | Total: 0.08s\n",
      "[FETCH]... ↓ https://www.pymnts.com/connectedeconomy/2024/zucke... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.pymnts.com/connectedeconomy/2024/zucke... | Status: True | Total: 0.05s\n",
      "[FETCH]... ↓ https://insidetelecom.com/wearable-technology-comp... | Status: True | Time: 0.00s\n",
      "[COMPLETE] ● https://insidetelecom.com/wearable-technology-comp... | Status: True | Total: 0.04s\n",
      "--------------------------\n",
      "11 11\n",
      "--------------------------\n",
      "11 11\n",
      "[INIT].... → Crawl4AI 0.4.247\n",
      "[FETCH]... ↓ https://www.designrush.com/agency/wearable-technol... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.designrush.com/agency/wearable-technol... | Status: True | Total: 0.05s\n",
      "[FETCH]... ↓ https://www.builtinnyc.com/companies/type/wearable... | Status: True | Time: 0.00s\n",
      "[COMPLETE] ● https://www.builtinnyc.com/companies/type/wearable... | Status: True | Total: 0.04s\n",
      "[FETCH]... ↓ https://mobile-magazine.com/top10/top-10-wearable-... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://mobile-magazine.com/top10/top-10-wearable-... | Status: True | Total: 0.06s\n",
      "[FETCH]... ↓ https://public.com/themes/wearables... | Status: True | Time: 0.14s\n",
      "[COMPLETE] ● https://public.com/themes/wearables... | Status: True | Total: 0.20s\n",
      "[FETCH]... ↓ https://wellfound.com/job-collections/top-wearable... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://wellfound.com/job-collections/top-wearable... | Status: True | Total: 0.05s\n",
      "[FETCH]... ↓ https://www.imarcgroup.com/industrial-wearable-dev... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.imarcgroup.com/industrial-wearable-dev... | Status: True | Total: 0.08s\n",
      "[FETCH]... ↓ https://www.builtinboston.com/companies/type/weara... | Status: True | Time: 0.16s\n",
      "[COMPLETE] ● https://www.builtinboston.com/companies/type/weara... | Status: True | Total: 0.22s\n",
      "[FETCH]... ↓ https://builtin.com/companies/type/wearables-compa... | Status: True | Time: 0.30s\n",
      "[COMPLETE] ● https://builtin.com/companies/type/wearables-compa... | Status: True | Total: 0.36s\n",
      "[FETCH]... ↓ https://www.marketsandmarkets.com/ResearchInsight/... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.marketsandmarkets.com/ResearchInsight/... | Status: True | Total: 0.05s\n",
      "[FETCH]... ↓ https://explodingtopics.com/blog/wearable-startups... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://explodingtopics.com/blog/wearable-startups... | Status: True | Total: 0.05s\n",
      "--------------------------\n",
      "10 10\n",
      "--------------------------\n",
      "10 10\n",
      "[INIT].... → Crawl4AI 0.4.247\n",
      "[FETCH]... ↓ https://www.goodfirms.co/resources/apple-launches-... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.goodfirms.co/resources/apple-launches-... | Status: True | Total: 0.09s\n",
      "[FETCH]... ↓ https://www.theverge.com/2024/9/8/24237890/apple-w... | Status: True | Time: 0.00s\n",
      "[COMPLETE] ● https://www.theverge.com/2024/9/8/24237890/apple-w... | Status: True | Total: 0.04s\n",
      "[FETCH]... ↓ https://www.industryweek.com/technology-and-iiot/a... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.industryweek.com/technology-and-iiot/a... | Status: True | Total: 0.05s\n",
      "[FETCH]... ↓ https://www.theverge.com/2024/9/8/24237890/apple-w... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.theverge.com/2024/9/8/24237890/apple-w... | Status: True | Total: 0.05s\n",
      "[FETCH]... ↓ https://www.straitstimes.com/tech/smartwatch-maker... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.straitstimes.com/tech/smartwatch-maker... | Status: True | Total: 0.05s\n",
      "[FETCH]... ↓ https://finshots.in/archive/how-apple-is-dominatin... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://finshots.in/archive/how-apple-is-dominatin... | Status: True | Total: 0.04s\n",
      "[FETCH]... ↓ https://channellife.co.nz/story/apple-still-owns-g... | Status: True | Time: 0.00s\n",
      "[COMPLETE] ● https://channellife.co.nz/story/apple-still-owns-g... | Status: True | Total: 0.05s\n",
      "[FETCH]... ↓ https://mobile-magazine.com/top10/top-10-wearable-... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://mobile-magazine.com/top10/top-10-wearable-... | Status: True | Total: 0.06s\n",
      "[FETCH]... ↓ https://www.cnbc.com/2021/12/12/what-apple-google-... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.cnbc.com/2021/12/12/what-apple-google-... | Status: True | Total: 0.06s\n",
      "[FETCH]... ↓ https://techwithdom.com/blog/should-apple-release-... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://techwithdom.com/blog/should-apple-release-... | Status: True | Total: 0.05s\n",
      "--------------------------\n",
      "10 10\n",
      "--------------------------\n",
      "10 10\n",
      "[INIT].... → Crawl4AI 0.4.247\n",
      "[ERROR]... × https://r.search.yahoo.com/_ylt=AwrNZdTXh4dn5wEAhR... | Error: \n",
      "┌───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
      "│ × Unexpected error in _crawl_web at line 528 in wrap_api_call                                                         │\n",
      "│ (../../../../../miniconda3/envs/graphRAG/lib/python3.9/site-packages/playwright/_impl/_connection.py):                │\n",
      "│   Error: BrowserContext.add_cookies: Protocol error (Storage.setCookies): Invalid cookie fields                       │\n",
      "│                                                                                                                       │\n",
      "│   Code context:                                                                                                       │\n",
      "│   523           parsed_st = _extract_stack_trace_information_from_stack(st, is_internal)                              │\n",
      "│   524           self._api_zone.set(parsed_st)                                                                         │\n",
      "│   525           try:                                                                                                  │\n",
      "│   526               return await cb()                                                                                 │\n",
      "│   527           except Exception as error:                                                                            │\n",
      "│   528 →             raise rewrite_error(error, f\"{parsed_st['apiName']}: {error}\") from None                          │\n",
      "│   529           finally:                                                                                              │\n",
      "│   530               self._api_zone.set(None)                                                                          │\n",
      "│   531                                                                                                                 │\n",
      "│   532       def wrap_api_call_sync(                                                                                   │\n",
      "│   533           self, cb: Callable[[], Any], is_internal: bool = False                                                │\n",
      "└───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\n",
      "\n",
      "[ERROR]... × https://r.search.yahoo.com/_ylt=AwrNZdTXh4dn5wEAah... | Error: \n",
      "┌───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
      "│ × Unexpected error in _crawl_web at line 528 in wrap_api_call                                                         │\n",
      "│ (../../../../../miniconda3/envs/graphRAG/lib/python3.9/site-packages/playwright/_impl/_connection.py):                │\n",
      "│   Error: BrowserContext.add_cookies: Protocol error (Storage.setCookies): Invalid cookie fields                       │\n",
      "│                                                                                                                       │\n",
      "│   Code context:                                                                                                       │\n",
      "│   523           parsed_st = _extract_stack_trace_information_from_stack(st, is_internal)                              │\n",
      "│   524           self._api_zone.set(parsed_st)                                                                         │\n",
      "│   525           try:                                                                                                  │\n",
      "│   526               return await cb()                                                                                 │\n",
      "│   527           except Exception as error:                                                                            │\n",
      "│   528 →             raise rewrite_error(error, f\"{parsed_st['apiName']}: {error}\") from None                          │\n",
      "│   529           finally:                                                                                              │\n",
      "│   530               self._api_zone.set(None)                                                                          │\n",
      "│   531                                                                                                                 │\n",
      "│   532       def wrap_api_call_sync(                                                                                   │\n",
      "│   533           self, cb: Callable[[], Any], is_internal: bool = False                                                │\n",
      "└───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\n",
      "\n",
      "[ERROR]... × https://r.search.yahoo.com/_ylt=AwrNZdTXh4dn5wEAdR... | Error: \n",
      "┌───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
      "│ × Unexpected error in _crawl_web at line 528 in wrap_api_call                                                         │\n",
      "│ (../../../../../miniconda3/envs/graphRAG/lib/python3.9/site-packages/playwright/_impl/_connection.py):                │\n",
      "│   Error: BrowserContext.add_cookies: Protocol error (Storage.setCookies): Invalid cookie fields                       │\n",
      "│                                                                                                                       │\n",
      "│   Code context:                                                                                                       │\n",
      "│   523           parsed_st = _extract_stack_trace_information_from_stack(st, is_internal)                              │\n",
      "│   524           self._api_zone.set(parsed_st)                                                                         │\n",
      "│   525           try:                                                                                                  │\n",
      "│   526               return await cb()                                                                                 │\n",
      "│   527           except Exception as error:                                                                            │\n",
      "│   528 →             raise rewrite_error(error, f\"{parsed_st['apiName']}: {error}\") from None                          │\n",
      "│   529           finally:                                                                                              │\n",
      "│   530               self._api_zone.set(None)                                                                          │\n",
      "│   531                                                                                                                 │\n",
      "│   532       def wrap_api_call_sync(                                                                                   │\n",
      "│   533           self, cb: Callable[[], Any], is_internal: bool = False                                                │\n",
      "└───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\n",
      "\n",
      "[ERROR]... × https://r.search.yahoo.com/_ylt=AwrNZdTXh4dn5wEAdx... | Error: \n",
      "┌───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
      "│ × Unexpected error in _crawl_web at line 528 in wrap_api_call                                                         │\n",
      "│ (../../../../../miniconda3/envs/graphRAG/lib/python3.9/site-packages/playwright/_impl/_connection.py):                │\n",
      "│   Error: BrowserContext.add_cookies: Protocol error (Storage.setCookies): Invalid cookie fields                       │\n",
      "│                                                                                                                       │\n",
      "│   Code context:                                                                                                       │\n",
      "│   523           parsed_st = _extract_stack_trace_information_from_stack(st, is_internal)                              │\n",
      "│   524           self._api_zone.set(parsed_st)                                                                         │\n",
      "│   525           try:                                                                                                  │\n",
      "│   526               return await cb()                                                                                 │\n",
      "│   527           except Exception as error:                                                                            │\n",
      "│   528 →             raise rewrite_error(error, f\"{parsed_st['apiName']}: {error}\") from None                          │\n",
      "│   529           finally:                                                                                              │\n",
      "│   530               self._api_zone.set(None)                                                                          │\n",
      "│   531                                                                                                                 │\n",
      "│   532       def wrap_api_call_sync(                                                                                   │\n",
      "│   533           self, cb: Callable[[], Any], is_internal: bool = False                                                │\n",
      "└───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\n",
      "\n",
      "[ERROR]... × https://r.search.yahoo.com/_ylt=AwrNZdTXh4dn5wEAWx... | Error: \n",
      "┌───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
      "│ × Unexpected error in _crawl_web at line 528 in wrap_api_call                                                         │\n",
      "│ (../../../../../miniconda3/envs/graphRAG/lib/python3.9/site-packages/playwright/_impl/_connection.py):                │\n",
      "│   Error: BrowserContext.add_cookies: Protocol error (Storage.setCookies): Invalid cookie fields                       │\n",
      "│                                                                                                                       │\n",
      "│   Code context:                                                                                                       │\n",
      "│   523           parsed_st = _extract_stack_trace_information_from_stack(st, is_internal)                              │\n",
      "│   524           self._api_zone.set(parsed_st)                                                                         │\n",
      "│   525           try:                                                                                                  │\n",
      "│   526               return await cb()                                                                                 │\n",
      "│   527           except Exception as error:                                                                            │\n",
      "│   528 →             raise rewrite_error(error, f\"{parsed_st['apiName']}: {error}\") from None                          │\n",
      "│   529           finally:                                                                                              │\n",
      "│   530               self._api_zone.set(None)                                                                          │\n",
      "│   531                                                                                                                 │\n",
      "│   532       def wrap_api_call_sync(                                                                                   │\n",
      "│   533           self, cb: Callable[[], Any], is_internal: bool = False                                                │\n",
      "└───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\n",
      "\n",
      "[ERROR]... × https://r.search.yahoo.com/_ylt=AwrNZdTXh4dn5wEAWR... | Error: \n",
      "┌───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
      "│ × Unexpected error in _crawl_web at line 528 in wrap_api_call                                                         │\n",
      "│ (../../../../../miniconda3/envs/graphRAG/lib/python3.9/site-packages/playwright/_impl/_connection.py):                │\n",
      "│   Error: BrowserContext.add_cookies: Protocol error (Storage.setCookies): Invalid cookie fields                       │\n",
      "│                                                                                                                       │\n",
      "│   Code context:                                                                                                       │\n",
      "│   523           parsed_st = _extract_stack_trace_information_from_stack(st, is_internal)                              │\n",
      "│   524           self._api_zone.set(parsed_st)                                                                         │\n",
      "│   525           try:                                                                                                  │\n",
      "│   526               return await cb()                                                                                 │\n",
      "│   527           except Exception as error:                                                                            │\n",
      "│   528 →             raise rewrite_error(error, f\"{parsed_st['apiName']}: {error}\") from None                          │\n",
      "│   529           finally:                                                                                              │\n",
      "│   530               self._api_zone.set(None)                                                                          │\n",
      "│   531                                                                                                                 │\n",
      "│   532       def wrap_api_call_sync(                                                                                   │\n",
      "│   533           self, cb: Callable[[], Any], is_internal: bool = False                                                │\n",
      "└───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\n",
      "\n",
      "[ERROR]... × https://r.search.yahoo.com/_ylt=AwrNZdTXh4dn5wEAbB... | Error: \n",
      "┌───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
      "│ × Unexpected error in _crawl_web at line 528 in wrap_api_call                                                         │\n",
      "│ (../../../../../miniconda3/envs/graphRAG/lib/python3.9/site-packages/playwright/_impl/_connection.py):                │\n",
      "│   Error: BrowserContext.add_cookies: Protocol error (Storage.setCookies): Invalid cookie fields                       │\n",
      "│                                                                                                                       │\n",
      "│   Code context:                                                                                                       │\n",
      "│   523           parsed_st = _extract_stack_trace_information_from_stack(st, is_internal)                              │\n",
      "│   524           self._api_zone.set(parsed_st)                                                                         │\n",
      "│   525           try:                                                                                                  │\n",
      "│   526               return await cb()                                                                                 │\n",
      "│   527           except Exception as error:                                                                            │\n",
      "│   528 →             raise rewrite_error(error, f\"{parsed_st['apiName']}: {error}\") from None                          │\n",
      "│   529           finally:                                                                                              │\n",
      "│   530               self._api_zone.set(None)                                                                          │\n",
      "│   531                                                                                                                 │\n",
      "│   532       def wrap_api_call_sync(                                                                                   │\n",
      "│   533           self, cb: Callable[[], Any], is_internal: bool = False                                                │\n",
      "└───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\n",
      "\n",
      "--------------------------\n",
      "7 7\n",
      "--------------------------\n",
      "7 7\n",
      "[INIT].... → Crawl4AI 0.4.247\n",
      "[FETCH]... ↓ https://healthcare-digital.com/digital-healthcare/... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://healthcare-digital.com/digital-healthcare/... | Status: True | Total: 0.05s\n",
      "[FETCH]... ↓ https://www.mordorintelligence.com/industry-report... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.mordorintelligence.com/industry-report... | Status: True | Total: 0.08s\n",
      "[FETCH]... ↓ https://mobile-magazine.com/top10/top-10-wearable-... | Status: True | Time: 0.17s\n",
      "[COMPLETE] ● https://mobile-magazine.com/top10/top-10-wearable-... | Status: True | Total: 0.26s\n",
      "[FETCH]... ↓ https://www.escatec.com/blog/wearable-medical-devi... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.escatec.com/blog/wearable-medical-devi... | Status: True | Total: 0.05s\n",
      "[FETCH]... ↓ https://builtin.com/articles/wearable-technology-i... | Status: True | Time: 0.00s\n",
      "[COMPLETE] ● https://builtin.com/articles/wearable-technology-i... | Status: True | Total: 0.04s\n",
      "[FETCH]... ↓ https://www.emergenresearch.com/blog/top-10-compan... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.emergenresearch.com/blog/top-10-compan... | Status: True | Total: 0.05s\n",
      "[FETCH]... ↓ https://www.verifiedmarketresearch.com/blog/top-we... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.verifiedmarketresearch.com/blog/top-we... | Status: True | Total: 0.05s\n",
      "[FETCH]... ↓ https://www.marketresearchfuture.com/reports/weara... | Status: True | Time: 0.00s\n",
      "[COMPLETE] ● https://www.marketresearchfuture.com/reports/weara... | Status: True | Total: 0.05s\n",
      "[FETCH]... ↓ https://explodingtopics.com/blog/wearable-startups... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://explodingtopics.com/blog/wearable-startups... | Status: True | Total: 0.06s\n",
      "[FETCH]... ↓ https://adamosoft.com/blog/healthcare-software-dev... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://adamosoft.com/blog/healthcare-software-dev... | Status: True | Total: 0.07s\n",
      "--------------------------\n",
      "10 10\n",
      "--------------------------\n",
      "10 10\n",
      "[INIT].... → Crawl4AI 0.4.247\n",
      "[FETCH]... ↓ https://www.cience.com/companies-database/united-s... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.cience.com/companies-database/united-s... | Status: True | Total: 0.08s\n",
      "[FETCH]... ↓ https://www.crunchbase.com/hub/united-states-compa... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.crunchbase.com/hub/united-states-compa... | Status: True | Total: 0.06s\n",
      "[FETCH]... ↓ https://en.wikipedia.org/wiki/List_of_largest_comp... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://en.wikipedia.org/wiki/List_of_largest_comp... | Status: True | Total: 0.05s\n",
      "[FETCH]... ↓ https://www.quora.com/How-many-companies-in-the-wo... | Status: True | Time: 0.11s\n",
      "[COMPLETE] ● https://www.quora.com/How-many-companies-in-the-wo... | Status: True | Total: 0.18s\n",
      "[FETCH]... ↓ https://companiesmarketcap.com/largest-companies-b... | Status: True | Time: 0.00s\n",
      "[COMPLETE] ● https://companiesmarketcap.com/largest-companies-b... | Status: True | Total: 0.05s\n",
      "[FETCH]... ↓ https://fortune.com/ranking/global500/... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://fortune.com/ranking/global500/... | Status: True | Total: 0.05s\n",
      "[FETCH]... ↓ https://stockanalysis.com/list/highest-revenue/... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://stockanalysis.com/list/highest-revenue/... | Status: True | Total: 0.06s\n",
      "[FETCH]... ↓ https://www.statista.com/statistics/263265/top-com... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.statista.com/statistics/263265/top-com... | Status: True | Total: 0.05s\n",
      "[FETCH]... ↓ https://gfmag.com/data/biggest-company-in-the-worl... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://gfmag.com/data/biggest-company-in-the-worl... | Status: True | Total: 0.10s\n",
      "--------------------------\n",
      "10 10\n",
      "--------------------------\n",
      "10 10\n",
      "[INIT].... → Crawl4AI 0.4.247\n",
      "[FETCH]... ↓ https://www.cbinsights.com/research-unicorn-compan... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.cbinsights.com/research-unicorn-compan... | Status: True | Total: 0.05s\n",
      "[FETCH]... ↓ https://www.cience.com/companies-database/united-s... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.cience.com/companies-database/united-s... | Status: True | Total: 0.07s\n",
      "[FETCH]... ↓ https://fortune.com/ranking/global500/... | Status: True | Time: 0.17s\n",
      "[COMPLETE] ● https://fortune.com/ranking/global500/... | Status: True | Total: 0.23s\n",
      "[FETCH]... ↓ https://en.wikipedia.org/wiki/List_of_largest_comp... | Status: True | Time: 0.16s\n",
      "[COMPLETE] ● https://en.wikipedia.org/wiki/List_of_largest_comp... | Status: True | Total: 0.23s\n",
      "[FETCH]... ↓ https://www.crunchbase.com/hub/companies-more-than... | Status: True | Time: 0.35s\n",
      "[COMPLETE] ● https://www.crunchbase.com/hub/companies-more-than... | Status: True | Total: 0.42s\n",
      "[FETCH]... ↓ https://www.crunchbase.com/hub/united-states-compa... | Status: True | Time: 0.50s\n",
      "[COMPLETE] ● https://www.crunchbase.com/hub/united-states-compa... | Status: True | Total: 0.58s\n",
      "[FETCH]... ↓ https://www.quora.com/How-many-companies-in-the-wo... | Status: True | Time: 0.36s\n",
      "[COMPLETE] ● https://www.quora.com/How-many-companies-in-the-wo... | Status: True | Total: 0.43s\n",
      "[FETCH]... ↓ https://www.visualcapitalist.com/the-worlds-top-co... | Status: True | Time: 0.52s\n",
      "[COMPLETE] ● https://www.visualcapitalist.com/the-worlds-top-co... | Status: True | Total: 0.59s\n",
      "[FETCH]... ↓ https://gfmag.com/data/biggest-company-in-the-worl... | Status: True | Time: 0.16s\n",
      "[COMPLETE] ● https://gfmag.com/data/biggest-company-in-the-worl... | Status: True | Total: 0.23s\n",
      "[FETCH]... ↓ https://www.forbes.com/lists/asia200/... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.forbes.com/lists/asia200/... | Status: True | Total: 0.06s\n",
      "--------------------------\n",
      "10 10\n",
      "--------------------------\n",
      "10 10\n",
      "[INIT].... → Crawl4AI 0.4.247\n",
      "[FETCH]... ↓ https://www.investing.com/academy/statistics/tesla... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.investing.com/academy/statistics/tesla... | Status: True | Total: 0.05s\n",
      "[FETCH]... ↓ https://finimize.com/content/framework-assess-whet... | Status: True | Time: 0.12s\n",
      "[COMPLETE] ● https://finimize.com/content/framework-assess-whet... | Status: True | Total: 0.18s\n",
      "[FETCH]... ↓ https://www.visualcapitalist.com/charted-teslas-un... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.visualcapitalist.com/charted-teslas-un... | Status: True | Total: 0.06s\n",
      "[FETCH]... ↓ https://www.visualcapitalist.com/charted-teslas-ma... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.visualcapitalist.com/charted-teslas-ma... | Status: True | Total: 0.07s\n",
      "[FETCH]... ↓ https://m.economictimes.com/news/international/bus... | Status: True | Time: 0.16s\n",
      "[COMPLETE] ● https://m.economictimes.com/news/international/bus... | Status: True | Total: 0.23s\n",
      "[FETCH]... ↓ https://www.investors.com/news/tesla-stock-tesla-p... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.investors.com/news/tesla-stock-tesla-p... | Status: True | Total: 0.05s\n",
      "[FETCH]... ↓ https://www.reddit.com/r/electricvehicles/comments... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.reddit.com/r/electricvehicles/comments... | Status: True | Total: 0.05s\n",
      "[FETCH]... ↓ https://www.cnn.com/2021/01/31/investing/tesla-pro... | Status: True | Time: 0.05s\n",
      "[COMPLETE] ● https://www.cnn.com/2021/01/31/investing/tesla-pro... | Status: True | Total: 0.12s\n",
      "[FETCH]... ↓ https://www.cnn.com/2024/01/02/business/tesla-sale... | Status: True | Time: 0.04s\n",
      "[COMPLETE] ● https://www.cnn.com/2024/01/02/business/tesla-sale... | Status: True | Total: 0.11s\n",
      "[FETCH]... ↓ https://www.buyacar.co.uk/the-latest-tesla-statist... | Status: True | Time: 0.02s\n",
      "[COMPLETE] ● https://www.buyacar.co.uk/the-latest-tesla-statist... | Status: True | Total: 0.07s\n",
      "--------------------------\n",
      "10 10\n",
      "--------------------------\n",
      "10 10\n",
      "[INIT].... → Crawl4AI 0.4.247\n",
      "[ERROR]... × https://r.search.yahoo.com/_ylt=AwrEtOjoh4dnHdgCR3... | Error: \n",
      "┌───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
      "│ × Unexpected error in _crawl_web at line 528 in wrap_api_call                                                         │\n",
      "│ (../../../../../miniconda3/envs/graphRAG/lib/python3.9/site-packages/playwright/_impl/_connection.py):                │\n",
      "│   Error: BrowserContext.add_cookies: Protocol error (Storage.setCookies): Invalid cookie fields                       │\n",
      "│                                                                                                                       │\n",
      "│   Code context:                                                                                                       │\n",
      "│   523           parsed_st = _extract_stack_trace_information_from_stack(st, is_internal)                              │\n",
      "│   524           self._api_zone.set(parsed_st)                                                                         │\n",
      "│   525           try:                                                                                                  │\n",
      "│   526               return await cb()                                                                                 │\n",
      "│   527           except Exception as error:                                                                            │\n",
      "│   528 →             raise rewrite_error(error, f\"{parsed_st['apiName']}: {error}\") from None                          │\n",
      "│   529           finally:                                                                                              │\n",
      "│   530               self._api_zone.set(None)                                                                          │\n",
      "│   531                                                                                                                 │\n",
      "│   532       def wrap_api_call_sync(                                                                                   │\n",
      "│   533           self, cb: Callable[[], Any], is_internal: bool = False                                                │\n",
      "└───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\n",
      "\n",
      "[ERROR]... × https://r.search.yahoo.com/_ylt=AwrEtOjoh4dnHdgCOH... | Error: \n",
      "┌───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
      "│ × Unexpected error in _crawl_web at line 528 in wrap_api_call                                                         │\n",
      "│ (../../../../../miniconda3/envs/graphRAG/lib/python3.9/site-packages/playwright/_impl/_connection.py):                │\n",
      "│   Error: BrowserContext.add_cookies: Protocol error (Storage.setCookies): Invalid cookie fields                       │\n",
      "│                                                                                                                       │\n",
      "│   Code context:                                                                                                       │\n",
      "│   523           parsed_st = _extract_stack_trace_information_from_stack(st, is_internal)                              │\n",
      "│   524           self._api_zone.set(parsed_st)                                                                         │\n",
      "│   525           try:                                                                                                  │\n",
      "│   526               return await cb()                                                                                 │\n",
      "│   527           except Exception as error:                                                                            │\n",
      "│   528 →             raise rewrite_error(error, f\"{parsed_st['apiName']}: {error}\") from None                          │\n",
      "│   529           finally:                                                                                              │\n",
      "│   530               self._api_zone.set(None)                                                                          │\n",
      "│   531                                                                                                                 │\n",
      "│   532       def wrap_api_call_sync(                                                                                   │\n",
      "│   533           self, cb: Callable[[], Any], is_internal: bool = False                                                │\n",
      "└───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\n",
      "\n",
      "[ERROR]... × https://r.search.yahoo.com/_ylt=AwrEtOjoh4dnHdgCT3... | Error: \n",
      "┌───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
      "│ × Unexpected error in _crawl_web at line 528 in wrap_api_call                                                         │\n",
      "│ (../../../../../miniconda3/envs/graphRAG/lib/python3.9/site-packages/playwright/_impl/_connection.py):                │\n",
      "│   Error: BrowserContext.add_cookies: Protocol error (Storage.setCookies): Invalid cookie fields                       │\n",
      "│                                                                                                                       │\n",
      "│   Code context:                                                                                                       │\n",
      "│   523           parsed_st = _extract_stack_trace_information_from_stack(st, is_internal)                              │\n",
      "│   524           self._api_zone.set(parsed_st)                                                                         │\n",
      "│   525           try:                                                                                                  │\n",
      "│   526               return await cb()                                                                                 │\n",
      "│   527           except Exception as error:                                                                            │\n",
      "│   528 →             raise rewrite_error(error, f\"{parsed_st['apiName']}: {error}\") from None                          │\n",
      "│   529           finally:                                                                                              │\n",
      "│   530               self._api_zone.set(None)                                                                          │\n",
      "│   531                                                                                                                 │\n",
      "│   532       def wrap_api_call_sync(                                                                                   │\n",
      "│   533           self, cb: Callable[[], Any], is_internal: bool = False                                                │\n",
      "└───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\n",
      "\n",
      "[ERROR]... × https://r.search.yahoo.com/_ylt=AwrEtOjoh4dnHdgCUX... | Error: \n",
      "┌───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
      "│ × Unexpected error in _crawl_web at line 528 in wrap_api_call                                                         │\n",
      "│ (../../../../../miniconda3/envs/graphRAG/lib/python3.9/site-packages/playwright/_impl/_connection.py):                │\n",
      "│   Error: BrowserContext.add_cookies: Protocol error (Storage.setCookies): Invalid cookie fields                       │\n",
      "│                                                                                                                       │\n",
      "│   Code context:                                                                                                       │\n",
      "│   523           parsed_st = _extract_stack_trace_information_from_stack(st, is_internal)                              │\n",
      "│   524           self._api_zone.set(parsed_st)                                                                         │\n",
      "│   525           try:                                                                                                  │\n",
      "│   526               return await cb()                                                                                 │\n",
      "│   527           except Exception as error:                                                                            │\n",
      "│   528 →             raise rewrite_error(error, f\"{parsed_st['apiName']}: {error}\") from None                          │\n",
      "│   529           finally:                                                                                              │\n",
      "│   530               self._api_zone.set(None)                                                                          │\n",
      "│   531                                                                                                                 │\n",
      "│   532       def wrap_api_call_sync(                                                                                   │\n",
      "│   533           self, cb: Callable[[], Any], is_internal: bool = False                                                │\n",
      "└───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\n",
      "\n",
      "[ERROR]... × https://r.search.yahoo.com/_ylt=AwrEtOjoh4dnHdgCTX... | Error: \n",
      "┌───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
      "│ × Unexpected error in _crawl_web at line 528 in wrap_api_call                                                         │\n",
      "│ (../../../../../miniconda3/envs/graphRAG/lib/python3.9/site-packages/playwright/_impl/_connection.py):                │\n",
      "│   Error: BrowserContext.add_cookies: Protocol error (Storage.setCookies): Invalid cookie fields                       │\n",
      "│                                                                                                                       │\n",
      "│   Code context:                                                                                                       │\n",
      "│   523           parsed_st = _extract_stack_trace_information_from_stack(st, is_internal)                              │\n",
      "│   524           self._api_zone.set(parsed_st)                                                                         │\n",
      "│   525           try:                                                                                                  │\n",
      "│   526               return await cb()                                                                                 │\n",
      "│   527           except Exception as error:                                                                            │\n",
      "│   528 →             raise rewrite_error(error, f\"{parsed_st['apiName']}: {error}\") from None                          │\n",
      "│   529           finally:                                                                                              │\n",
      "│   530               self._api_zone.set(None)                                                                          │\n",
      "│   531                                                                                                                 │\n",
      "│   532       def wrap_api_call_sync(                                                                                   │\n",
      "│   533           self, cb: Callable[[], Any], is_internal: bool = False                                                │\n",
      "└───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\n",
      "\n",
      "[ERROR]... × https://r.search.yahoo.com/_ylt=AwrEtOjoh4dnHdgCMX... | Error: \n",
      "┌───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
      "│ × Unexpected error in _crawl_web at line 528 in wrap_api_call                                                         │\n",
      "│ (../../../../../miniconda3/envs/graphRAG/lib/python3.9/site-packages/playwright/_impl/_connection.py):                │\n",
      "│   Error: BrowserContext.add_cookies: Protocol error (Storage.setCookies): Invalid cookie fields                       │\n",
      "│                                                                                                                       │\n",
      "│   Code context:                                                                                                       │\n",
      "│   523           parsed_st = _extract_stack_trace_information_from_stack(st, is_internal)                              │\n",
      "│   524           self._api_zone.set(parsed_st)                                                                         │\n",
      "│   525           try:                                                                                                  │\n",
      "│   526               return await cb()                                                                                 │\n",
      "│   527           except Exception as error:                                                                            │\n",
      "│   528 →             raise rewrite_error(error, f\"{parsed_st['apiName']}: {error}\") from None                          │\n",
      "│   529           finally:                                                                                              │\n",
      "│   530               self._api_zone.set(None)                                                                          │\n",
      "│   531                                                                                                                 │\n",
      "│   532       def wrap_api_call_sync(                                                                                   │\n",
      "│   533           self, cb: Callable[[], Any], is_internal: bool = False                                                │\n",
      "└───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\n",
      "\n",
      "[ERROR]... × https://r.search.yahoo.com/_ylt=AwrEtOjoh4dnHdgCX3... | Error: \n",
      "┌───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
      "│ × Unexpected error in _crawl_web at line 528 in wrap_api_call                                                         │\n",
      "│ (../../../../../miniconda3/envs/graphRAG/lib/python3.9/site-packages/playwright/_impl/_connection.py):                │\n",
      "│   Error: BrowserContext.add_cookies: Protocol error (Storage.setCookies): Invalid cookie fields                       │\n",
      "│                                                                                                                       │\n",
      "│   Code context:                                                                                                       │\n",
      "│   523           parsed_st = _extract_stack_trace_information_from_stack(st, is_internal)                              │\n",
      "│   524           self._api_zone.set(parsed_st)                                                                         │\n",
      "│   525           try:                                                                                                  │\n",
      "│   526               return await cb()                                                                                 │\n",
      "│   527           except Exception as error:                                                                            │\n",
      "│   528 →             raise rewrite_error(error, f\"{parsed_st['apiName']}: {error}\") from None                          │\n",
      "│   529           finally:                                                                                              │\n",
      "│   530               self._api_zone.set(None)                                                                          │\n",
      "│   531                                                                                                                 │\n",
      "│   532       def wrap_api_call_sync(                                                                                   │\n",
      "│   533           self, cb: Callable[[], Any], is_internal: bool = False                                                │\n",
      "└───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\n",
      "\n",
      "--------------------------\n",
      "7 7\n",
      "--------------------------\n",
      "7 7\n",
      "[INIT].... → Crawl4AI 0.4.247\n",
      "[FETCH]... ↓ https://www.aljazeera.com/economy/2021/2/3/billion... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.aljazeera.com/economy/2021/2/3/billion... | Status: True | Total: 0.06s\n",
      "[FETCH]... ↓ https://fortune.com/2024/05/09/amazon-andy-jassy-e... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://fortune.com/2024/05/09/amazon-andy-jassy-e... | Status: True | Total: 0.08s\n",
      "[FETCH]... ↓ https://www.theregister.com/2024/05/01/amazon_q1_2... | Status: True | Time: 0.00s\n",
      "[COMPLETE] ● https://www.theregister.com/2024/05/01/amazon_q1_2... | Status: True | Total: 0.06s\n",
      "[FETCH]... ↓ https://finance.yahoo.com/news/amazon-web-services... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://finance.yahoo.com/news/amazon-web-services... | Status: True | Total: 0.08s\n",
      "[FETCH]... ↓ https://www.forbes.com/sites/bethkindig/2024/05/17... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.forbes.com/sites/bethkindig/2024/05/17... | Status: True | Total: 0.08s\n",
      "[FETCH]... ↓ https://www.forrester.com/blogs/amazon-vs-walmart-... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.forrester.com/blogs/amazon-vs-walmart-... | Status: True | Total: 0.09s\n",
      "[FETCH]... ↓ https://www.forbes.com/sites/petercohan/2024/07/01... | Status: True | Time: 0.18s\n",
      "[COMPLETE] ● https://www.forbes.com/sites/petercohan/2024/07/01... | Status: True | Total: 0.26s\n",
      "[FETCH]... ↓ https://www.forestshipping.com/amazon-ai-100B-doll... | Status: True | Time: 0.37s\n",
      "[COMPLETE] ● https://www.forestshipping.com/amazon-ai-100B-doll... | Status: True | Total: 0.44s\n",
      "[FETCH]... ↓ https://www.theguardian.com/technology/2024/apr/30... | Status: True | Time: 0.18s\n",
      "[COMPLETE] ● https://www.theguardian.com/technology/2024/apr/30... | Status: True | Total: 0.25s\n",
      "[FETCH]... ↓ https://www.statista.com/statistics/266282/annual-... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.statista.com/statistics/266282/annual-... | Status: True | Total: 0.06s\n",
      "--------------------------\n",
      "10 10\n",
      "--------------------------\n",
      "10 10\n",
      "[INIT].... → Crawl4AI 0.4.247\n",
      "[FETCH]... ↓ https://www.quora.com/Will-IBM-reemerge-as-a-leade... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.quora.com/Will-IBM-reemerge-as-a-leade... | Status: True | Total: 0.06s\n",
      "[FETCH]... ↓ https://www.techtarget.com/searchitchannel/definit... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.techtarget.com/searchitchannel/definit... | Status: True | Total: 0.08s\n",
      "[FETCH]... ↓ https://www.techtarget.com/searchitchannel/definit... | Status: True | Time: 0.02s\n",
      "[COMPLETE] ● https://www.techtarget.com/searchitchannel/definit... | Status: True | Total: 0.10s\n",
      "[FETCH]... ↓ https://en.wikipedia.org/wiki/IBM... | Status: True | Time: 0.20s\n",
      "[COMPLETE] ● https://en.wikipedia.org/wiki/IBM... | Status: True | Total: 0.27s\n",
      "[FETCH]... ↓ https://www.ibm.com/about... | Status: True | Time: 0.37s\n",
      "[COMPLETE] ● https://www.ibm.com/about... | Status: True | Total: 0.47s\n",
      "[FETCH]... ↓ https://www.investopedia.com/companies-owned-by-ib... | Status: True | Time: 0.37s\n",
      "[COMPLETE] ● https://www.investopedia.com/companies-owned-by-ib... | Status: True | Total: 0.44s\n",
      "[FETCH]... ↓ https://www.forbes.com/companies/ibm/... | Status: True | Time: 0.39s\n",
      "[COMPLETE] ● https://www.forbes.com/companies/ibm/... | Status: True | Total: 0.46s\n",
      "[FETCH]... ↓ https://www.ibm.com/industries... | Status: True | Time: 0.39s\n",
      "[COMPLETE] ● https://www.ibm.com/industries... | Status: True | Total: 0.47s\n",
      "[FETCH]... ↓ https://www.reddit.com/r/IBM/comments/1dn1s65/what... | Status: True | Time: 0.33s\n",
      "[COMPLETE] ● https://www.reddit.com/r/IBM/comments/1dn1s65/what... | Status: True | Total: 0.44s\n",
      "[FETCH]... ↓ https://akshatsinghbisht.com/why-ibm-is-a-market-l... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://akshatsinghbisht.com/why-ibm-is-a-market-l... | Status: True | Total: 0.06s\n",
      "--------------------------\n",
      "10 10\n",
      "--------------------------\n",
      "10 10\n",
      "[INIT].... → Crawl4AI 0.4.247\n",
      "[FETCH]... ↓ https://www.eia.gov/energyexplained/oil-and-petrol... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.eia.gov/energyexplained/oil-and-petrol... | Status: True | Total: 0.10s\n",
      "[FETCH]... ↓ https://www.investopedia.com/articles/markets/1013... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.investopedia.com/articles/markets/1013... | Status: True | Total: 0.06s\n",
      "[FETCH]... ↓ https://www.investopedia.com/how-exxonmobil-makes-... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.investopedia.com/how-exxonmobil-makes-... | Status: True | Total: 0.05s\n",
      "[FETCH]... ↓ https://investor.exxonmobil.com/company-informatio... | Status: True | Time: 0.00s\n",
      "[COMPLETE] ● https://investor.exxonmobil.com/company-informatio... | Status: True | Total: 0.05s\n",
      "[FETCH]... ↓ https://www.britannica.com/money/Exxon-Mobil-Corpo... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.britannica.com/money/Exxon-Mobil-Corpo... | Status: True | Total: 0.06s\n",
      "[FETCH]... ↓ https://www.britannica.com/money/Mobil-Corporation... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.britannica.com/money/Mobil-Corporation... | Status: True | Total: 0.07s\n",
      "[FETCH]... ↓ https://en.wikipedia.org/wiki/ExxonMobil... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://en.wikipedia.org/wiki/ExxonMobil... | Status: True | Total: 0.09s\n",
      "[FETCH]... ↓ https://www.statista.com/topics/1109/exxonmobil/... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.statista.com/topics/1109/exxonmobil/... | Status: True | Total: 0.06s\n",
      "[FETCH]... ↓ https://www.exxonmobilpipeline.com/en/about/locati... | Status: True | Time: 0.00s\n",
      "[COMPLETE] ● https://www.exxonmobilpipeline.com/en/about/locati... | Status: True | Total: 0.05s\n",
      "[FETCH]... ↓ https://www.exxonmobilpipeline.com/en... | Status: True | Time: 0.00s\n",
      "[COMPLETE] ● https://www.exxonmobilpipeline.com/en... | Status: True | Total: 0.06s\n",
      "--------------------------\n",
      "10 10\n",
      "--------------------------\n",
      "10 10\n",
      "[INIT].... → Crawl4AI 0.4.247\n",
      "[FETCH]... ↓ https://www.quora.com/Why-is-Google-an-advertising... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.quora.com/Why-is-Google-an-advertising... | Status: True | Total: 0.06s\n",
      "[FETCH]... ↓ https://www.deptagency.com/insight/beyond-google-t... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.deptagency.com/insight/beyond-google-t... | Status: True | Total: 0.08s\n",
      "[FETCH]... ↓ https://analyticsindiamag.com/global-tech/google-i... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://analyticsindiamag.com/global-tech/google-i... | Status: True | Total: 0.06s\n",
      "[FETCH]... ↓ https://blog.google/around-the-globe/google-asia/a... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://blog.google/around-the-globe/google-asia/a... | Status: True | Total: 0.08s\n",
      "[FETCH]... ↓ https://www.nytimes.com/2008/08/11/technology/11go... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.nytimes.com/2008/08/11/technology/11go... | Status: True | Total: 0.06s\n",
      "[FETCH]... ↓ https://support.google.com/google-ads/answer/17043... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://support.google.com/google-ads/answer/17043... | Status: True | Total: 0.06s\n",
      "[FETCH]... ↓ https://www.accc.gov.au/media-release/googles-domi... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.accc.gov.au/media-release/googles-domi... | Status: True | Total: 0.05s\n",
      "[FETCH]... ↓ https://www.promarket.org/2020/02/24/how-google-an... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.promarket.org/2020/02/24/how-google-an... | Status: True | Total: 0.06s\n",
      "[FETCH]... ↓ https://techliberation.com/2008/08/11/why-google-i... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://techliberation.com/2008/08/11/why-google-i... | Status: True | Total: 0.06s\n",
      "[FETCH]... ↓ https://www.nytimes.com/2005/11/16/technology/goog... | Status: True | Time: 0.00s\n",
      "[COMPLETE] ● https://www.nytimes.com/2005/11/16/technology/goog... | Status: True | Total: 0.05s\n",
      "--------------------------\n",
      "10 10\n",
      "--------------------------\n",
      "10 10\n",
      "[INIT].... → Crawl4AI 0.4.247\n",
      "[FETCH]... ↓ https://www.fiercepharma.com/pharma/top-20-pharma-... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.fiercepharma.com/pharma/top-20-pharma-... | Status: True | Total: 0.08s\n",
      "[FETCH]... ↓ https://www.visualcapitalist.com/cp/worlds-50-larg... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.visualcapitalist.com/cp/worlds-50-larg... | Status: True | Total: 0.06s\n",
      "[FETCH]... ↓ https://en.wikipedia.org/wiki/Pfizer... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://en.wikipedia.org/wiki/Pfizer... | Status: True | Total: 0.06s\n",
      "[FETCH]... ↓ https://www.trtworld.com/magazine/who-owns-the-wor... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.trtworld.com/magazine/who-owns-the-wor... | Status: True | Total: 0.08s\n",
      "[FETCH]... ↓ https://www.statista.com/statistics/309425/prescri... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.statista.com/statistics/309425/prescri... | Status: True | Total: 0.06s\n",
      "[FETCH]... ↓ https://www.investopedia.com/ask/answers/052015/wh... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.investopedia.com/ask/answers/052015/wh... | Status: True | Total: 0.08s\n",
      "[FETCH]... ↓ https://www.pfizer.com/news/media-resources/press-... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.pfizer.com/news/media-resources/press-... | Status: True | Total: 0.06s\n",
      "[FETCH]... ↓ https://www.pfizer.com/about/history/pfizer_warner... | Status: True | Time: 0.18s\n",
      "[COMPLETE] ● https://www.pfizer.com/about/history/pfizer_warner... | Status: True | Total: 0.25s\n",
      "[FETCH]... ↓ https://www.proclinical.com/blogs/2024-7/who-are-t... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.proclinical.com/blogs/2024-7/who-are-t... | Status: True | Total: 0.06s\n",
      "--------------------------\n",
      "10 10\n",
      "--------------------------\n",
      "10 10\n",
      "[INIT].... → Crawl4AI 0.4.247\n",
      "[FETCH]... ↓ https://en.wikipedia.org/wiki/SpaceX... | Status: True | Time: 0.02s\n",
      "[COMPLETE] ● https://en.wikipedia.org/wiki/SpaceX... | Status: True | Total: 0.10s\n",
      "[FETCH]... ↓ https://businessintexas.com/business-sectors/aeros... | Status: True | Time: 0.00s\n",
      "[COMPLETE] ● https://businessintexas.com/business-sectors/aeros... | Status: True | Total: 0.06s\n",
      "[FETCH]... ↓ https://www.ourcrowd.com/learn/what-is-aerospace-a... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.ourcrowd.com/learn/what-is-aerospace-a... | Status: True | Total: 0.06s\n",
      "[FETCH]... ↓ https://www.barrons.com/articles/spacex-joins-the-... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.barrons.com/articles/spacex-joins-the-... | Status: True | Total: 0.08s\n",
      "[FETCH]... ↓ https://www.barrons.com/articles/spacex-stock-boei... | Status: True | Time: 0.17s\n",
      "[COMPLETE] ● https://www.barrons.com/articles/spacex-stock-boei... | Status: True | Total: 0.25s\n",
      "[FETCH]... ↓ https://fortune.com/2024/12/07/spacex-palantir-val... | Status: True | Time: 0.23s\n",
      "[COMPLETE] ● https://fortune.com/2024/12/07/spacex-palantir-val... | Status: True | Total: 0.30s\n",
      "[FETCH]... ↓ https://inkstickmedia.com/spacex-says-it-is-buildi... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://inkstickmedia.com/spacex-says-it-is-buildi... | Status: True | Total: 0.06s\n",
      "[FETCH]... ↓ https://ezassi.com/aerospace-defense-industry-inno... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://ezassi.com/aerospace-defense-industry-inno... | Status: True | Total: 0.06s\n",
      "[FETCH]... ↓ https://camoinassociates.com/resources/aerospace-a... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://camoinassociates.com/resources/aerospace-a... | Status: True | Total: 0.07s\n",
      "[FETCH]... ↓ https://www.reddit.com/r/aerospace/comments/1crder... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.reddit.com/r/aerospace/comments/1crder... | Status: True | Total: 0.06s\n",
      "--------------------------\n",
      "10 10\n",
      "--------------------------\n",
      "10 10\n",
      "[INIT].... → Crawl4AI 0.4.247\n",
      "[FETCH]... ↓ https://www.techtarget.com/searchcloudcomputing/de... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.techtarget.com/searchcloudcomputing/de... | Status: True | Total: 0.06s\n",
      "[FETCH]... ↓ https://azure.microsoft.com/en-us/resources/cloud-... | Status: True | Time: 0.13s\n",
      "[COMPLETE] ● https://azure.microsoft.com/en-us/resources/cloud-... | Status: True | Total: 0.21s\n",
      "[FETCH]... ↓ https://azure.microsoft.com/en-us/resources/cloud-... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://azure.microsoft.com/en-us/resources/cloud-... | Status: True | Total: 0.08s\n",
      "[FETCH]... ↓ https://www.microsoft.com/en-us/microsoft-cloud... | Status: True | Time: 0.20s\n",
      "[COMPLETE] ● https://www.microsoft.com/en-us/microsoft-cloud... | Status: True | Total: 0.28s\n",
      "[FETCH]... ↓ https://azure.microsoft.com/en-us/resources/cloud-... | Status: True | Time: 0.18s\n",
      "[COMPLETE] ● https://azure.microsoft.com/en-us/resources/cloud-... | Status: True | Total: 0.25s\n",
      "[FETCH]... ↓ https://azure.microsoft.com/... | Status: True | Time: 0.02s\n",
      "[COMPLETE] ● https://azure.microsoft.com/... | Status: True | Total: 0.09s\n",
      "[FETCH]... ↓ https://www.microsoft.com/en-us/microsoft-cloud/wh... | Status: True | Time: 0.00s\n",
      "[COMPLETE] ● https://www.microsoft.com/en-us/microsoft-cloud/wh... | Status: True | Total: 0.05s\n",
      "[FETCH]... ↓ https://www.microsoft.com/insidetrack/blog/microso... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.microsoft.com/insidetrack/blog/microso... | Status: True | Total: 0.08s\n",
      "[FETCH]... ↓ https://www.linkedin.com/pulse/microsofts-shift-cl... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.linkedin.com/pulse/microsofts-shift-cl... | Status: True | Total: 0.06s\n",
      "[FETCH]... ↓ https://www.smartosc.com/what-is-microsoft-cloud-c... | Status: True | Time: 0.00s\n",
      "[COMPLETE] ● https://www.smartosc.com/what-is-microsoft-cloud-c... | Status: True | Total: 0.06s\n",
      "--------------------------\n",
      "10 10\n",
      "--------------------------\n",
      "10 10\n",
      "[INIT].... → Crawl4AI 0.4.247\n",
      "[FETCH]... ↓ https://www.blackridgeresearch.com/blog/top-renewa... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.blackridgeresearch.com/blog/top-renewa... | Status: True | Total: 0.06s\n",
      "[FETCH]... ↓ https://www.investopedia.com/investing/top-alterna... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.investopedia.com/investing/top-alterna... | Status: True | Total: 0.08s\n",
      "[FETCH]... ↓ https://www.tickertape.in/blog/top-green-energy-st... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.tickertape.in/blog/top-green-energy-st... | Status: True | Total: 0.06s\n",
      "[FETCH]... ↓ https://www.5paisa.com/blog/best-green-energy-stoc... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.5paisa.com/blog/best-green-energy-stoc... | Status: True | Total: 0.07s\n",
      "[FETCH]... ↓ https://wellfound.com/job-collections/5-companies-... | Status: True | Time: 0.19s\n",
      "[COMPLETE] ● https://wellfound.com/job-collections/5-companies-... | Status: True | Total: 0.29s\n",
      "[FETCH]... ↓ https://www.smallcase.com/collections/what-are-gre... | Status: True | Time: 0.21s\n",
      "[COMPLETE] ● https://www.smallcase.com/collections/what-are-gre... | Status: True | Total: 0.28s\n",
      "[FETCH]... ↓ https://www.soleosenergy.com/top-10-green-energy-c... | Status: True | Time: 0.19s\n",
      "[COMPLETE] ● https://www.soleosenergy.com/top-10-green-energy-c... | Status: True | Total: 0.26s\n",
      "[FETCH]... ↓ https://builtin.com/articles/renewable-energy-comp... | Status: True | Time: 0.39s\n",
      "[COMPLETE] ● https://builtin.com/articles/renewable-energy-comp... | Status: True | Total: 0.46s\n",
      "[FETCH]... ↓ https://appreciatewealth.com/blog/top-green-energy... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://appreciatewealth.com/blog/top-green-energy... | Status: True | Total: 0.07s\n",
      "[FETCH]... ↓ https://www.equitymaster.com/stockquotes/greenener... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.equitymaster.com/stockquotes/greenener... | Status: True | Total: 0.11s\n",
      "--------------------------\n",
      "10 10\n",
      "--------------------------\n",
      "10 10\n",
      "[INIT].... → Crawl4AI 0.4.247\n",
      "[FETCH]... ↓ https://vamp.com/blog/social-media-sites/... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://vamp.com/blog/social-media-sites/... | Status: True | Total: 0.05s\n",
      "[FETCH]... ↓ https://www.justanswer.com/computer/pvuwe-huge-inc... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.justanswer.com/computer/pvuwe-huge-inc... | Status: True | Total: 0.06s\n",
      "[FETCH]... ↓ https://www.pewresearch.org/internet/2019/01/16/fa... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.pewresearch.org/internet/2019/01/16/fa... | Status: True | Total: 0.09s\n",
      "[FETCH]... ↓ https://www.linkedin.com/pulse/four-main-categorie... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.linkedin.com/pulse/four-main-categorie... | Status: True | Total: 0.06s\n",
      "[FETCH]... ↓ https://www.searchenginejournal.com/social-media/s... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.searchenginejournal.com/social-media/s... | Status: True | Total: 0.08s\n",
      "[FETCH]... ↓ https://savemyleads.com/blog/other/how-to-see-how-... | Status: True | Time: 0.17s\n",
      "[COMPLETE] ● https://savemyleads.com/blog/other/how-to-see-how-... | Status: True | Total: 0.24s\n",
      "[FETCH]... ↓ https://fiveminutemarketing.com/2022/10/facebook-i... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://fiveminutemarketing.com/2022/10/facebook-i... | Status: True | Total: 0.08s\n",
      "[FETCH]... ↓ https://jennstrends.com/which-social-media-sites-t... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://jennstrends.com/which-social-media-sites-t... | Status: True | Total: 0.05s\n",
      "[FETCH]... ↓ https://www.postcontrolmarketing.com/social-media-... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.postcontrolmarketing.com/social-media-... | Status: True | Total: 0.06s\n",
      "[FETCH]... ↓ https://peppervirtualassistant.com/blog/a-comprehe... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://peppervirtualassistant.com/blog/a-comprehe... | Status: True | Total: 0.09s\n",
      "--------------------------\n",
      "10 10\n",
      "--------------------------\n",
      "10 10\n",
      "[INIT].... → Crawl4AI 0.4.247\n",
      "[ERROR]... × https://r.search.yahoo.com/_ylt=AwrFdLELiIdnIQIA8V... | Error: \n",
      "┌───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
      "│ × Unexpected error in _crawl_web at line 528 in wrap_api_call                                                         │\n",
      "│ (../../../../../miniconda3/envs/graphRAG/lib/python3.9/site-packages/playwright/_impl/_connection.py):                │\n",
      "│   Error: BrowserContext.add_cookies: Protocol error (Storage.setCookies): Invalid cookie fields                       │\n",
      "│                                                                                                                       │\n",
      "│   Code context:                                                                                                       │\n",
      "│   523           parsed_st = _extract_stack_trace_information_from_stack(st, is_internal)                              │\n",
      "│   524           self._api_zone.set(parsed_st)                                                                         │\n",
      "│   525           try:                                                                                                  │\n",
      "│   526               return await cb()                                                                                 │\n",
      "│   527           except Exception as error:                                                                            │\n",
      "│   528 →             raise rewrite_error(error, f\"{parsed_st['apiName']}: {error}\") from None                          │\n",
      "│   529           finally:                                                                                              │\n",
      "│   530               self._api_zone.set(None)                                                                          │\n",
      "│   531                                                                                                                 │\n",
      "│   532       def wrap_api_call_sync(                                                                                   │\n",
      "│   533           self, cb: Callable[[], Any], is_internal: bool = False                                                │\n",
      "└───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\n",
      "\n",
      "[ERROR]... × https://r.search.yahoo.com/_ylt=AwrFdLELiIdnIQIA_1... | Error: \n",
      "┌───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
      "│ × Unexpected error in _crawl_web at line 528 in wrap_api_call                                                         │\n",
      "│ (../../../../../miniconda3/envs/graphRAG/lib/python3.9/site-packages/playwright/_impl/_connection.py):                │\n",
      "│   Error: BrowserContext.add_cookies: Protocol error (Storage.setCookies): Invalid cookie fields                       │\n",
      "│                                                                                                                       │\n",
      "│   Code context:                                                                                                       │\n",
      "│   523           parsed_st = _extract_stack_trace_information_from_stack(st, is_internal)                              │\n",
      "│   524           self._api_zone.set(parsed_st)                                                                         │\n",
      "│   525           try:                                                                                                  │\n",
      "│   526               return await cb()                                                                                 │\n",
      "│   527           except Exception as error:                                                                            │\n",
      "│   528 →             raise rewrite_error(error, f\"{parsed_st['apiName']}: {error}\") from None                          │\n",
      "│   529           finally:                                                                                              │\n",
      "│   530               self._api_zone.set(None)                                                                          │\n",
      "│   531                                                                                                                 │\n",
      "│   532       def wrap_api_call_sync(                                                                                   │\n",
      "│   533           self, cb: Callable[[], Any], is_internal: bool = False                                                │\n",
      "└───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\n",
      "\n",
      "[ERROR]... × https://r.search.yahoo.com/_ylt=AwrFdLELiIdnIQIA3F... | Error: \n",
      "┌───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
      "│ × Unexpected error in _crawl_web at line 528 in wrap_api_call                                                         │\n",
      "│ (../../../../../miniconda3/envs/graphRAG/lib/python3.9/site-packages/playwright/_impl/_connection.py):                │\n",
      "│   Error: BrowserContext.add_cookies: Protocol error (Storage.setCookies): Invalid cookie fields                       │\n",
      "│                                                                                                                       │\n",
      "│   Code context:                                                                                                       │\n",
      "│   523           parsed_st = _extract_stack_trace_information_from_stack(st, is_internal)                              │\n",
      "│   524           self._api_zone.set(parsed_st)                                                                         │\n",
      "│   525           try:                                                                                                  │\n",
      "│   526               return await cb()                                                                                 │\n",
      "│   527           except Exception as error:                                                                            │\n",
      "│   528 →             raise rewrite_error(error, f\"{parsed_st['apiName']}: {error}\") from None                          │\n",
      "│   529           finally:                                                                                              │\n",
      "│   530               self._api_zone.set(None)                                                                          │\n",
      "│   531                                                                                                                 │\n",
      "│   532       def wrap_api_call_sync(                                                                                   │\n",
      "│   533           self, cb: Callable[[], Any], is_internal: bool = False                                                │\n",
      "└───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\n",
      "\n",
      "[ERROR]... × https://r.search.yahoo.com/_ylt=AwrFdLELiIdnIQIA71... | Error: \n",
      "┌───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
      "│ × Unexpected error in _crawl_web at line 528 in wrap_api_call                                                         │\n",
      "│ (../../../../../miniconda3/envs/graphRAG/lib/python3.9/site-packages/playwright/_impl/_connection.py):                │\n",
      "│   Error: BrowserContext.add_cookies: Protocol error (Storage.setCookies): Invalid cookie fields                       │\n",
      "│                                                                                                                       │\n",
      "│   Code context:                                                                                                       │\n",
      "│   523           parsed_st = _extract_stack_trace_information_from_stack(st, is_internal)                              │\n",
      "│   524           self._api_zone.set(parsed_st)                                                                         │\n",
      "│   525           try:                                                                                                  │\n",
      "│   526               return await cb()                                                                                 │\n",
      "│   527           except Exception as error:                                                                            │\n",
      "│   528 →             raise rewrite_error(error, f\"{parsed_st['apiName']}: {error}\") from None                          │\n",
      "│   529           finally:                                                                                              │\n",
      "│   530               self._api_zone.set(None)                                                                          │\n",
      "│   531                                                                                                                 │\n",
      "│   532       def wrap_api_call_sync(                                                                                   │\n",
      "│   533           self, cb: Callable[[], Any], is_internal: bool = False                                                │\n",
      "└───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\n",
      "\n",
      "[ERROR]... × https://r.search.yahoo.com/_ylt=AwrFdLELiIdnIQIA61... | Error: \n",
      "┌───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
      "│ × Unexpected error in _crawl_web at line 528 in wrap_api_call                                                         │\n",
      "│ (../../../../../miniconda3/envs/graphRAG/lib/python3.9/site-packages/playwright/_impl/_connection.py):                │\n",
      "│   Error: BrowserContext.add_cookies: Protocol error (Storage.setCookies): Invalid cookie fields                       │\n",
      "│                                                                                                                       │\n",
      "│   Code context:                                                                                                       │\n",
      "│   523           parsed_st = _extract_stack_trace_information_from_stack(st, is_internal)                              │\n",
      "│   524           self._api_zone.set(parsed_st)                                                                         │\n",
      "│   525           try:                                                                                                  │\n",
      "│   526               return await cb()                                                                                 │\n",
      "│   527           except Exception as error:                                                                            │\n",
      "│   528 →             raise rewrite_error(error, f\"{parsed_st['apiName']}: {error}\") from None                          │\n",
      "│   529           finally:                                                                                              │\n",
      "│   530               self._api_zone.set(None)                                                                          │\n",
      "│   531                                                                                                                 │\n",
      "│   532       def wrap_api_call_sync(                                                                                   │\n",
      "│   533           self, cb: Callable[[], Any], is_internal: bool = False                                                │\n",
      "└───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\n",
      "\n",
      "[ERROR]... × https://r.search.yahoo.com/_ylt=AwrFdLELiIdnIQIA3l... | Error: \n",
      "┌───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
      "│ × Unexpected error in _crawl_web at line 528 in wrap_api_call                                                         │\n",
      "│ (../../../../../miniconda3/envs/graphRAG/lib/python3.9/site-packages/playwright/_impl/_connection.py):                │\n",
      "│   Error: BrowserContext.add_cookies: Protocol error (Storage.setCookies): Invalid cookie fields                       │\n",
      "│                                                                                                                       │\n",
      "│   Code context:                                                                                                       │\n",
      "│   523           parsed_st = _extract_stack_trace_information_from_stack(st, is_internal)                              │\n",
      "│   524           self._api_zone.set(parsed_st)                                                                         │\n",
      "│   525           try:                                                                                                  │\n",
      "│   526               return await cb()                                                                                 │\n",
      "│   527           except Exception as error:                                                                            │\n",
      "│   528 →             raise rewrite_error(error, f\"{parsed_st['apiName']}: {error}\") from None                          │\n",
      "│   529           finally:                                                                                              │\n",
      "│   530               self._api_zone.set(None)                                                                          │\n",
      "│   531                                                                                                                 │\n",
      "│   532       def wrap_api_call_sync(                                                                                   │\n",
      "│   533           self, cb: Callable[[], Any], is_internal: bool = False                                                │\n",
      "└───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\n",
      "\n",
      "--------------------------\n",
      "6 6\n",
      "--------------------------\n",
      "6 6\n",
      "[INIT].... → Crawl4AI 0.4.247\n",
      "[FETCH]... ↓ https://ecommercedb.com/insights/the-world-s-most-... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://ecommercedb.com/insights/the-world-s-most-... | Status: True | Total: 0.06s\n",
      "[FETCH]... ↓ https://builtin.com/articles/e-commerce-companies... | Status: True | Time: 0.00s\n",
      "[COMPLETE] ● https://builtin.com/articles/e-commerce-companies... | Status: True | Total: 0.08s\n",
      "[FETCH]... ↓ https://companiesmarketcap.com/e-commerce/largest-... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://companiesmarketcap.com/e-commerce/largest-... | Status: True | Total: 0.09s\n",
      "[FETCH]... ↓ https://www.fool.com/investing/stock-market/market... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.fool.com/investing/stock-market/market... | Status: True | Total: 0.06s\n",
      "[FETCH]... ↓ https://www.statista.com/statistics/245340/leading... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.statista.com/statistics/245340/leading... | Status: True | Total: 0.07s\n",
      "[FETCH]... ↓ https://www.similarweb.com/blog/sales/selling-to-e... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.similarweb.com/blog/sales/selling-to-e... | Status: True | Total: 0.07s\n",
      "[FETCH]... ↓ https://www.shopify.com/blog/ecommerce-companies... | Status: True | Time: 0.00s\n",
      "[COMPLETE] ● https://www.shopify.com/blog/ecommerce-companies... | Status: True | Total: 0.06s\n",
      "[FETCH]... ↓ https://axiomq.com/blog/8-largest-e-commerce-compa... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://axiomq.com/blog/8-largest-e-commerce-compa... | Status: True | Total: 0.07s\n",
      "[FETCH]... ↓ https://www.emarketer.com/insights/biggest-retail-... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.emarketer.com/insights/biggest-retail-... | Status: True | Total: 0.06s\n",
      "[FETCH]... ↓ https://www.doofinder.com/en/statistics/largest-ec... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www.doofinder.com/en/statistics/largest-ec... | Status: True | Total: 0.06s\n",
      "--------------------------\n",
      "10 10\n",
      "--------------------------\n",
      "10 10\n"
     ]
    }
   ],
   "source": [
    "crawled_list_all = []\n",
    "for item in snippets_data:\n",
    "    crawled_list = await main(item['urls'])\n",
    "    snippets_list = []\n",
    "    content_list = []\n",
    "    assert len(item['snippets']) == len(item['urls'])\n",
    "    print('-'*26)\n",
    "    print(len(item['snippets']), len(item['urls']))\n",
    "\n",
    "    for cr, sp, url in zip(crawled_list, item['snippets'], item['urls']):\n",
    "        if str(cr[0]) == url and cr[1]:\n",
    "            snippets_list.append(sp)\n",
    "            content_list.append(clean_text(cr[2]))\n",
    "        else:\n",
    "            snippets_list.append(sp)\n",
    "            content_list.append(\"\")\n",
    "\n",
    "        assert len(snippets_list) == len(content_list)\n",
    "        \n",
    "    print('-'*26)\n",
    "    print(len(snippets_list), len(content_list))\n",
    "            \n",
    "    crawled_list_all.append({\"query\": item[\"query\"],\"snippets\": snippets_list, \"content\": content_list})\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(index)\n\u001b[1;32m      5\u001b[0m index\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sp) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(ct)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for page in crawled_list_all:\n",
    "    index  = 0\n",
    "    for sp, ct, in zip(page['snippets'], page['content']):\n",
    "        print(index)\n",
    "        index+=1\n",
    "        assert len(sp) == len(ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('crawled_cleaned_content_v2.json', 'w') as f:\n",
    "    json.dump(crawled_list_all, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "crawled_cleaned_content_list = []\n",
    "for item in crawled_list_all:\n",
    "    cleaned_content_list = []\n",
    "    for content in item:\n",
    "        cleaned_content_list.append(clean_text(str(content[2])))\n",
    "    crawled_cleaned_content_list.append(cleaned_content_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snippets_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_markdown = clean_text(results[0].markdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cleaned_markdown), len(results[0].markdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cleaned_markdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlidingWindowChunking:\n",
    "    def __init__(self, window_size=400, step=350):\n",
    "        self.window_size = window_size\n",
    "        self.step = step\n",
    "\n",
    "    def chunk(self, text):\n",
    "        words = text.split()\n",
    "        chunks = []\n",
    "        for i in range(0, len(words) - self.window_size + 1, self.step):\n",
    "            chunks.append(' '.join(words[i:i + self.window_size]))\n",
    "        return chunks\n",
    "\n",
    "# Example Usage\n",
    "text = \"This is a long text to demonstrate sliding window chunking.\"\n",
    "chunker = SlidingWindowChunking()\n",
    "print(chunker.chunk(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_list = chunker.chunk(result.markdown_v2.fit_markdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(chunks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(chunks_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import httpx\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "_ = load_dotenv()\n",
    "\n",
    "\n",
    "async def get_source_from_pegasus(params):\n",
    "    pegasus_url = os.getenv(\"CLOUDFUNCTION_SERVICE\")\n",
    "    headers = {\"accept\": \"application/json\"}\n",
    "    async with httpx.AsyncClient(timeout=300) as client:\n",
    "        try:\n",
    "            response = await client.get(pegasus_url, headers=headers, params=params)\n",
    "            response.raise_for_status()\n",
    "            json_response = response.json()\n",
    "            return json_response\n",
    "        except httpx.HTTPStatusError as http_err:\n",
    "            status_code = http_err.response.status_code\n",
    "            print(f\"Status code: {status_code}\")\n",
    "            return None\n",
    "        except httpx.RequestError as req_err:\n",
    "            print(f\"Request error occurred: {str(req_err)}\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"Exception: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Biggest Venture Capital Firms in Germany\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pegasus_result = await get_source_from_pegasus(params={\"query\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pegasus_result['query_result'][0]['link']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in pegasus_result['query_result']:\n",
    "    urls_list.apend(result['link'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphRAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
